# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/chewc2.ipynb.

# %% auto 0
__all__ = ['device', 'input_length', 'pop_size', 'dummy_geno_data', 'num_meta_features', 'Genome', 'Population', 'Trait',
           'calculate_breeding_value', 'truncation_selection', 'recombine', 'phenotype', 'create_random_pop',
           'update_pop', 'breed', 'create_pop', 'bv', 'create_progeny', 'run_generation', 'population_statistics',
           'BreedingSimulation', 'GeneticFeatureExtractor', 'MetaDataProcessor', 'CompleteNetwork', 'create_dummy_data',
           'prep']

# %% ../nbs/chewc2.ipynb 1
import torch
import matplotlib.pyplot as plt
from fastcore.basics import patch
import uuid
import pdb
import torch
from matplotlib.animation import FuncAnimation

device='cpu'

class Genome:
    def __init__(self, n_chr, n_loci):
        self.ploidy = 2
        self.n_chr = n_chr
        self.n_loci = n_loci
        self.shape = (self.ploidy, self.n_chr, self.n_loci)
        
class Population:
    def __init__(self, genome, haplotypes, device=device):
        self.genome = genome
        self.device = device
        self.phenotypes = None
        self.haplotypes = haplotypes
        self.dosages = haplotypes.sum(dim=1).float()
        self.size = haplotypes.shape[0]
                
class Trait:
    def __init__(self, genome, founder_population, target_mean, target_variance, device=device):
        self.target_mean = target_mean
        self.target_variance = target_variance
        self.device = device
        random_effects = torch.randn(genome.n_chr, genome.n_loci, device=self.device)
        random_effects -= random_effects.mean()
        founder_scores = torch.einsum('kl,hkl->h', random_effects, founder_population.dosages)
        founder_mean, founder_var = founder_scores.mean(), founder_scores.var()
        scaling_factors = torch.sqrt(self.target_variance / founder_var)
        self.scaling_factors = scaling_factors
        random_effects *= scaling_factors
        self.effects = random_effects
        self.intercept = founder_mean - target_mean

        
def calculate_breeding_value(population_dosages, trait_effects, device = device):
    return torch.einsum('hjk,jk->h', population_dosages,trait_effects)

def truncation_selection(population, trait, top_percent):
    return torch.topk(population.phenotypes, top_percent).indices

# meiosis
def recombine(parent_haplo_tensor, recombination_rate=0.1):
    num_individuals, ploidy, num_chromosomes, num_loci = parent_haplo_tensor.shape    
    # Generate crossover masks
    maternal, paternal = parent_haplo_tensor[:,0,:,:],parent_haplo_tensor[:,1,:,:],
    crossovers = torch.bernoulli(torch.full((num_individuals, num_chromosomes, num_loci), recombination_rate, device=device))
    #crossovers = torch.rand((num_individuals, num_chromosomes, num_loci), device=device) < recombination_rate
    progeny = maternal * (1 - crossovers) + paternal * crossovers
    return progeny


def phenotype(population, trait, h2):
    breeding_values = calculate_breeding_value(population.dosages, trait.effects) 
    
    if breeding_values.var() == 0:
        print('phenotype: no var')
        environmental_variance = 0  
    else:
        environmental_variance = (1 - h2) / h2 * breeding_values.var() 
    
    # Check if environmental_variance is zero before applying torch.sqrt and .clone()
    if environmental_variance == 0:
        environmental_noise = torch.zeros(breeding_values.shape, device=device)
    else:
        environmental_noise = torch.randn(breeding_values.shape, device=device) * torch.sqrt(environmental_variance).detach()
    
    population.phenotypes = breeding_values + environmental_noise
#     def _create_random_haplotypes(self,num_individuals):
#         return torch.randint(0, 2, (num_individuals, *self.g.shape), device=self.device)
def create_random_pop(G, pop_size):
    return torch.randint(0, 2, (pop_size, *G.shape), device= device)

def update_pop(population, haplotype_pop_tensor):
    population.haplotypes = haplotype_pop_tensor
    population.dosages = haplotype_pop_tensor.sum(dim=1).float()
    return population

# meiosis
def recombine(parent_haplo_tensor, recombination_rate=0.1):
    num_individuals, ploidy, num_chromosomes, num_loci = parent_haplo_tensor.shape
    # Generate crossover masks
    maternal, paternal = parent_haplo_tensor[:,0,:,:],parent_haplo_tensor[:,1,:,:],
    crossovers = torch.bernoulli(torch.full((num_individuals, num_chromosomes, num_loci), recombination_rate, device=device))
#     crossovers = torch.rand((num_individuals, num_chromosomes, num_loci), device=device) < recombination_rate
    progeny = maternal * torch.logical_not(crossovers) + paternal * crossovers
    return progeny

def breed(mother_tensor, father_tensor, recombination_rate=0.1):
    eggs = recombine(mother_tensor,recombination_rate)
    pollens = recombine(father_tensor,recombination_rate)
    return torch.stack((eggs,pollens), dim=1)

def create_pop(G, haplotypes):
    return Population(G, haplotypes=haplotypes)

def bv(P,T):
    P.breeding_values = calculate_breeding_value(P.dosages,T.effects)
    
def create_progeny(mother_gametes, father_gametes,reps = 1):
    progeny = []
    for _ in range(reps):
        # Randomly shuffle the gametes from each parent 
        shuffled_mother_indices = torch.randperm(mother_gametes.shape[0])
        shuffled_father_indices = torch.randperm(father_gametes.shape[0])

        # Select the shuffled gametes
        mother_gametes = mother_gametes[shuffled_mother_indices]
        father_gametes = father_gametes[shuffled_father_indices]

        # Stack the gametes to create progeny haplotypes
        progeny_haplotypes = torch.stack((mother_gametes, father_gametes),dim=1)
        progeny.append(progeny_haplotypes)
    return torch.vstack(progeny)

# Function to run one generation
def run_generation(P, T, h2, reps, pop_size, selection_fraction):
    bv(P, T)  # Calculate breeding values
    phenotype(P, T, h2)  # Calculate phenotypes with given h2
    selected = P.haplotypes[torch.topk(P.phenotypes, int(pop_size * selection_fraction)).indices]  # Select top individuals based on phenotype
    m = recombine(selected)  # Mother gametes
    f = recombine(selected)  # Father gametes
    progeny = create_progeny(m, f, reps=reps)  # Create progeny
    new_population = Population(G, progeny)
    bv(new_population, T)  # Calculate breeding values for progeny
    phenotype(new_population, T, h2)  # Calculate phenotypes for progeny
    return new_population

# %% ../nbs/chewc2.ipynb 4
def population_statistics(population_tensor):
    """
    
    """
    
    #Calculate the mean genotype value divided by 2 for each marker.
    def calculate_allele_frequencies(genotypes):
        num_individuals = genotypes.size(0)
        allele_frequencies = torch.mean(genotypes, dim=0) / 2
        return allele_frequencies.float()
    #Calculate the unique genotype counts and their frequencies.
    def calculate_genotype_frequencies(genotypes):
        num_individuals = genotypes.size(0)
        unique_genotypes, counts = torch.unique(genotypes, dim=0, return_counts=True)
        genotype_frequencies = counts.float() / num_individuals
        return unique_genotypes, genotype_frequencies
    #Calculate the proportion of heterozygous individuals at each marker.
    def calculate_heterozygosity(genotypes):
        num_individuals = genotypes.size(0)
        heterozygosity = torch.sum(genotypes == 1, dim=0).float() / num_individuals
        return heterozygosity.float()
    #Calculate the frequency of the less common allele.
    def calculate_maf(genotypes):
        allele_frequencies = calculate_allele_frequencies(genotypes)
        maf = torch.minimum(allele_frequencies, 1 - allele_frequencies)
        return maf.float()
    #Measure the degree of inbreeding based on observed and expected heterozygosity.
    def calculate_inbreeding_coefficient(genotypes):
        num_markers = genotypes.size(1)
        observed_heterozygosity = torch.sum(genotypes == 1, dim=1).float() / num_markers
        expected_heterozygosity = 2 * calculate_allele_frequencies(genotypes) * (1 - calculate_allele_frequencies(genotypes))
        average_expected_heterozygosity = torch.mean(expected_heterozygosity)
        inbreeding_coefficient = 1 - (observed_heterozygosity / average_expected_heterozygosity)
        return inbreeding_coefficient.float()
    #Calculate the correlation matrix for the genotypes.
    def calculate_ld(genotypes):
        num_markers = genotypes.size(1)
        ld_matrix = torch.corrcoef(genotypes.T)
        return ld_matrix.float()
    #Measure the genetic differentiation between subpopulations.
    def calculate_fst(genotypes, subpopulations):
        total_allele_frequencies = calculate_allele_frequencies(genotypes)
        subpop_allele_frequencies = [calculate_allele_frequencies(genotypes[subpop]) for subpop in subpopulations]
        ht = 2 * total_allele_frequencies * (1 - total_allele_frequencies)
        hs = torch.mean(torch.stack([2 * freq * (1 - freq) for freq in subpop_allele_frequencies]), dim=0)
        fst = (ht - hs) / ht
        return fst
    #Estimate the effective population size based on allele frequencies and genetic drift.
    def calculate_effective_population_size(genotypes):
        num_individuals = genotypes.size(0)
        allele_frequencies = calculate_allele_frequencies(genotypes)
        variance = torch.var(allele_frequencies)
        ne = (num_individuals - 1) / (2 * variance)
        return ne

    genotypes = population_tensor
    stats = {
        'allele_frequencies': calculate_allele_frequencies(genotypes),
        'genotype_frequencies': calculate_genotype_frequencies(genotypes),
        'heterozygosity': calculate_heterozygosity(genotypes),
        'maf': calculate_maf(genotypes),
        'inbreeding_coefficient': calculate_inbreeding_coefficient(genotypes),
        'ld_matrix': calculate_ld(genotypes),
        'effective_population_size': calculate_effective_population_size(genotypes)
    }
    return stats

# %% ../nbs/chewc2.ipynb 10
class BreedingSimulation:
    def __init__(self, G, T, h2, reps, pop_size, selection_fraction):
        self.G = G
        self.T = T
        self.h2 = h2
        self.reps = reps
        self.pop_size = pop_size
        self.selection_fraction = selection_fraction
        self.population = create_pop(G, create_random_pop(G, pop_size)) # Start with a random population
        self.history = []  # For tracking population data over generations

    def step(self, actions): # Actions will be provided by the RL agent
        selected_parent_indices = self.select_parents(actions)
        selected = self.population.haplotypes[selected_parent_indices]
        
        #breeding
        m = recombine(selected)  # Mother gametes
        f = recombine(selected)  # Father gametes
        progeny = create_progeny(m, f, reps=self.reps)  # Create progeny

        #phenotype
        self.population = update_pop(self.population, progeny)
        bv(self.population, self.T)
        phenotype(self.population, self.T, self.h2)

        # Calculate reward (e.g., genetic gain)
        reward = self.calculate_reward()

        # Track data for this generation
        self.track_data(actions, reward)

        return self.get_state(), reward

    def select_parents(self, actions):
        #the output from agent network will go into here.
        phenotype(self.population, self.T, self.h2)
        parents = torch.topk(self.population.phenotypes, actions).indices
        return parents

    def calculate_reward(self):
        # Define how to calculate the reward based on your objective. 
        # Example: Improvement in average trait value
        return self.population.phenotypes.mean()

    def get_state(self):
        # Define how to represent the state of the environment to the 
        # RL agent. You might return features like:
        # - Average trait value: self.population.phenotypes.mean()
        # - Genetic diversity metrics
        # - ...
        return self.population.phenotypes.mean() # Placeholder

    def track_data(self, actions, reward):
        n_ind, n_chr, n_loci = self.population.haplotypes.sum(dim=1).shape
        pop_stat_in  = self.population.haplotypes.sum(dim=1).view((n_ind, n_chr* n_loci))
        pop_stat = population_statistics(pop_stat_in)
#         population_statistics(pop_stat_in.float())['allele_frequencies'].mean()
#         import pdb;pdb.set_trace()
        gen_data = {
            'generation': len(self.history),
            'avg_phenotype': self.population.phenotypes.mean().item(),
            'phenotype_variance': self.population.phenotypes.var().item(),
            'avg_breeding_value': self.population.breeding_values.mean().item(),
            'actions': actions,  # You might want to log the actions taken
            'reward': reward.item(),
            'n_ind': n_ind,
            'heterozygosity': pop_stat['heterozygosity'].mean().item(),
            'allele_frequencies': pop_stat['allele_frequencies'].mean().item(),
            'maf': pop_stat['maf'].mean().item(),
            'inbreeding_coefficient': pop_stat['inbreeding_coefficient'].mean().item(),
            'effective_population_size': pop_stat['effective_population_size'].item()
        }
        self.history.append(gen_data)

    def plot_history(self):
        def normalize(data):
            min_val = min(data)
            max_val = max(data)
            return [(x - min_val) / (max_val - min_val) for x in data]
        generations = [d['generation'] for d in self.history]
        avg_phenotypes = [d['avg_phenotype'] for d in self.history]
        actions = [d['maf'] for d in self.history]
        
        avg_phenotypes = normalize(avg_phenotypes)
        actions = normalize(actions)
        plt.plot(generations, avg_phenotypes)
        plt.plot(generations, actions)
        plt.xlabel('Generation')
        plt.ylabel('Average Phenotype')
        plt.title('Breeding Progress')
        plt.show()


# %% ../nbs/chewc2.ipynb 12
import torch
import torch.nn as nn

class GeneticFeatureExtractor(nn.Module):
    def __init__(self, input_size, num_features=64):
        super(GeneticFeatureExtractor, self).__init__()
        self.num_features = num_features
        self.conv1 = nn.Conv1d(in_channels=2, out_channels=64, kernel_size=32, stride=8)
        self.conv2 = nn.Conv1d(in_channels=64, out_channels=16, kernel_size=8, stride=2)
        
        # Calculate the size after convolutions
        conv1_output_size = (input_size - 32) // 8 + 1
        conv2_output_size = (conv1_output_size - 8) // 2 + 1
        self.flattened_size = conv2_output_size * 16
        
        self.flatten = nn.Flatten()
        self.mlp = nn.Linear(self.flattened_size, self.num_features)

    def forward(self, x):
        x1 = self.conv1(x)
        x1 = torch.relu(x1)
        x1 = self.conv2(x1)
        x1 = torch.relu(x1)
        x1 = self.flatten(x1)
        x1 = self.mlp(x1)

        # Permute the channels
        x2 = x.flip(1)
        x2 = self.conv1(x2)
        x2 = torch.relu(x2)
        x2 = self.conv2(x2)
        x2 = torch.relu(x2)
        x2 = self.flatten(x2)
        x2 = self.mlp(x2)

        # Average the outputs
        x = (x1 + x2) / 2
        return x
    
class MetaDataProcessor(nn.Module):
    def __init__(self, num_features=64, meta_features=16):
        super(MetaDataProcessor, self).__init__()
        self.num_features = num_features
        self.meta_features = meta_features
        # The key change: Input size now reflects num_meta_features 
        self.meta_mlp_action = nn.Linear(num_meta_features, meta_features) 
        self.meta_mlp_value = nn.Linear(num_meta_features, meta_features) 

    def forward(self, meta_data):  # Input is now meta_data
        meta_action = self.meta_mlp_action(meta_data)
        meta_value = self.meta_mlp_value(meta_data)
        return meta_action, meta_value

class CompleteNetwork(nn.Module):
    def __init__(self, input_size, num_features=64, meta_features=16):
        super(CompleteNetwork, self).__init__()
        self.genetic_extractor = GeneticFeatureExtractor(input_size, num_features)
        self.meta_processor = MetaDataProcessor(num_features, meta_features)
        self.final_mlp_action = nn.Linear(num_features + meta_features, num_features)
        self.final_mlp_value = nn.Linear(num_features + meta_features, num_features)

    def forward(self, x, meta_data): # Input is now meta_data 
        genetic_features = self.genetic_extractor(x)
        meta_action, meta_value = self.meta_processor(meta_data)
        combined_action = torch.cat((genetic_features, meta_action), dim=1)
        combined_value = torch.cat((genetic_features, meta_value), dim=1)
        action_output = self.final_mlp_action(combined_action)
        value_output = self.final_mlp_value(combined_value)
        return action_output, value_output
    
# Function to create dummy data
def create_dummy_data(batch_size, channels, length):
    return torch.randn(batch_size, channels, length)

def prep(tensor):
    return tensor.view(tensor.shape[0], tensor.shape[1], -1)

# Example usage with different input sizes
input_length = 7000  # Change this to any length
pop_size = 1
dummy_geno_data = create_dummy_data(pop_size, 2, input_length)

num_meta_features = 5 # float values in tensor

