{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7570e93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x01_populationStatistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4201390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0115],\n",
       "        [ 0.0443],\n",
       "        [ 0.0966],\n",
       "        [ 0.1589],\n",
       "        [ 0.0359],\n",
       "        [ 0.1215],\n",
       "        [ 0.0256],\n",
       "        [ 0.1162],\n",
       "        [ 0.0761],\n",
       "        [ 0.1222],\n",
       "        [ 0.0108],\n",
       "        [ 0.1478],\n",
       "        [ 0.0938],\n",
       "        [ 0.1359],\n",
       "        [ 0.0126],\n",
       "        [ 0.1062],\n",
       "        [ 0.0533],\n",
       "        [ 0.0419],\n",
       "        [ 0.1082],\n",
       "        [ 0.0670],\n",
       "        [ 0.0770],\n",
       "        [ 0.1396],\n",
       "        [ 0.0725],\n",
       "        [ 0.0962],\n",
       "        [ 0.1536],\n",
       "        [ 0.0791],\n",
       "        [ 0.0505],\n",
       "        [ 0.0868],\n",
       "        [ 0.0786],\n",
       "        [ 0.0854],\n",
       "        [ 0.0248],\n",
       "        [ 0.0910],\n",
       "        [ 0.1261],\n",
       "        [ 0.1952],\n",
       "        [ 0.1334],\n",
       "        [ 0.1311],\n",
       "        [ 0.0898],\n",
       "        [ 0.1687],\n",
       "        [ 0.1043],\n",
       "        [ 0.0831],\n",
       "        [ 0.0560],\n",
       "        [ 0.1386],\n",
       "        [ 0.1083],\n",
       "        [ 0.1072],\n",
       "        [ 0.0761],\n",
       "        [ 0.0632],\n",
       "        [ 0.1177],\n",
       "        [ 0.0033],\n",
       "        [ 0.0366],\n",
       "        [ 0.0608],\n",
       "        [ 0.0932],\n",
       "        [ 0.1157],\n",
       "        [ 0.0631],\n",
       "        [ 0.0788],\n",
       "        [ 0.1263],\n",
       "        [ 0.0849],\n",
       "        [ 0.0968],\n",
       "        [ 0.0933],\n",
       "        [ 0.0886],\n",
       "        [ 0.0569],\n",
       "        [ 0.0659],\n",
       "        [ 0.0882],\n",
       "        [ 0.0984],\n",
       "        [ 0.1325],\n",
       "        [ 0.1376],\n",
       "        [ 0.1198],\n",
       "        [ 0.1042],\n",
       "        [ 0.0828],\n",
       "        [ 0.1172],\n",
       "        [ 0.1368],\n",
       "        [ 0.0540],\n",
       "        [ 0.0482],\n",
       "        [ 0.0886],\n",
       "        [ 0.1140],\n",
       "        [ 0.1142],\n",
       "        [ 0.1205],\n",
       "        [ 0.0614],\n",
       "        [ 0.0898],\n",
       "        [ 0.0888],\n",
       "        [ 0.1046],\n",
       "        [ 0.0813],\n",
       "        [ 0.0458],\n",
       "        [ 0.0396],\n",
       "        [ 0.1031],\n",
       "        [ 0.0621],\n",
       "        [ 0.0896],\n",
       "        [ 0.1289],\n",
       "        [ 0.0823],\n",
       "        [ 0.0480],\n",
       "        [ 0.0427],\n",
       "        [ 0.0261],\n",
       "        [ 0.0642],\n",
       "        [ 0.0337],\n",
       "        [-0.0044],\n",
       "        [ 0.0238],\n",
       "        [ 0.0924],\n",
       "        [ 0.0776],\n",
       "        [ 0.0570],\n",
       "        [ 0.0742],\n",
       "        [ 0.0702],\n",
       "        [ 0.0376],\n",
       "        [ 0.1132],\n",
       "        [ 0.0671],\n",
       "        [ 0.0301],\n",
       "        [ 0.0451],\n",
       "        [ 0.0843],\n",
       "        [ 0.0637],\n",
       "        [ 0.0392],\n",
       "        [ 0.1327],\n",
       "        [ 0.0819],\n",
       "        [ 0.0401],\n",
       "        [ 0.1064],\n",
       "        [ 0.0027],\n",
       "        [-0.0054],\n",
       "        [ 0.0849],\n",
       "        [ 0.0639],\n",
       "        [ 0.0820],\n",
       "        [ 0.0628],\n",
       "        [ 0.1387],\n",
       "        [ 0.0783],\n",
       "        [ 0.0414],\n",
       "        [ 0.0356],\n",
       "        [ 0.0472],\n",
       "        [ 0.1283],\n",
       "        [ 0.0479],\n",
       "        [ 0.0592],\n",
       "        [ 0.0764],\n",
       "        [ 0.0790],\n",
       "        [ 0.0090],\n",
       "        [ 0.0464],\n",
       "        [ 0.0324],\n",
       "        [ 0.0511],\n",
       "        [ 0.0913],\n",
       "        [ 0.0939],\n",
       "        [ 0.1389],\n",
       "        [ 0.0903],\n",
       "        [ 0.0916],\n",
       "        [ 0.1313],\n",
       "        [ 0.1208],\n",
       "        [ 0.0626],\n",
       "        [ 0.1286],\n",
       "        [ 0.0632],\n",
       "        [ 0.0521],\n",
       "        [ 0.0559],\n",
       "        [ 0.0438],\n",
       "        [ 0.1151],\n",
       "        [ 0.0977],\n",
       "        [ 0.0958],\n",
       "        [ 0.0900],\n",
       "        [ 0.0601],\n",
       "        [ 0.0158],\n",
       "        [ 0.0212],\n",
       "        [ 0.1010],\n",
       "        [ 0.0531],\n",
       "        [ 0.0528],\n",
       "        [ 0.0578],\n",
       "        [ 0.1167],\n",
       "        [ 0.0245],\n",
       "        [ 0.1062],\n",
       "        [ 0.1104],\n",
       "        [ 0.0462],\n",
       "        [ 0.1151],\n",
       "        [ 0.0723],\n",
       "        [ 0.1369],\n",
       "        [ 0.0368],\n",
       "        [ 0.0800],\n",
       "        [ 0.0376],\n",
       "        [ 0.1136],\n",
       "        [ 0.0787],\n",
       "        [ 0.1046],\n",
       "        [ 0.1035],\n",
       "        [ 0.0623],\n",
       "        [ 0.0843],\n",
       "        [ 0.0298],\n",
       "        [ 0.0517],\n",
       "        [ 0.0780],\n",
       "        [ 0.0770],\n",
       "        [ 0.0402],\n",
       "        [ 0.0933],\n",
       "        [ 0.0861],\n",
       "        [ 0.1010],\n",
       "        [ 0.1116],\n",
       "        [ 0.0698],\n",
       "        [ 0.0177],\n",
       "        [ 0.0677],\n",
       "        [ 0.0553],\n",
       "        [ 0.0571],\n",
       "        [ 0.1564],\n",
       "        [ 0.0291],\n",
       "        [ 0.0460],\n",
       "        [ 0.1289],\n",
       "        [ 0.0576],\n",
       "        [ 0.0888],\n",
       "        [ 0.0351],\n",
       "        [ 0.0829],\n",
       "        [ 0.0786],\n",
       "        [ 0.0499],\n",
       "        [ 0.0458],\n",
       "        [ 0.1313],\n",
       "        [ 0.1299]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from fastcore.basics import patch\n",
    "import uuid\n",
    "import pdb\n",
    "import torch\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "device='cpu'\n",
    "\n",
    "class Genome:\n",
    "    def __init__(self, n_chr, n_loci):\n",
    "        self.ploidy = 2\n",
    "        self.n_chr = n_chr\n",
    "        self.n_loci = n_loci\n",
    "        self.shape = (self.ploidy, self.n_chr, self.n_loci)\n",
    "        \n",
    "class Population:\n",
    "    def __init__(self, genome, haplotypes, device=device):\n",
    "        self.genome = genome\n",
    "        self.device = device\n",
    "        self.phenotypes = None\n",
    "        self.bvs = None\n",
    "        self.haplotypes = haplotypes\n",
    "        self.dosages = haplotypes.sum(dim=1).float()\n",
    "        self.size = haplotypes.shape[0]\n",
    "                \n",
    "class Trait:\n",
    "    def __init__(self, genome, founder_population, target_mean, target_variance, device=device):\n",
    "        self.target_mean = target_mean\n",
    "        self.target_variance = target_variance\n",
    "        self.device = device\n",
    "        random_effects = torch.randn(genome.n_chr, genome.n_loci, device=self.device)\n",
    "        random_effects -= random_effects.mean()\n",
    "        founder_scores = torch.einsum('kl,hkl->h', random_effects, founder_population.dosages)\n",
    "        founder_mean, founder_var = founder_scores.mean(), founder_scores.var()\n",
    "        scaling_factors = torch.sqrt(self.target_variance / founder_var)\n",
    "        self.scaling_factors = scaling_factors\n",
    "        random_effects *= scaling_factors\n",
    "        self.effects = random_effects\n",
    "        self.intercept = founder_mean - target_mean\n",
    "\n",
    "        \n",
    "def calculate_breeding_value(population_dosages, trait_effects, device = device):\n",
    "    return torch.einsum('hjk,jk->h', population_dosages,trait_effects)\n",
    "\n",
    "def truncation_selection(population, trait, top_percent):\n",
    "    return torch.topk(population.phenotypes, top_percent).indices\n",
    "\n",
    "# meiosis\n",
    "def recombine(parent_haplo_tensor, recombination_rate=0.1):\n",
    "    num_individuals, ploidy, num_chromosomes, num_loci = parent_haplo_tensor.shape    \n",
    "    # Generate crossover masks\n",
    "    maternal, paternal = parent_haplo_tensor[:,0,:,:],parent_haplo_tensor[:,1,:,:],\n",
    "    crossovers = torch.bernoulli(torch.full((num_individuals, num_chromosomes, num_loci), recombination_rate, device=device))\n",
    "    #crossovers = torch.rand((num_individuals, num_chromosomes, num_loci), device=device) < recombination_rate\n",
    "    progeny = maternal * (1 - crossovers) + paternal * crossovers\n",
    "    return progeny\n",
    "\n",
    "\n",
    "def phenotype(population, trait, h2):\n",
    "    breeding_values = calculate_breeding_value(population.dosages, trait.effects) \n",
    "    \n",
    "    if breeding_values.var() == 0:\n",
    "#         print('phenotype: no var')\n",
    "        environmental_variance = 0  \n",
    "    else:\n",
    "        environmental_variance = (1 - h2) / h2 * breeding_values.var() \n",
    "    \n",
    "    # Check if environmental_variance is zero before applying torch.sqrt and .clone()\n",
    "    if environmental_variance == 0:\n",
    "        environmental_noise = torch.zeros(breeding_values.shape, device=device)\n",
    "    else:\n",
    "        environmental_noise = torch.randn(breeding_values.shape, device=device) * torch.sqrt(environmental_variance).detach()\n",
    "    \n",
    "    population.breeding_values = breeding_values\n",
    "    population.phenotypes = breeding_values + environmental_noise\n",
    "#     def _create_random_haplotypes(self,num_individuals):\n",
    "#         return torch.randint(0, 2, (num_individuals, *self.g.shape), device=self.device)\n",
    "def create_random_pop(G, pop_size):\n",
    "    return torch.randint(0, 2, (pop_size, *G.shape), device= device)\n",
    "\n",
    "def update_pop(population, haplotype_pop_tensor):\n",
    "    population.haplotypes = haplotype_pop_tensor\n",
    "    population.dosages = haplotype_pop_tensor.sum(dim=1).float()\n",
    "    return population\n",
    "\n",
    "# meiosis\n",
    "def recombine(parent_haplo_tensor, recombination_rate=0.1):\n",
    "    num_individuals, ploidy, num_chromosomes, num_loci = parent_haplo_tensor.shape\n",
    "    # Generate crossover masks\n",
    "    maternal, paternal = parent_haplo_tensor[:,0,:,:],parent_haplo_tensor[:,1,:,:],\n",
    "    crossovers = torch.bernoulli(torch.full((num_individuals, num_chromosomes, num_loci), recombination_rate, device=device))\n",
    "#     crossovers = torch.rand((num_individuals, num_chromosomes, num_loci), device=device) < recombination_rate\n",
    "    progeny = maternal * torch.logical_not(crossovers) + paternal * crossovers\n",
    "    return progeny\n",
    "\n",
    "def breed(mother_tensor, father_tensor, recombination_rate=0.1):\n",
    "    eggs = recombine(mother_tensor,recombination_rate)\n",
    "    pollens = recombine(father_tensor,recombination_rate)\n",
    "    return torch.stack((eggs,pollens), dim=1)\n",
    "\n",
    "def create_pop(G, haplotypes):\n",
    "    return Population(G, haplotypes=haplotypes)\n",
    "\n",
    "def bv(P,T):\n",
    "    P.breeding_values = calculate_breeding_value(P.dosages,T.effects)\n",
    "    \n",
    "def create_progeny(mother_gametes, father_gametes,reps = 1):\n",
    "    progeny = []\n",
    "    for _ in range(reps):\n",
    "        # Randomly shuffle the gametes from each parent \n",
    "        shuffled_mother_indices = torch.randperm(mother_gametes.shape[0])\n",
    "        shuffled_father_indices = torch.randperm(father_gametes.shape[0])\n",
    "\n",
    "        # Select the shuffled gametes\n",
    "        mother_gametes = mother_gametes[shuffled_mother_indices]\n",
    "        father_gametes = father_gametes[shuffled_father_indices]\n",
    "\n",
    "        # Stack the gametes to create progeny haplotypes\n",
    "        progeny_haplotypes = torch.stack((mother_gametes, father_gametes),dim=1)\n",
    "        progeny.append(progeny_haplotypes)\n",
    "    return torch.vstack(progeny)\n",
    "    \n",
    "\n",
    "class BreedingEnvironment:\n",
    "    def __init__(self, G, T, h2, reps, pop_size, max_generations=10, variance_threshold=1e-6):\n",
    "        self.G = G\n",
    "        self.T = T\n",
    "        self.h2 = h2\n",
    "        self.reps = reps\n",
    "        self.pop_size = pop_size\n",
    "        self.max_generations = max_generations\n",
    "        self.variance_threshold = variance_threshold\n",
    "\n",
    "        # Create and store the initial population\n",
    "        self.initial_haplotypes = create_random_pop(G, pop_size)\n",
    "        self.initial_population = create_pop(G, self.initial_haplotypes)\n",
    "        phenotype(self.initial_population, self.T, self.h2)\n",
    "        \n",
    "        # Initialize current population\n",
    "        self.population = self.initial_population\n",
    "        self.history = []\n",
    "        self.current_generation = 0\n",
    "        \n",
    "    def step(self, selection_scores):\n",
    "        # Log current population\n",
    "        current_state = self.get_state()\n",
    "\n",
    "        # Select parents based on actions\n",
    "        selected_parent_indices = self.select_parents(actions)\n",
    "        selected = self.population.haplotypes[selected_parent_indices]\n",
    "\n",
    "        # Breeding\n",
    "        m = recombine(selected)  # Mother gametes\n",
    "        f = recombine(selected)  # Father gametes\n",
    "        progeny = create_progeny(m, f, reps=action2[actions])  # Create progeny\n",
    "\n",
    "        # Create new population from progeny\n",
    "        new_pop = create_pop(self.G, progeny)\n",
    "        phenotype(new_pop, self.T, self.h2)\n",
    "\n",
    "        # Switch current population to progeny population\n",
    "        self.population = new_pop\n",
    "        # Check if episode is done\n",
    "        done = self.is_done()\n",
    "        # Calculate reward only if the episode is done\n",
    "        reward = self.calculate_reward() if self.is_done() else 0\n",
    "        reward = self.calculate_reward()\n",
    "#         print(self.population.phenotypes.var())\n",
    "        # Get new state\n",
    "        new_state = self.get_state()\n",
    "\n",
    "        # Increment generation counter\n",
    "        self.current_generation += 1\n",
    "        return new_state, reward, done\n",
    "\n",
    "    def select_parents(self, selection_scores):\n",
    "        k = int(self.pop_size * 0.1)  # Select top 10% as in the paper\n",
    "        parents = torch.topk(selection_scores, k).indices\n",
    "        return parents\n",
    "    \n",
    "\n",
    "    def calculate_reward(self):\n",
    "        if self.current_generation == self.max_generations - 1:\n",
    "            return self.population.phenotypes.max()\n",
    "        return 0\n",
    "    \n",
    "    def is_done(self):\n",
    "        return self.current_generation >= self.max_generations\n",
    "\n",
    "    def reset(self):\n",
    "        # Reset to the initial population\n",
    "        self.population = create_pop(self.G, self.initial_haplotypes.clone())\n",
    "        phenotype(self.population, self.T, self.h2)\n",
    "        self.history = []\n",
    "        self.current_generation = 0\n",
    "        return self.get_state()\n",
    "    \n",
    "    def get_state(self):\n",
    "        generation_progress = self.current_generation / self.max_generations\n",
    "        return self.population.haplotypes, generation_progress\n",
    "\n",
    "    \n",
    "    # Neural Network\n",
    "class BreedingNetwork(nn.Module):\n",
    "    def __init__(self, genotype_size, hidden_size=64):\n",
    "        super(BreedingNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(genotype_size + 1, hidden_size)  # +1 for generation %\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, genotype, generation_percent):\n",
    "        generation_percent = torch.ones(genotype.shape[0])*generation_percent\n",
    "        x = torch.cat([genotype, generation_percent.unsqueeze(1)], dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "class PPOAgent:\n",
    "    def __init__(self, state_dim, action_dim, hidden_dim=64, lr=3e-4, gamma=0.99, epsilon=0.2, value_coef=0.5, entropy_coef=0.01):\n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(state_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, action_dim),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(state_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        self.optimizer = optim.Adam(list(self.actor.parameters()) + list(self.critic.parameters()), lr=lr)\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.value_coef = value_coef\n",
    "        self.entropy_coef = entropy_coef\n",
    "\n",
    "    def get_action(self, state):\n",
    "        probs = self.actor(state)\n",
    "        action = torch.multinomial(probs, 1)\n",
    "        return action.item(), probs[0, action.item()].item()\n",
    "\n",
    "    def update(self, states, actions, old_probs, rewards, next_states, dones):\n",
    "        states = torch.FloatTensor(states)\n",
    "        actions = torch.LongTensor(actions)\n",
    "        old_probs = torch.FloatTensor(old_probs)\n",
    "        rewards = torch.FloatTensor(rewards)\n",
    "        next_states = torch.FloatTensor(next_states)\n",
    "        dones = torch.FloatTensor(dones)\n",
    "\n",
    "        # Compute advantages\n",
    "        values = self.critic(states).squeeze()\n",
    "        next_values = self.critic(next_states).squeeze()\n",
    "        advantages = rewards + self.gamma * next_values * (1 - dones) - values\n",
    "\n",
    "        # Compute actor loss\n",
    "        new_probs = self.actor(states)\n",
    "        new_probs = new_probs.gather(1, actions.unsqueeze(1)).squeeze()\n",
    "        ratio = new_probs / old_probs\n",
    "        surr1 = ratio * advantages\n",
    "        surr2 = torch.clamp(ratio, 1 - self.epsilon, 1 + self.epsilon) * advantages\n",
    "        actor_loss = -torch.min(surr1, surr2).mean()\n",
    "\n",
    "        # Compute critic loss\n",
    "        critic_loss = (rewards + self.gamma * next_values * (1 - dones) - values).pow(2).mean()\n",
    "\n",
    "        # Compute entropy bonus\n",
    "        entropy = -(new_probs * torch.log(new_probs)).mean()\n",
    "\n",
    "        # Total loss\n",
    "        loss = actor_loss + self.value_coef * critic_loss - self.entropy_coef * entropy\n",
    "\n",
    "        # Update networks\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss.item()\n",
    "    \n",
    "n_chr = 1\n",
    "n_loci = 500\n",
    "founder_pop_size = 200\n",
    "\n",
    "G = Genome(n_chr, n_loci)\n",
    "founder_pop = create_pop(G, create_random_pop(G, founder_pop_size))\n",
    "T = Trait(G, founder_pop, target_mean=0.0, target_variance=1.0)\n",
    "\n",
    "\n",
    "sim = BreedingEnvironment(G,T,h2=.5,reps=1,pop_size=founder_pop_size)\n",
    "net = BreedingNetwork(n_loci*n_chr*2)\n",
    "\n",
    "input_net = sim.population.haplotypes.view(founder_pop_size, n_loci*n_chr*2)\n",
    "#example input\n",
    "net(input_net,  0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1280b02b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
