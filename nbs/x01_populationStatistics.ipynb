{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7570e93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x01_populationStatistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "442521b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from chewc.chewc import *\n",
    "# import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8216cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "436d0bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from fastcore.basics import patch\n",
    "import uuid\n",
    "import pdb\n",
    "import torch\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "device='cpu'\n",
    "\n",
    "class Genome:\n",
    "    def __init__(self, n_chr, n_loci):\n",
    "        self.ploidy = 2\n",
    "        self.n_chr = n_chr\n",
    "        self.n_loci = n_loci\n",
    "        self.shape = (self.ploidy, self.n_chr, self.n_loci)\n",
    "        \n",
    "class Population:\n",
    "    def __init__(self, genome, haplotypes, device=device):\n",
    "        self.genome = genome\n",
    "        self.device = device\n",
    "        self.phenotypes = None\n",
    "        self.bvs = None\n",
    "        self.haplotypes = haplotypes\n",
    "        self.dosages = haplotypes.sum(dim=1).float()\n",
    "        self.size = haplotypes.shape[0]\n",
    "                \n",
    "class Trait:\n",
    "    def __init__(self, genome, founder_population, target_mean, target_variance, device=device):\n",
    "        self.target_mean = target_mean\n",
    "        self.target_variance = target_variance\n",
    "        self.device = device\n",
    "        random_effects = torch.randn(genome.n_chr, genome.n_loci, device=self.device)\n",
    "        random_effects -= random_effects.mean()\n",
    "        founder_scores = torch.einsum('kl,hkl->h', random_effects, founder_population.dosages)\n",
    "        founder_mean, founder_var = founder_scores.mean(), founder_scores.var()\n",
    "        scaling_factors = torch.sqrt(self.target_variance / founder_var)\n",
    "        self.scaling_factors = scaling_factors\n",
    "        random_effects *= scaling_factors\n",
    "        self.effects = random_effects\n",
    "        self.intercept = founder_mean - target_mean\n",
    "\n",
    "        \n",
    "def calculate_breeding_value(population_dosages, trait_effects, device = device):\n",
    "    return torch.einsum('hjk,jk->h', population_dosages,trait_effects)\n",
    "\n",
    "def truncation_selection(population, trait, top_percent):\n",
    "    return torch.topk(population.phenotypes, top_percent).indices\n",
    "\n",
    "# meiosis\n",
    "def recombine(parent_haplo_tensor, recombination_rate=0.1):\n",
    "    num_individuals, ploidy, num_chromosomes, num_loci = parent_haplo_tensor.shape    \n",
    "    # Generate crossover masks\n",
    "    maternal, paternal = parent_haplo_tensor[:,0,:,:],parent_haplo_tensor[:,1,:,:],\n",
    "    crossovers = torch.bernoulli(torch.full((num_individuals, num_chromosomes, num_loci), recombination_rate, device=device))\n",
    "    #crossovers = torch.rand((num_individuals, num_chromosomes, num_loci), device=device) < recombination_rate\n",
    "    progeny = maternal * (1 - crossovers) + paternal * crossovers\n",
    "    return progeny\n",
    "\n",
    "\n",
    "def phenotype(population, trait, h2):\n",
    "    breeding_values = calculate_breeding_value(population.dosages, trait.effects) \n",
    "    \n",
    "    if breeding_values.var() == 0:\n",
    "        print('phenotype: no var')\n",
    "        environmental_variance = 0  \n",
    "    else:\n",
    "        environmental_variance = (1 - h2) / h2 * breeding_values.var() \n",
    "    \n",
    "    # Check if environmental_variance is zero before applying torch.sqrt and .clone()\n",
    "    if environmental_variance == 0:\n",
    "        environmental_noise = torch.zeros(breeding_values.shape, device=device)\n",
    "    else:\n",
    "        environmental_noise = torch.randn(breeding_values.shape, device=device) * torch.sqrt(environmental_variance).detach()\n",
    "    \n",
    "    population.breeding_values = breeding_values\n",
    "    population.phenotypes = breeding_values + environmental_noise\n",
    "#     def _create_random_haplotypes(self,num_individuals):\n",
    "#         return torch.randint(0, 2, (num_individuals, *self.g.shape), device=self.device)\n",
    "def create_random_pop(G, pop_size):\n",
    "    return torch.randint(0, 2, (pop_size, *G.shape), device= device)\n",
    "\n",
    "def update_pop(population, haplotype_pop_tensor):\n",
    "    population.haplotypes = haplotype_pop_tensor\n",
    "    population.dosages = haplotype_pop_tensor.sum(dim=1).float()\n",
    "    return population\n",
    "\n",
    "# meiosis\n",
    "def recombine(parent_haplo_tensor, recombination_rate=0.1):\n",
    "    num_individuals, ploidy, num_chromosomes, num_loci = parent_haplo_tensor.shape\n",
    "    # Generate crossover masks\n",
    "    maternal, paternal = parent_haplo_tensor[:,0,:,:],parent_haplo_tensor[:,1,:,:],\n",
    "    crossovers = torch.bernoulli(torch.full((num_individuals, num_chromosomes, num_loci), recombination_rate, device=device))\n",
    "#     crossovers = torch.rand((num_individuals, num_chromosomes, num_loci), device=device) < recombination_rate\n",
    "    progeny = maternal * torch.logical_not(crossovers) + paternal * crossovers\n",
    "    return progeny\n",
    "\n",
    "def breed(mother_tensor, father_tensor, recombination_rate=0.1):\n",
    "    eggs = recombine(mother_tensor,recombination_rate)\n",
    "    pollens = recombine(father_tensor,recombination_rate)\n",
    "    return torch.stack((eggs,pollens), dim=1)\n",
    "\n",
    "def create_pop(G, haplotypes):\n",
    "    return Population(G, haplotypes=haplotypes)\n",
    "\n",
    "def bv(P,T):\n",
    "    P.breeding_values = calculate_breeding_value(P.dosages,T.effects)\n",
    "    \n",
    "def create_progeny(mother_gametes, father_gametes,reps = 1):\n",
    "    progeny = []\n",
    "    for _ in range(reps):\n",
    "        # Randomly shuffle the gametes from each parent \n",
    "        shuffled_mother_indices = torch.randperm(mother_gametes.shape[0])\n",
    "        shuffled_father_indices = torch.randperm(father_gametes.shape[0])\n",
    "\n",
    "        # Select the shuffled gametes\n",
    "        mother_gametes = mother_gametes[shuffled_mother_indices]\n",
    "        father_gametes = father_gametes[shuffled_father_indices]\n",
    "\n",
    "        # Stack the gametes to create progeny haplotypes\n",
    "        progeny_haplotypes = torch.stack((mother_gametes, father_gametes),dim=1)\n",
    "        progeny.append(progeny_haplotypes)\n",
    "    return torch.vstack(progeny)\n",
    "\n",
    "\n",
    "class MyNetwork(nn.Module):\n",
    "    def __init__(self, L, P):\n",
    "        super(MyNetwork, self).__init__()\n",
    "        \n",
    "        # Layers for input1 and input3\n",
    "        self.fc1 = nn.Linear(L, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        \n",
    "        # Layers for input2\n",
    "        self.fc3 = nn.Linear(P, 128)\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        \n",
    "        # Layers for the upper triangle of input_matrix\n",
    "        self.fc_matrix = nn.Linear(L * (L + 1) // 2, 256)\n",
    "        \n",
    "        # Final fully connected layers\n",
    "        self.fc_final1 = nn.Linear(64 * 3 + 256, 64)\n",
    "        self.fc_final2 = nn.Linear(64, 5)  # Changed from 10 to 5 for a single choice with 5 values\n",
    "    \n",
    "    def forward(self, input1, input2, input3, input_matrix):\n",
    "        \n",
    "        # Process input1 and input3\n",
    "        x1 = F.relu(self.fc1(input1))\n",
    "        x1 = F.relu(self.fc2(x1))\n",
    "        \n",
    "        x3 = F.relu(self.fc1(input3))\n",
    "        x3 = F.relu(self.fc2(x3))\n",
    "        \n",
    "        # Process input2\n",
    "        x2 = F.relu(self.fc3(input2))\n",
    "        x2 = F.relu(self.fc4(x2))\n",
    "        \n",
    "        # Process input_matrix\n",
    "        indices = torch.triu_indices(input_matrix.size(1), input_matrix.size(2))\n",
    "        upper_triangle = input_matrix[:, indices[0], indices[1]]\n",
    "        x_matrix = F.relu(self.fc_matrix(upper_triangle))\n",
    "        \n",
    "        # Concatenate all features\n",
    "        x = torch.cat((x1, x2, x3, x_matrix), dim=1)\n",
    "        \n",
    "        # Final fully connected layers\n",
    "        x = F.relu(self.fc_final1(x))\n",
    "        output = self.fc_final2(x)\n",
    "        \n",
    "        # Apply softmax to get probabilities for the single choice with 5 values\n",
    "        output = F.softmax(output, dim=1)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    \n",
    "def population_statistics(population_tensor):\n",
    "\n",
    "    \n",
    "    #Calculate the mean genotype value divided by 2 for each marker.\n",
    "    def calculate_allele_frequencies(genotypes):\n",
    "        num_individuals = genotypes.size(0)\n",
    "        allele_frequencies = torch.mean(genotypes, dim=0) / 2.\n",
    "        return allele_frequencies\n",
    "    #Calculate the unique genotype counts and their frequencies.\n",
    "    def calculate_genotype_frequencies(genotypes):\n",
    "        num_individuals = genotypes.size(0)\n",
    "        unique_genotypes, counts = torch.unique(genotypes, dim=0, return_counts=True)\n",
    "        genotype_frequencies = counts.float() / num_individuals\n",
    "        return unique_genotypes, genotype_frequencies\n",
    "    #Calculate the proportion of heterozygous individuals at each marker.\n",
    "    def calculate_heterozygosity(genotypes):\n",
    "        num_individuals = genotypes.size(0)\n",
    "        heterozygosity = torch.sum(genotypes == 1, dim=0).float() / num_individuals\n",
    "        return heterozygosity\n",
    "    #Calculate the frequency of the less common allele.\n",
    "    def calculate_maf(genotypes):\n",
    "        allele_frequencies = calculate_allele_frequencies(genotypes)\n",
    "        maf = torch.minimum(allele_frequencies, 1 - allele_frequencies)\n",
    "        return maf\n",
    "    #Measure the degree of inbreeding based on observed and expected heterozygosity.\n",
    "    def calculate_inbreeding_coefficient(genotypes):\n",
    "        num_markers = genotypes.size(1)\n",
    "        observed_heterozygosity = torch.sum(genotypes == 1, dim=1).float() / num_markers\n",
    "        expected_heterozygosity = 2 * calculate_allele_frequencies(genotypes) * (1 - calculate_allele_frequencies(genotypes))\n",
    "        average_expected_heterozygosity = torch.mean(expected_heterozygosity)\n",
    "        inbreeding_coefficient = 1 - (observed_heterozygosity / average_expected_heterozygosity)\n",
    "        return inbreeding_coefficient\n",
    "    #Calculate the correlation matrix for the genotypes.\n",
    "    def calculate_ld(genotypes):\n",
    "        num_markers = genotypes.size(1)\n",
    "        ld_matrix = torch.corrcoef(genotypes.T)\n",
    "        return ld_matrix\n",
    "    #Measure the genetic differentiation between subpopulations.\n",
    "    def calculate_fst(genotypes, subpopulations):\n",
    "        total_allele_frequencies = calculate_allele_frequencies(genotypes)\n",
    "        subpop_allele_frequencies = [calculate_allele_frequencies(genotypes[subpop]) for subpop in subpopulations]\n",
    "        ht = 2 * total_allele_frequencies * (1 - total_allele_frequencies)\n",
    "        hs = torch.mean(torch.stack([2 * freq * (1 - freq) for freq in subpop_allele_frequencies]), dim=0)\n",
    "        fst = (ht - hs) / ht\n",
    "        return fst\n",
    "    #Estimate the effective population size based on allele frequencies and genetic drift.\n",
    "    def calculate_effective_population_size(genotypes):\n",
    "        num_individuals = genotypes.size(0)\n",
    "        allele_frequencies = calculate_allele_frequencies(genotypes)\n",
    "        variance = torch.var(allele_frequencies)\n",
    "        ne = (num_individuals - 1) / (2 * variance)\n",
    "        return ne\n",
    "\n",
    "    genotypes = population_tensor\n",
    "    stats = {\n",
    "        'allele_frequencies': calculate_allele_frequencies(genotypes),\n",
    "        'genotype_frequencies': calculate_genotype_frequencies(genotypes),\n",
    "        'heterozygosity': calculate_heterozygosity(genotypes),\n",
    "        'maf': calculate_maf(genotypes),\n",
    "        'inbreeding_coefficient': calculate_inbreeding_coefficient(genotypes),\n",
    "        'ld_matrix': calculate_ld(genotypes),\n",
    "        'effective_population_size': calculate_effective_population_size(genotypes)\n",
    "    }\n",
    "    return stats\n",
    "\n",
    "class BreedingSimulation:\n",
    "    def __init__(self, G, T, h2, reps, pop_size, max_generations=10, variance_threshold=1e-6):\n",
    "        self.G = G\n",
    "        self.T = T\n",
    "        self.h2 = h2\n",
    "        self.reps = reps\n",
    "        self.pop_size = pop_size\n",
    "        self.max_generations = max_generations\n",
    "        self.variance_threshold = variance_threshold\n",
    "\n",
    "        # Create and store the initial population\n",
    "        self.initial_haplotypes = create_random_pop(G, pop_size)\n",
    "        self.initial_population = create_pop(G, self.initial_haplotypes)\n",
    "        phenotype(self.initial_population, self.T, self.h2)\n",
    "\n",
    "        # Initialize current population\n",
    "        self.population = self.initial_population\n",
    "        self.history = []\n",
    "        self.current_generation = 0\n",
    "        \n",
    "    def step(self, actions):\n",
    "        # Log current population\n",
    "        current_state = self.get_state()\n",
    "        self.track_data(actions, self.calculate_reward())\n",
    "\n",
    "        # Select parents based on actions\n",
    "        selected_parent_indices = self.select_parents(actions)\n",
    "        selected = self.population.haplotypes[selected_parent_indices]\n",
    "\n",
    "        # Breeding\n",
    "        m = recombine(selected)  # Mother gametes\n",
    "        f = recombine(selected)  # Father gametes\n",
    "        progeny = create_progeny(m, f, reps=action2[torch.argmax(actions)])  # Create progeny\n",
    "\n",
    "        # Create new population from progeny\n",
    "        new_pop = create_pop(self.G, progeny)\n",
    "        phenotype(new_pop, self.T, self.h2)\n",
    "\n",
    "        # Switch current population to progeny population\n",
    "        self.population = new_pop\n",
    "\n",
    "        # Calculate reward based on new population\n",
    "        reward = self.calculate_reward()\n",
    "\n",
    "        # Get new state\n",
    "        new_state = self.get_state()\n",
    "        # Check if episode is done\n",
    "        done = self.is_done()\n",
    "\n",
    "        return new_state, reward, done\n",
    "\n",
    "    def select_parents(self, actions):\n",
    "        if self.population.phenotypes is None:\n",
    "            phenotype(self.population, self.T, self.h2)\n",
    "\n",
    "        parents = torch.topk(self.population.phenotypes, action1[torch.argmax(actions)]).indices\n",
    "        \n",
    "        return parents\n",
    "\n",
    "    def calculate_reward(self):\n",
    "        # Define how to calculate the reward based on your objective. \n",
    "        # Example: Improvement in average trait value\n",
    "        return self.population.phenotypes.mean()\n",
    "    \n",
    "    def is_done(self):\n",
    "        # Check if max generations reached or phenotypic variance is too low\n",
    "        if self.current_generation >= self.max_generations:\n",
    "            return True\n",
    "        if self.population.phenotypes.var() < self.variance_threshold:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def reset(self):\n",
    "        # Reset to the initial population\n",
    "        self.population = create_pop(self.G, self.initial_haplotypes.clone())\n",
    "        phenotype(self.population, self.T, self.h2)\n",
    "        self.history = []\n",
    "        self.current_generation = 0\n",
    "        return self.get_state()\n",
    "    \n",
    "    def get_state(self):\n",
    "        # Calculate population statistics here\n",
    "        n_ind, n_chr, n_loci = self.population.haplotypes.sum(dim=1).shape\n",
    "        pop_stat_in  = self.population.haplotypes.sum(dim=1).view((n_ind, n_chr* n_loci))\n",
    "        pop_stat = population_statistics(pop_stat_in.float())\n",
    "\n",
    "        # Create a dictionary to hold state features\n",
    "        state = {\n",
    "            'avg_phenotype': self.population.phenotypes.mean(),\n",
    "            'phenotype_variance': self.population.phenotypes.var(),\n",
    "            'avg_breeding_value': self.population.breeding_values.mean(),\n",
    "            'heterozygosity': pop_stat['heterozygosity'],\n",
    "#             'allele_frequencies': pop_stat['allele_frequencies'],\n",
    "            'maf': pop_stat['maf'], # Assuming your model uses the whole maf vector\n",
    "            'inbreeding_coefficient': pop_stat['inbreeding_coefficient'],\n",
    "            'ld_matrix': pop_stat['ld_matrix'],\n",
    "            'genotype_frequencies': pop_stat['genotype_frequencies'][1]\n",
    "            # Add any other relevant features from pop_stat\n",
    "        }\n",
    "        return state\n",
    "\n",
    "    def track_data(self, actions, reward):\n",
    "        # Reuse state features from get_state()\n",
    "        state = self.get_state()\n",
    "        gen_data = {\n",
    "            'generation': len(self.history),\n",
    "            'avg_phenotype': state['avg_phenotype'].item(),\n",
    "            'phenotype_variance': state['phenotype_variance'].item(),\n",
    "            'avg_breeding_value': state['avg_breeding_value'].item(),\n",
    "            'actions': actions,\n",
    "            'reward': reward.item(),\n",
    "            'n_ind': self.pop_size,  # Assuming 'n_ind' is calculated in get_state()\n",
    "            'heterozygosity': state['heterozygosity'].mean(),\n",
    "#             'allele_frequencies': state['allele_frequencies'].mean(),\n",
    "            'maf': state['maf'].mean().mean(),\n",
    "            'inbreeding_coefficient': state['inbreeding_coefficient'].mean().item(),\n",
    "            # ... include other items from pop_stat as needed ...\n",
    "        }\n",
    "        self.history.append(gen_data)\n",
    "\n",
    "    def plot_history(self):\n",
    "        def normalize(data):\n",
    "            min_val = min(data)\n",
    "            max_val = max(data)\n",
    "            return [(x - min_val) / (max_val - min_val) for x in data]\n",
    "        generations = [d['generation'] for d in self.history]\n",
    "        avg_phenotypes = [d['avg_phenotype'] for d in self.history]\n",
    "        actions = [d['maf'] for d in self.history]\n",
    "        \n",
    "        avg_phenotypes = normalize(avg_phenotypes)\n",
    "        actions = normalize(actions)\n",
    "        plt.plot(generations, avg_phenotypes)\n",
    "        plt.plot(generations, actions)\n",
    "        plt.xlabel('Generation')\n",
    "        plt.ylabel('Average Phenotype')\n",
    "        plt.title('Breeding Progress')\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "    \n",
    "class RLAgent:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def select_action(self,state):\n",
    "        # Example: Convert state to tensor and feed it to the model to get actions\n",
    "        \n",
    "        input1 = state['maf'].unsqueeze(0)\n",
    "        input2 = state['inbreeding_coefficient'].unsqueeze(0) \n",
    "        input3 = state['heterozygosity'].unsqueeze(0)\n",
    "#         input4 = state['genotype_frequencies'].unsqueeze(0)\n",
    "        input_matrix = state['ld_matrix'].unsqueeze(0)\n",
    "\n",
    "        actions = self.model(input1, input2, input3, input_matrix)\n",
    "        return actions\n",
    "    \n",
    "    \n",
    "    #initialize the settings\n",
    "n_chr = 5\n",
    "n_loci = 100\n",
    "founder_pop_size = 200\n",
    "\n",
    "G = Genome(n_chr, n_loci)\n",
    "founder_pop = create_pop(G, create_random_pop(G, founder_pop_size))\n",
    "T = Trait(G, founder_pop, target_mean=0.0, target_variance=1.0)\n",
    "\n",
    "sim = BreedingSimulation(G, T, h2=.99, reps=1, pop_size=founder_pop_size)\n",
    "\n",
    "model = MyNetwork(n_loci*n_chr, founder_pop_size)\n",
    "\n",
    "agent = RLAgent(model)\n",
    "\n",
    "# Define the actions\n",
    "action1 = [5, 10, 20, 50, 100] # top k\n",
    "action2 = [40, 20, 10, 4, 2] # number x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0725e9e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'avg_phenotype': tensor(3.0008),\n",
       "  'phenotype_variance': tensor(0.2779),\n",
       "  'avg_breeding_value': tensor(3.0025),\n",
       "  'heterozygosity': tensor([0.5100, 0.3400, 0.3800, 0.5100, 0.3000, 0.0000, 0.3700, 0.5100, 0.3800,\n",
       "          0.5900, 0.5900, 0.4000, 0.5200, 0.5900, 0.3800, 0.4600, 0.5100, 0.4600,\n",
       "          0.3400, 0.2000, 0.3000, 0.4800, 0.3000, 0.4700, 0.2000, 0.4900, 0.5100,\n",
       "          0.4200, 0.5200, 0.5100, 0.5200, 0.4800, 0.2000, 0.5100, 0.4200, 0.3000,\n",
       "          0.4800, 0.3000, 0.5900, 0.5000, 0.5000, 0.2000, 0.5100, 0.2000, 0.5300,\n",
       "          0.4200, 0.5200, 0.4900, 0.4700, 0.0000, 0.4000, 0.4800, 0.3400, 0.3800,\n",
       "          0.5000, 0.3000, 0.5200, 0.4800, 0.2000, 0.5200, 0.6000, 0.0000, 0.4900,\n",
       "          0.5200, 0.3800, 0.5200, 0.5900, 0.5100, 0.5100, 0.4200, 0.5000, 0.4900,\n",
       "          0.5600, 0.5100, 0.5900, 0.4900, 0.0000, 0.3400, 0.4800, 0.5100, 0.5900,\n",
       "          0.5200, 0.4500, 0.5200, 0.4300, 0.3400, 0.4700, 0.5000, 0.4000, 0.5300,\n",
       "          0.3800, 0.5700, 0.4800, 0.5100, 0.5300, 0.0000, 0.0000, 0.3200, 0.3800,\n",
       "          0.4200, 0.5000, 0.4400, 0.6100, 0.4600, 0.5000, 0.5600, 0.4900, 0.4800,\n",
       "          0.4700, 0.3400, 0.3300, 0.2000, 0.4600, 0.4800, 0.5000, 0.4200, 0.4700,\n",
       "          0.5200, 0.3800, 0.4700, 0.4200, 0.3200, 0.5000, 0.4700, 0.5900, 0.5300,\n",
       "          0.4300, 0.0000, 0.5900, 0.0000, 0.0000, 0.4900, 0.4600, 0.4800, 0.4600,\n",
       "          0.0000, 0.6700, 0.5500, 0.5100, 0.5900, 0.4900, 0.4700, 0.0000, 0.5200,\n",
       "          0.3700, 0.5700, 0.3700, 0.4800, 0.3800, 0.3000, 0.3400, 0.4400, 0.3000,\n",
       "          0.3200, 0.4800, 0.5100, 0.4900, 0.5100, 0.5100, 0.5200, 0.2000, 0.5200,\n",
       "          0.3200, 0.3400, 0.5200, 0.5200, 0.5900, 0.3700, 0.3000, 0.5100, 0.4200,\n",
       "          0.4500, 0.5300, 0.4900, 0.4700, 0.3400, 0.4500, 0.5500, 0.3800, 0.4700,\n",
       "          0.4800, 0.4200, 0.4800, 0.5900, 0.5100, 0.5900, 0.2000, 0.4700, 0.5100,\n",
       "          0.5100, 0.5500, 0.2000, 0.3400, 0.4600, 0.4900, 0.2000, 0.5900, 0.4700,\n",
       "          0.5900, 0.5100, 0.5100, 0.5200, 0.0000, 0.5600, 0.0000, 0.4800, 0.2000,\n",
       "          0.4200, 0.3000, 0.5900, 0.4600, 0.4400, 0.3800, 0.3400, 0.5000, 0.4400,\n",
       "          0.5100, 0.4800, 0.5900, 0.4700, 0.2000, 0.4600, 0.4700, 0.3400, 0.5900,\n",
       "          0.4600, 0.5300, 0.3800, 0.4900, 0.4500, 0.4800, 0.0000, 0.4700, 0.5500,\n",
       "          0.4400, 0.5700, 0.5200, 0.5000, 0.3700, 0.5000, 0.4900, 0.4900, 0.5900,\n",
       "          0.4700, 0.5100, 0.3700, 0.5800, 0.5100, 0.3800, 0.4800, 0.4700, 0.5000,\n",
       "          0.5800, 0.5100, 0.4700, 0.4900, 0.5900, 0.4600, 0.3400, 0.4200, 0.4700,\n",
       "          0.4800, 0.5000, 0.3700, 0.4000, 0.5900, 0.4600, 0.5000, 0.5200, 0.4800,\n",
       "          0.5900, 0.4700, 0.0000, 0.3400, 0.4900, 0.4800, 0.4700, 0.3800, 0.5800,\n",
       "          0.5000, 0.3700, 0.5300, 0.2000, 0.5000, 0.3200, 0.5900, 0.2000, 0.5300,\n",
       "          0.4800, 0.3800, 0.5900, 0.3000, 0.5100, 0.5900, 0.5100, 0.4800, 0.5000,\n",
       "          0.5200, 0.5900, 0.5000, 0.5200, 0.5100, 0.5100, 0.5100, 0.5600, 0.5200,\n",
       "          0.4800, 0.0000, 0.0000, 0.5100, 0.3400, 0.4800, 0.5900, 0.4800, 0.4800,\n",
       "          0.3700, 0.4800, 0.4400, 0.3400, 0.5200, 0.5000, 0.4800, 0.5900, 0.3400,\n",
       "          0.4700, 0.5000, 0.4900, 0.5100, 0.4000, 0.5700, 0.5200, 0.6000, 0.4700,\n",
       "          0.6100, 0.5700, 0.2000, 0.4700, 0.5000, 0.4900, 0.5900, 0.4400, 0.4800,\n",
       "          0.4700, 0.5100, 0.4700, 0.3200, 0.3400, 0.3400, 0.5000, 0.0000, 0.5800,\n",
       "          0.3400, 0.5200, 0.3400, 0.2800, 0.3000, 0.4800, 0.5100, 0.4800, 0.3000,\n",
       "          0.5000, 0.3000, 0.4700, 0.4000, 0.5100, 0.2000, 0.5900, 0.4100, 0.0000,\n",
       "          0.2000, 0.4700, 0.4900, 0.5900, 0.6000, 0.4800, 0.0000, 0.5300, 0.3400,\n",
       "          0.0000, 0.3000, 0.5700, 0.5900, 0.4700, 0.5000, 0.5000, 0.5500, 0.2600,\n",
       "          0.4800, 0.4000, 0.3000, 0.3000, 0.4700, 0.5000, 0.4800, 0.5000, 0.4700,\n",
       "          0.4800, 0.5900, 0.5000, 0.4600, 0.4100, 0.5100, 0.4700, 0.5200, 0.4700,\n",
       "          0.4300, 0.5300, 0.4700, 0.3200, 0.5100, 0.4700, 0.4800, 0.5900, 0.4700,\n",
       "          0.5100, 0.3200, 0.3000, 0.5900, 0.5900, 0.3800, 0.3700, 0.5900, 0.3200,\n",
       "          0.4700, 0.3000, 0.6000, 0.3000, 0.3200, 0.0000, 0.5600, 0.3400, 0.4700,\n",
       "          0.2000, 0.4600, 0.3200, 0.0000, 0.2000, 0.4700, 0.3800, 0.5900, 0.0000,\n",
       "          0.4600, 0.6000, 0.5700, 0.5100, 0.4900, 0.5000, 0.3200, 0.3800, 0.3000,\n",
       "          0.3800, 0.4100, 0.4900, 0.5300, 0.4400, 0.4700, 0.4800, 0.4000, 0.6000,\n",
       "          0.5200, 0.3000, 0.4900, 0.4700, 0.3000, 0.3700, 0.3400, 0.4300, 0.3800,\n",
       "          0.4400, 0.2000, 0.3000, 0.4300, 0.5200, 0.5900, 0.4900, 0.4700, 0.4700,\n",
       "          0.4000, 0.3700, 0.5500, 0.3700, 0.5200, 0.0000, 0.5900, 0.5100, 0.4200,\n",
       "          0.3700, 0.5200, 0.5900, 0.3400, 0.2000, 0.0000, 0.4800, 0.5000, 0.5200,\n",
       "          0.4200, 0.2000, 0.4800, 0.4900, 0.4000]),\n",
       "  'maf': tensor([0.4000, 0.2000, 0.2000, 0.4000, 0.2000, 0.0000, 0.2000, 0.4000, 0.2000,\n",
       "          0.4000, 0.4000, 0.3000, 0.3000, 0.4000, 0.2000, 0.4000, 0.5000, 0.3000,\n",
       "          0.2000, 0.1000, 0.2000, 0.3000, 0.2000, 0.4000, 0.1000, 0.4000, 0.4000,\n",
       "          0.3000, 0.4000, 0.4000, 0.4000, 0.4000, 0.1000, 0.4000, 0.3000, 0.2000,\n",
       "          0.3000, 0.2000, 0.4000, 0.4000, 0.4000, 0.1000, 0.3000, 0.1000, 0.5000,\n",
       "          0.3000, 0.4000, 0.5000, 0.4000, 0.0000, 0.3000, 0.4000, 0.2000, 0.2000,\n",
       "          0.4000, 0.2000, 0.5000, 0.4000, 0.1000, 0.4000, 0.5000, 0.0000, 0.4000,\n",
       "          0.4000, 0.2000, 0.4000, 0.4000, 0.4000, 0.4000, 0.3000, 0.4000, 0.5000,\n",
       "          0.4000, 0.4000, 0.4000, 0.4000, 0.0000, 0.2000, 0.3000, 0.4000, 0.4000,\n",
       "          0.5000, 0.3000, 0.4000, 0.3000, 0.2000, 0.4000, 0.4000, 0.2000, 0.5000,\n",
       "          0.2000, 0.5000, 0.4000, 0.4000, 0.5000, 0.0000, 0.0000, 0.2000, 0.2000,\n",
       "          0.4000, 0.3000, 0.3000, 0.5000, 0.3000, 0.4000, 0.5000, 0.4000, 0.5000,\n",
       "          0.4000, 0.2000, 0.2000, 0.1000, 0.3000, 0.4000, 0.4000, 0.3000, 0.4000,\n",
       "          0.4000, 0.2000, 0.4000, 0.3000, 0.2000, 0.4000, 0.4000, 0.4000, 0.5000,\n",
       "          0.3000, 0.0000, 0.4000, 0.0000, 0.0000, 0.4000, 0.3000, 0.4000, 0.3000,\n",
       "          0.0000, 0.5000, 0.5000, 0.4000, 0.4000, 0.4000, 0.4000, 0.0000, 0.4000,\n",
       "          0.2000, 0.5000, 0.2000, 0.3000, 0.2000, 0.2000, 0.2000, 0.3000, 0.2000,\n",
       "          0.2000, 0.4000, 0.4000, 0.4000, 0.5000, 0.5000, 0.4000, 0.1000, 0.5000,\n",
       "          0.2000, 0.2000, 0.3000, 0.4000, 0.4000, 0.2000, 0.2000, 0.4000, 0.3000,\n",
       "          0.4000, 0.5000, 0.4000, 0.4000, 0.2000, 0.3000, 0.5000, 0.2000, 0.4000,\n",
       "          0.4000, 0.3000, 0.4000, 0.4000, 0.4000, 0.4000, 0.1000, 0.4000, 0.4000,\n",
       "          0.4000, 0.5000, 0.1000, 0.2000, 0.4000, 0.4000, 0.1000, 0.4000, 0.3000,\n",
       "          0.4000, 0.4000, 0.4000, 0.4000, 0.0000, 0.4000, 0.0000, 0.4000, 0.1000,\n",
       "          0.3000, 0.2000, 0.4000, 0.3000, 0.3000, 0.2000, 0.2000, 0.4000, 0.3000,\n",
       "          0.3000, 0.4000, 0.4000, 0.4000, 0.1000, 0.4000, 0.4000, 0.2000, 0.4000,\n",
       "          0.3000, 0.5000, 0.2000, 0.4000, 0.3000, 0.5000, 0.0000, 0.4000, 0.5000,\n",
       "          0.3000, 0.5000, 0.3000, 0.4000, 0.2000, 0.4000, 0.4000, 0.4000, 0.4000,\n",
       "          0.3000, 0.4000, 0.2000, 0.4000, 0.4000, 0.2000, 0.4000, 0.4000, 0.4000,\n",
       "          0.5000, 0.3000, 0.4000, 0.4000, 0.4000, 0.3000, 0.2000, 0.4000, 0.4000,\n",
       "          0.5000, 0.4000, 0.2000, 0.2000, 0.4000, 0.3000, 0.4000, 0.4000, 0.3000,\n",
       "          0.4000, 0.4000, 0.0000, 0.2000, 0.4000, 0.4000, 0.4000, 0.2000, 0.4000,\n",
       "          0.4000, 0.2000, 0.5000, 0.1000, 0.4000, 0.2000, 0.4000, 0.1000, 0.5000,\n",
       "          0.3000, 0.2000, 0.4000, 0.2000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000,\n",
       "          0.4000, 0.4000, 0.4000, 0.5000, 0.4000, 0.5000, 0.4000, 0.5000, 0.4000,\n",
       "          0.4000, 0.0000, 0.0000, 0.4000, 0.2000, 0.4000, 0.4000, 0.4000, 0.4000,\n",
       "          0.2000, 0.3000, 0.3000, 0.2000, 0.5000, 0.4000, 0.4000, 0.4000, 0.2000,\n",
       "          0.4000, 0.4000, 0.4000, 0.4000, 0.3000, 0.5000, 0.4000, 0.5000, 0.4000,\n",
       "          0.5000, 0.4000, 0.1000, 0.4000, 0.4000, 0.4000, 0.4000, 0.3000, 0.3000,\n",
       "          0.4000, 0.4000, 0.4000, 0.2000, 0.2000, 0.2000, 0.4000, 0.0000, 0.5000,\n",
       "          0.2000, 0.4000, 0.2000, 0.2000, 0.2000, 0.4000, 0.4000, 0.4000, 0.2000,\n",
       "          0.4000, 0.2000, 0.4000, 0.2000, 0.4000, 0.1000, 0.4000, 0.3000, 0.0000,\n",
       "          0.1000, 0.4000, 0.4000, 0.4000, 0.5000, 0.3000, 0.0000, 0.5000, 0.2000,\n",
       "          0.0000, 0.2000, 0.5000, 0.4000, 0.4000, 0.4000, 0.4000, 0.5000, 0.2000,\n",
       "          0.4000, 0.2000, 0.2000, 0.2000, 0.3000, 0.4000, 0.4000, 0.4000, 0.3000,\n",
       "          0.4000, 0.4000, 0.4000, 0.3000, 0.3000, 0.4000, 0.4000, 0.4000, 0.3000,\n",
       "          0.3000, 0.5000, 0.4000, 0.2000, 0.5000, 0.4000, 0.4000, 0.4000, 0.3000,\n",
       "          0.4000, 0.2000, 0.2000, 0.4000, 0.4000, 0.2000, 0.2000, 0.4000, 0.2000,\n",
       "          0.3000, 0.2000, 0.5000, 0.2000, 0.2000, 0.0000, 0.5000, 0.2000, 0.3000,\n",
       "          0.1000, 0.3000, 0.2000, 0.0000, 0.1000, 0.4000, 0.2000, 0.4000, 0.0000,\n",
       "          0.3000, 0.5000, 0.5000, 0.4000, 0.4000, 0.4000, 0.2000, 0.2000, 0.2000,\n",
       "          0.2000, 0.3000, 0.4000, 0.5000, 0.3000, 0.3000, 0.5000, 0.2000, 0.5000,\n",
       "          0.4000, 0.2000, 0.4000, 0.4000, 0.2000, 0.2000, 0.2000, 0.3000, 0.2000,\n",
       "          0.3000, 0.1000, 0.2000, 0.3000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000,\n",
       "          0.3000, 0.2000, 0.5000, 0.2000, 0.3000, 0.0000, 0.4000, 0.4000, 0.3000,\n",
       "          0.2000, 0.5000, 0.4000, 0.2000, 0.1000, 0.0000, 0.4000, 0.4000, 0.3000,\n",
       "          0.3000, 0.1000, 0.4000, 0.4000, 0.3000]),\n",
       "  'inbreeding_coefficient': tensor([-0.2505, -0.1957, -0.1409, -0.3003, -0.2405, -0.1957, -0.2804, -0.2505,\n",
       "          -0.1957, -0.1957, -0.3003, -0.2804, -0.2505, -0.1907, -0.1658, -0.3003,\n",
       "          -0.2505, -0.1409, -0.1957, -0.2405, -0.2555,  0.7609, -0.1957, -0.2505,\n",
       "          -0.1409, -0.1957,  0.8754, -0.1907, -0.1010, -0.2405, -0.2405, -0.1957,\n",
       "           0.7708, -0.2156, -0.2405, -0.1907, -0.3003, -0.2405,  0.8754,  0.8007,\n",
       "           0.8754, -0.1658, -0.2555, -0.1409, -0.2555, -0.1957, -0.3551, -0.1957,\n",
       "          -0.2106, -0.2505, -0.2106, -0.1010, -0.2405, -0.2505, -0.3551,  0.8754,\n",
       "          -0.1957,  0.7708, -0.2106,  0.7609, -0.1409, -0.2106, -0.1957, -0.1658,\n",
       "          -0.2555, -0.2405, -0.2555,  0.7609, -0.2156, -0.1409, -0.1658, -0.2555,\n",
       "          -0.2405, -0.1957, -0.1409, -0.1957, -0.2505, -0.1409, -0.2555,  0.7609,\n",
       "          -0.3003, -0.2555, -0.1957, -0.2156, -0.1907, -0.2156, -0.2405, -0.2505,\n",
       "          -0.3003, -0.2106, -0.2106, -0.2505, -0.2405, -0.1010, -0.3551, -0.3003,\n",
       "           0.8754, -0.1658, -0.2106, -0.1907,  0.8754, -0.1658, -0.3003, -0.2106,\n",
       "          -0.1907, -0.2555, -0.2804, -0.1658, -0.1409, -0.1957, -0.1957, -0.3003,\n",
       "          -0.1957, -0.2804,  0.7708, -0.1957,  0.7609,  0.7708,  0.8754, -0.2106,\n",
       "          -0.2156, -0.2555, -0.3003, -0.1907, -0.1957,  0.7858, -0.2505, -0.2156,\n",
       "          -0.1957, -0.1957,  0.8007, -0.3003, -0.2555, -0.2804,  0.7708, -0.2405,\n",
       "          -0.2505, -0.2804, -0.3003,  0.8007, -0.2405, -0.1957, -0.2804,  0.7708,\n",
       "          -0.1658,  0.8754, -0.2405,  0.7708, -0.1957, -0.1957, -0.2156, -0.1907,\n",
       "          -0.3003, -0.1957, -0.2555,  0.8754, -0.1907, -0.1957, -0.1658, -0.2555,\n",
       "          -0.2555, -0.1957, -0.1957, -0.1409, -0.3003, -0.1409, -0.3003, -0.1957,\n",
       "          -0.2555, -0.3551, -0.2106, -0.1957, -0.1658, -0.2555, -0.1409, -0.2156,\n",
       "          -0.2405, -0.3003, -0.2505, -0.2106, -0.2106,  0.7609, -0.2156, -0.2405,\n",
       "           0.7708, -0.1957,  0.8754, -0.1010,  0.7858, -0.2505, -0.1907, -0.2156,\n",
       "          -0.2505, -0.3003, -0.2405, -0.1409, -0.2555, -0.3003, -0.1010, -0.2804]),\n",
       "  'ld_matrix': tensor([[ 1.0000,  0.3810, -0.3216,  ...,  0.1291,  0.6741,  0.4719],\n",
       "          [ 0.3810,  1.0000,  0.3402,  ...,  0.4348, -0.4261,  0.4129],\n",
       "          [-0.3216,  0.3402,  1.0000,  ..., -0.3538, -0.5864,  0.1774],\n",
       "          ...,\n",
       "          [ 0.1291,  0.4348, -0.3538,  ...,  1.0000, -0.2211,  0.4134],\n",
       "          [ 0.6741, -0.4261, -0.5864,  ..., -0.2211,  1.0000,  0.1319],\n",
       "          [ 0.4719,  0.4129,  0.1774,  ...,  0.4134,  0.1319,  1.0000]]),\n",
       "  'genotype_frequencies': tensor([0.0300, 0.0500, 0.0450, 0.0300, 0.0350, 0.0400, 0.0550, 0.0500, 0.0100,\n",
       "          0.0200, 0.0400, 0.0700, 0.0500, 0.0400, 0.0300, 0.0250, 0.0250, 0.0400,\n",
       "          0.0500, 0.0600, 0.0600, 0.0500, 0.0300, 0.0500, 0.0150])},\n",
       " tensor(3.0008),\n",
       " False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# single cycle - no phenotyping, going purely off rewards and population statistics\n",
    "# print(sim.population.size)\n",
    "selection = agent.select_action(sim.get_state())\n",
    "# Get the indices of the maximum values for each parameter\n",
    "action_values = torch.argmax(selection)\n",
    "# print(action_values)\n",
    "sim.step(action_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82f667a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 finished with reward: 41.43060302734375\n",
      "Episode 2 finished with reward: 51.226837158203125\n",
      "phenotype: no var\n",
      "Episode 3 finished with reward: 78.9163589477539\n",
      "Episode 4 finished with reward: 37.544559478759766\n",
      "Episode 5 finished with reward: 71.15979766845703\n",
      "Episode 6 finished with reward: 58.341835021972656\n",
      "Episode 7 finished with reward: 55.07215881347656\n",
      "phenotype: no var\n",
      "Episode 8 finished with reward: 46.20412063598633\n",
      "Episode 9 finished with reward: 44.45256042480469\n",
      "Episode 10 finished with reward: 38.45543670654297\n",
      "Episode 11 finished with reward: 45.51296615600586\n",
      "Episode 12 finished with reward: 46.6032600402832\n",
      "phenotype: no var\n",
      "Episode 13 finished with reward: 48.44721221923828\n",
      "Episode 14 finished with reward: 55.812503814697266\n",
      "Episode 15 finished with reward: 48.62456512451172\n",
      "Episode 16 finished with reward: 58.43301010131836\n",
      "phenotype: no var\n",
      "Episode 17 finished with reward: 74.50603485107422\n",
      "Episode 18 finished with reward: 51.048431396484375\n",
      "Episode 19 finished with reward: 54.69117736816406\n",
      "Episode 20 finished with reward: 40.22206497192383\n",
      "Episode 21 finished with reward: 63.840797424316406\n",
      "phenotype: no var\n",
      "Episode 22 finished with reward: 39.078208923339844\n",
      "Episode 23 finished with reward: 39.92033386230469\n",
      "phenotype: no var\n",
      "Episode 24 finished with reward: 39.728797912597656\n",
      "Episode 25 finished with reward: 44.893638610839844\n",
      "Episode 26 finished with reward: 38.18816375732422\n",
      "Episode 27 finished with reward: 53.12285232543945\n",
      "Episode 28 finished with reward: 48.514869689941406\n",
      "Episode 29 finished with reward: 49.917327880859375\n",
      "Episode 30 finished with reward: 52.42830276489258\n",
      "Episode 31 finished with reward: 65.91290283203125\n",
      "Episode 32 finished with reward: 40.738555908203125\n",
      "Episode 33 finished with reward: 45.0166130065918\n",
      "Episode 34 finished with reward: 54.70027160644531\n",
      "Episode 35 finished with reward: 81.90901184082031\n",
      "Episode 36 finished with reward: 51.90245819091797\n",
      "Episode 37 finished with reward: 70.17066955566406\n",
      "Episode 38 finished with reward: 63.188140869140625\n",
      "Episode 39 finished with reward: 64.6207046508789\n",
      "Episode 40 finished with reward: 47.732906341552734\n",
      "Episode 41 finished with reward: 41.67036437988281\n",
      "Episode 42 finished with reward: 38.21964645385742\n",
      "Episode 43 finished with reward: 48.33306884765625\n",
      "Episode 44 finished with reward: 49.94343948364258\n",
      "Episode 45 finished with reward: 48.28861999511719\n",
      "phenotype: no var\n",
      "Episode 46 finished with reward: 51.5044059753418\n",
      "Episode 47 finished with reward: 64.74910736083984\n",
      "Episode 48 finished with reward: 62.96154022216797\n",
      "Episode 49 finished with reward: 59.58588790893555\n",
      "Episode 50 finished with reward: 54.482540130615234\n",
      "Episode 51 finished with reward: 54.04044723510742\n",
      "Episode 52 finished with reward: 49.091453552246094\n",
      "Episode 53 finished with reward: 67.24847412109375\n",
      "Episode 54 finished with reward: 53.828857421875\n",
      "Episode 55 finished with reward: 43.668548583984375\n",
      "Episode 56 finished with reward: 63.66549301147461\n",
      "Episode 57 finished with reward: 38.43143081665039\n",
      "Episode 58 finished with reward: 40.80296325683594\n",
      "Episode 59 finished with reward: 43.39360046386719\n",
      "Episode 60 finished with reward: 55.899635314941406\n",
      "Episode 61 finished with reward: 64.99002075195312\n",
      "Episode 62 finished with reward: 79.15955352783203\n",
      "phenotype: no var\n",
      "Episode 63 finished with reward: 29.5582332611084\n",
      "Episode 64 finished with reward: 52.98282241821289\n",
      "Episode 65 finished with reward: 59.35806655883789\n",
      "phenotype: no var\n",
      "Episode 66 finished with reward: 63.38683319091797\n",
      "Episode 67 finished with reward: 36.335365295410156\n",
      "Episode 68 finished with reward: 53.20616912841797\n",
      "Episode 69 finished with reward: 35.67398452758789\n",
      "Episode 70 finished with reward: 66.64047241210938\n",
      "phenotype: no var\n",
      "Episode 71 finished with reward: 54.96553421020508\n",
      "Episode 72 finished with reward: 52.78085708618164\n",
      "Episode 73 finished with reward: 60.68743133544922\n",
      "phenotype: no var\n",
      "Episode 74 finished with reward: 52.6069450378418\n",
      "Episode 75 finished with reward: 35.876739501953125\n",
      "Episode 76 finished with reward: 52.655975341796875\n",
      "phenotype: no var\n",
      "Episode 77 finished with reward: 63.57143783569336\n",
      "Episode 78 finished with reward: 52.66689682006836\n",
      "phenotype: no var\n",
      "Episode 79 finished with reward: 35.601497650146484\n",
      "phenotype: no var\n",
      "Episode 80 finished with reward: 75.26034545898438\n",
      "phenotype: no var\n",
      "Episode 81 finished with reward: 40.81894302368164\n",
      "Episode 82 finished with reward: 41.75255584716797\n",
      "Episode 83 finished with reward: 57.42890167236328\n",
      "Episode 84 finished with reward: 57.461551666259766\n",
      "phenotype: no var\n",
      "Episode 85 finished with reward: 46.59638214111328\n",
      "Episode 86 finished with reward: 34.027103424072266\n",
      "phenotype: no var\n",
      "Episode 87 finished with reward: 46.78513717651367\n",
      "Episode 88 finished with reward: 47.6204719543457\n",
      "Episode 89 finished with reward: 43.37003707885742\n",
      "Episode 90 finished with reward: 42.8415412902832\n",
      "Episode 91 finished with reward: 42.71631622314453\n",
      "Episode 92 finished with reward: 45.89143753051758\n",
      "Episode 93 finished with reward: 46.87944793701172\n",
      "Episode 94 finished with reward: 69.41968536376953\n",
      "Episode 95 finished with reward: 76.73208618164062\n",
      "phenotype: no var\n",
      "Episode 96 finished with reward: 40.964561462402344\n",
      "Episode 97 finished with reward: 51.10784912109375\n",
      "Episode 98 finished with reward: 48.03031921386719\n",
      "phenotype: no var\n",
      "Episode 99 finished with reward: 42.194580078125\n",
      "Episode 100 finished with reward: 47.2534294128418\n"
     ]
    }
   ],
   "source": [
    "num_episodes=100\n",
    "# Training loop\n",
    "for episode in range(num_episodes):\n",
    "    state = sim.reset()\n",
    "    episode_reward = 0\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        action = agent.select_action(state)\n",
    "        next_state, reward, done = sim.step(action)\n",
    "        # Here you would update your agent (e.g., store experience, update Q-values)\n",
    "        episode_reward += reward\n",
    "        state = next_state\n",
    "    \n",
    "    print(f\"Episode {episode + 1} finished with reward: {episode_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1c6285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37ee39b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c64872b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
