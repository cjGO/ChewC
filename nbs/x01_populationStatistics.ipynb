{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7570e93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x01_populationStatistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "442521b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from chewc.chewc import *\n",
    "# import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8216cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "436d0bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from fastcore.basics import patch\n",
    "import uuid\n",
    "import pdb\n",
    "import torch\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "device='cpu'\n",
    "\n",
    "class Genome:\n",
    "    def __init__(self, n_chr, n_loci):\n",
    "        self.ploidy = 2\n",
    "        self.n_chr = n_chr\n",
    "        self.n_loci = n_loci\n",
    "        self.shape = (self.ploidy, self.n_chr, self.n_loci)\n",
    "        \n",
    "class Population:\n",
    "    def __init__(self, genome, haplotypes, device=device):\n",
    "        self.genome = genome\n",
    "        self.device = device\n",
    "        self.phenotypes = None\n",
    "        self.bvs = None\n",
    "        self.haplotypes = haplotypes\n",
    "        self.dosages = haplotypes.sum(dim=1).float()\n",
    "        self.size = haplotypes.shape[0]\n",
    "                \n",
    "class Trait:\n",
    "    def __init__(self, genome, founder_population, target_mean, target_variance, device=device):\n",
    "        self.target_mean = target_mean\n",
    "        self.target_variance = target_variance\n",
    "        self.device = device\n",
    "        random_effects = torch.randn(genome.n_chr, genome.n_loci, device=self.device)\n",
    "        random_effects -= random_effects.mean()\n",
    "        founder_scores = torch.einsum('kl,hkl->h', random_effects, founder_population.dosages)\n",
    "        founder_mean, founder_var = founder_scores.mean(), founder_scores.var()\n",
    "        scaling_factors = torch.sqrt(self.target_variance / founder_var)\n",
    "        self.scaling_factors = scaling_factors\n",
    "        random_effects *= scaling_factors\n",
    "        self.effects = random_effects\n",
    "        self.intercept = founder_mean - target_mean\n",
    "\n",
    "        \n",
    "def calculate_breeding_value(population_dosages, trait_effects, device = device):\n",
    "    return torch.einsum('hjk,jk->h', population_dosages,trait_effects)\n",
    "\n",
    "def truncation_selection(population, trait, top_percent):\n",
    "    return torch.topk(population.phenotypes, top_percent).indices\n",
    "\n",
    "# meiosis\n",
    "def recombine(parent_haplo_tensor, recombination_rate=0.1):\n",
    "    num_individuals, ploidy, num_chromosomes, num_loci = parent_haplo_tensor.shape    \n",
    "    # Generate crossover masks\n",
    "    maternal, paternal = parent_haplo_tensor[:,0,:,:],parent_haplo_tensor[:,1,:,:],\n",
    "    crossovers = torch.bernoulli(torch.full((num_individuals, num_chromosomes, num_loci), recombination_rate, device=device))\n",
    "    #crossovers = torch.rand((num_individuals, num_chromosomes, num_loci), device=device) < recombination_rate\n",
    "    progeny = maternal * (1 - crossovers) + paternal * crossovers\n",
    "    return progeny\n",
    "\n",
    "\n",
    "def phenotype(population, trait, h2):\n",
    "    breeding_values = calculate_breeding_value(population.dosages, trait.effects) \n",
    "    \n",
    "    if breeding_values.var() == 0:\n",
    "        print('phenotype: no var')\n",
    "        environmental_variance = 0  \n",
    "    else:\n",
    "        environmental_variance = (1 - h2) / h2 * breeding_values.var() \n",
    "    \n",
    "    # Check if environmental_variance is zero before applying torch.sqrt and .clone()\n",
    "    if environmental_variance == 0:\n",
    "        environmental_noise = torch.zeros(breeding_values.shape, device=device)\n",
    "    else:\n",
    "        environmental_noise = torch.randn(breeding_values.shape, device=device) * torch.sqrt(environmental_variance).detach()\n",
    "    \n",
    "    population.breeding_values = breeding_values\n",
    "    population.phenotypes = breeding_values + environmental_noise\n",
    "#     def _create_random_haplotypes(self,num_individuals):\n",
    "#         return torch.randint(0, 2, (num_individuals, *self.g.shape), device=self.device)\n",
    "def create_random_pop(G, pop_size):\n",
    "    return torch.randint(0, 2, (pop_size, *G.shape), device= device)\n",
    "\n",
    "def update_pop(population, haplotype_pop_tensor):\n",
    "    population.haplotypes = haplotype_pop_tensor\n",
    "    population.dosages = haplotype_pop_tensor.sum(dim=1).float()\n",
    "    return population\n",
    "\n",
    "# meiosis\n",
    "def recombine(parent_haplo_tensor, recombination_rate=0.1):\n",
    "    num_individuals, ploidy, num_chromosomes, num_loci = parent_haplo_tensor.shape\n",
    "    # Generate crossover masks\n",
    "    maternal, paternal = parent_haplo_tensor[:,0,:,:],parent_haplo_tensor[:,1,:,:],\n",
    "    crossovers = torch.bernoulli(torch.full((num_individuals, num_chromosomes, num_loci), recombination_rate, device=device))\n",
    "#     crossovers = torch.rand((num_individuals, num_chromosomes, num_loci), device=device) < recombination_rate\n",
    "    progeny = maternal * torch.logical_not(crossovers) + paternal * crossovers\n",
    "    return progeny\n",
    "\n",
    "def breed(mother_tensor, father_tensor, recombination_rate=0.1):\n",
    "    eggs = recombine(mother_tensor,recombination_rate)\n",
    "    pollens = recombine(father_tensor,recombination_rate)\n",
    "    return torch.stack((eggs,pollens), dim=1)\n",
    "\n",
    "def create_pop(G, haplotypes):\n",
    "    return Population(G, haplotypes=haplotypes)\n",
    "\n",
    "def bv(P,T):\n",
    "    P.breeding_values = calculate_breeding_value(P.dosages,T.effects)\n",
    "    \n",
    "def create_progeny(mother_gametes, father_gametes,reps = 1):\n",
    "    progeny = []\n",
    "    for _ in range(reps):\n",
    "        # Randomly shuffle the gametes from each parent \n",
    "        shuffled_mother_indices = torch.randperm(mother_gametes.shape[0])\n",
    "        shuffled_father_indices = torch.randperm(father_gametes.shape[0])\n",
    "\n",
    "        # Select the shuffled gametes\n",
    "        mother_gametes = mother_gametes[shuffled_mother_indices]\n",
    "        father_gametes = father_gametes[shuffled_father_indices]\n",
    "\n",
    "        # Stack the gametes to create progeny haplotypes\n",
    "        progeny_haplotypes = torch.stack((mother_gametes, father_gametes),dim=1)\n",
    "        progeny.append(progeny_haplotypes)\n",
    "    return torch.vstack(progeny)\n",
    "\n",
    "\n",
    "class MyNetwork(nn.Module):\n",
    "    def __init__(self, L, P):\n",
    "        super(MyNetwork, self).__init__()\n",
    "        \n",
    "        # Layers for input1 and input3\n",
    "        self.fc1 = nn.Linear(L, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        \n",
    "        # Layers for input2\n",
    "        self.fc3 = nn.Linear(P, 128)\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        \n",
    "        # Layers for the upper triangle of input_matrix\n",
    "        self.fc_matrix = nn.Linear(L * (L + 1) // 2, 256)\n",
    "        \n",
    "        # Final fully connected layers\n",
    "        self.fc_final1 = nn.Linear(64 * 3 + 256, 64)\n",
    "        self.fc_final2 = nn.Linear(64, 5)  # Changed from 10 to 5 for a single choice with 5 values\n",
    "    \n",
    "    def forward(self, input1, input2, input3, input_matrix):\n",
    "        \n",
    "        # Process input1 and input3\n",
    "        x1 = F.relu(self.fc1(input1))\n",
    "        x1 = F.relu(self.fc2(x1))\n",
    "        \n",
    "        x3 = F.relu(self.fc1(input3))\n",
    "        x3 = F.relu(self.fc2(x3))\n",
    "        \n",
    "        # Process input2\n",
    "        x2 = F.relu(self.fc3(input2))\n",
    "        x2 = F.relu(self.fc4(x2))\n",
    "        \n",
    "        # Process input_matrix\n",
    "        indices = torch.triu_indices(input_matrix.size(1), input_matrix.size(2))\n",
    "        upper_triangle = input_matrix[:, indices[0], indices[1]]\n",
    "        x_matrix = F.relu(self.fc_matrix(upper_triangle))\n",
    "        \n",
    "        # Concatenate all features\n",
    "        x = torch.cat((x1, x2, x3, x_matrix), dim=1)\n",
    "        \n",
    "        # Final fully connected layers\n",
    "        x = F.relu(self.fc_final1(x))\n",
    "        output = self.fc_final2(x)\n",
    "        \n",
    "        # Apply softmax to get probabilities for the single choice with 5 values\n",
    "        output = F.softmax(output, dim=1)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    \n",
    "def population_statistics(population_tensor):\n",
    "\n",
    "    \n",
    "    #Calculate the mean genotype value divided by 2 for each marker.\n",
    "    def calculate_allele_frequencies(genotypes):\n",
    "        num_individuals = genotypes.size(0)\n",
    "        allele_frequencies = torch.mean(genotypes, dim=0) / 2.\n",
    "        return allele_frequencies\n",
    "    #Calculate the unique genotype counts and their frequencies.\n",
    "    def calculate_genotype_frequencies(genotypes):\n",
    "        num_individuals = genotypes.size(0)\n",
    "        unique_genotypes, counts = torch.unique(genotypes, dim=0, return_counts=True)\n",
    "        genotype_frequencies = counts.float() / num_individuals\n",
    "        return unique_genotypes, genotype_frequencies\n",
    "    #Calculate the proportion of heterozygous individuals at each marker.\n",
    "    def calculate_heterozygosity(genotypes):\n",
    "        num_individuals = genotypes.size(0)\n",
    "        heterozygosity = torch.sum(genotypes == 1, dim=0).float() / num_individuals\n",
    "        return heterozygosity\n",
    "    #Calculate the frequency of the less common allele.\n",
    "    def calculate_maf(genotypes):\n",
    "        allele_frequencies = calculate_allele_frequencies(genotypes)\n",
    "        maf = torch.minimum(allele_frequencies, 1 - allele_frequencies)\n",
    "        return maf\n",
    "    #Measure the degree of inbreeding based on observed and expected heterozygosity.\n",
    "    def calculate_inbreeding_coefficient(genotypes):\n",
    "        num_markers = genotypes.size(1)\n",
    "        observed_heterozygosity = torch.sum(genotypes == 1, dim=1).float() / num_markers\n",
    "        expected_heterozygosity = 2 * calculate_allele_frequencies(genotypes) * (1 - calculate_allele_frequencies(genotypes))\n",
    "        average_expected_heterozygosity = torch.mean(expected_heterozygosity)\n",
    "        inbreeding_coefficient = 1 - (observed_heterozygosity / average_expected_heterozygosity)\n",
    "        return inbreeding_coefficient\n",
    "    #Calculate the correlation matrix for the genotypes.\n",
    "    def calculate_ld(genotypes):\n",
    "        num_markers = genotypes.size(1)\n",
    "        ld_matrix = torch.corrcoef(genotypes.T)\n",
    "        return ld_matrix\n",
    "    #Measure the genetic differentiation between subpopulations.\n",
    "    def calculate_fst(genotypes, subpopulations):\n",
    "        total_allele_frequencies = calculate_allele_frequencies(genotypes)\n",
    "        subpop_allele_frequencies = [calculate_allele_frequencies(genotypes[subpop]) for subpop in subpopulations]\n",
    "        ht = 2 * total_allele_frequencies * (1 - total_allele_frequencies)\n",
    "        hs = torch.mean(torch.stack([2 * freq * (1 - freq) for freq in subpop_allele_frequencies]), dim=0)\n",
    "        fst = (ht - hs) / ht\n",
    "        return fst\n",
    "    #Estimate the effective population size based on allele frequencies and genetic drift.\n",
    "    def calculate_effective_population_size(genotypes):\n",
    "        num_individuals = genotypes.size(0)\n",
    "        allele_frequencies = calculate_allele_frequencies(genotypes)\n",
    "        variance = torch.var(allele_frequencies)\n",
    "        ne = (num_individuals - 1) / (2 * variance)\n",
    "        return ne\n",
    "\n",
    "    genotypes = population_tensor\n",
    "    stats = {\n",
    "        'allele_frequencies': calculate_allele_frequencies(genotypes),\n",
    "        'genotype_frequencies': calculate_genotype_frequencies(genotypes),\n",
    "        'heterozygosity': calculate_heterozygosity(genotypes),\n",
    "        'maf': calculate_maf(genotypes),\n",
    "        'inbreeding_coefficient': calculate_inbreeding_coefficient(genotypes),\n",
    "        'ld_matrix': calculate_ld(genotypes),\n",
    "        'effective_population_size': calculate_effective_population_size(genotypes)\n",
    "    }\n",
    "    return stats\n",
    "\n",
    "class BreedingSimulation:\n",
    "    def __init__(self, G, T, h2, reps, pop_size, max_generations=10, variance_threshold=1e-6):\n",
    "        self.G = G\n",
    "        self.T = T\n",
    "        self.h2 = h2\n",
    "        self.reps = reps\n",
    "        self.pop_size = pop_size\n",
    "        self.population = create_pop(G, create_random_pop(G, pop_size))\n",
    "        self.history = []\n",
    "        self.population.phenotypes = torch.zeros(pop_size)\n",
    "        self.population.breeding_values = torch.zeros(pop_size)\n",
    "        self.max_generations = max_generations\n",
    "        self.current_generation = 0\n",
    "        self.variance_threshold = variance_threshold\n",
    "        \n",
    "    def step(self, actions):\n",
    "        # Log current population\n",
    "        current_state = self.get_state()\n",
    "        self.track_data(actions, self.calculate_reward())\n",
    "\n",
    "        # Select parents based on actions\n",
    "        selected_parent_indices = self.select_parents(actions)\n",
    "        selected = self.population.haplotypes[selected_parent_indices]\n",
    "\n",
    "        # Breeding\n",
    "        m = recombine(selected)  # Mother gametes\n",
    "        f = recombine(selected)  # Father gametes\n",
    "        progeny = create_progeny(m, f, reps=action2[torch.argmax(actions)])  # Create progeny\n",
    "\n",
    "        # Create new population from progeny\n",
    "        new_pop = create_pop(self.G, progeny)\n",
    "        phenotype(new_pop, self.T, self.h2)\n",
    "\n",
    "        # Switch current population to progeny population\n",
    "        self.population = new_pop\n",
    "\n",
    "        # Calculate reward based on new population\n",
    "        reward = self.calculate_reward()\n",
    "\n",
    "        # Get new state\n",
    "        new_state = self.get_state()\n",
    "        # Check if episode is done\n",
    "        done = self.is_done()\n",
    "\n",
    "        return new_state, reward, done\n",
    "\n",
    "    def select_parents(self, actions):\n",
    "        if self.population.phenotypes is None:\n",
    "            phenotype(self.population, self.T, self.h2)\n",
    "\n",
    "        parents = torch.topk(self.population.phenotypes, action1[torch.argmax(actions)]).indices\n",
    "        \n",
    "        return parents\n",
    "\n",
    "    def calculate_reward(self):\n",
    "        # Define how to calculate the reward based on your objective. \n",
    "        # Example: Improvement in average trait value\n",
    "        return self.population.phenotypes.mean()\n",
    "    \n",
    "    def is_done(self):\n",
    "        # Check if max generations reached or phenotypic variance is too low\n",
    "        if self.current_generation >= self.max_generations:\n",
    "            return True\n",
    "        if self.population.phenotypes.var() < self.variance_threshold:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def get_state(self):\n",
    "        # Calculate population statistics here\n",
    "        n_ind, n_chr, n_loci = self.population.haplotypes.sum(dim=1).shape\n",
    "        pop_stat_in  = self.population.haplotypes.sum(dim=1).view((n_ind, n_chr* n_loci))\n",
    "        pop_stat = population_statistics(pop_stat_in.float())\n",
    "\n",
    "        # Create a dictionary to hold state features\n",
    "        state = {\n",
    "            'avg_phenotype': self.population.phenotypes.mean(),\n",
    "            'phenotype_variance': self.population.phenotypes.var(),\n",
    "            'avg_breeding_value': self.population.breeding_values.mean(),\n",
    "            'heterozygosity': pop_stat['heterozygosity'],\n",
    "#             'allele_frequencies': pop_stat['allele_frequencies'],\n",
    "            'maf': pop_stat['maf'], # Assuming your model uses the whole maf vector\n",
    "            'inbreeding_coefficient': pop_stat['inbreeding_coefficient'],\n",
    "            'ld_matrix': pop_stat['ld_matrix'],\n",
    "            'genotype_frequencies': pop_stat['genotype_frequencies'][1]\n",
    "            # Add any other relevant features from pop_stat\n",
    "        }\n",
    "        return state\n",
    "\n",
    "    def track_data(self, actions, reward):\n",
    "        # Reuse state features from get_state()\n",
    "        state = self.get_state()\n",
    "        gen_data = {\n",
    "            'generation': len(self.history),\n",
    "            'avg_phenotype': state['avg_phenotype'].item(),\n",
    "            'phenotype_variance': state['phenotype_variance'].item(),\n",
    "            'avg_breeding_value': state['avg_breeding_value'].item(),\n",
    "            'actions': actions,\n",
    "            'reward': reward.item(),\n",
    "            'n_ind': self.pop_size,  # Assuming 'n_ind' is calculated in get_state()\n",
    "            'heterozygosity': state['heterozygosity'].mean(),\n",
    "#             'allele_frequencies': state['allele_frequencies'].mean(),\n",
    "            'maf': state['maf'].mean().mean(),\n",
    "            'inbreeding_coefficient': state['inbreeding_coefficient'].mean().item(),\n",
    "            # ... include other items from pop_stat as needed ...\n",
    "        }\n",
    "        self.history.append(gen_data)\n",
    "\n",
    "    def plot_history(self):\n",
    "        def normalize(data):\n",
    "            min_val = min(data)\n",
    "            max_val = max(data)\n",
    "            return [(x - min_val) / (max_val - min_val) for x in data]\n",
    "        generations = [d['generation'] for d in self.history]\n",
    "        avg_phenotypes = [d['avg_phenotype'] for d in self.history]\n",
    "        actions = [d['maf'] for d in self.history]\n",
    "        \n",
    "        avg_phenotypes = normalize(avg_phenotypes)\n",
    "        actions = normalize(actions)\n",
    "        plt.plot(generations, avg_phenotypes)\n",
    "        plt.plot(generations, actions)\n",
    "        plt.xlabel('Generation')\n",
    "        plt.ylabel('Average Phenotype')\n",
    "        plt.title('Breeding Progress')\n",
    "        plt.show()\n",
    "        \n",
    "    def reset(self):\n",
    "        # Reset the simulation to initial state\n",
    "        self.population = create_pop(self.G, create_random_pop(self.G, self.pop_size))\n",
    "        self.history = []\n",
    "        self.population.phenotypes = torch.zeros(self.pop_size)\n",
    "        self.population.breeding_values = torch.zeros(self.pop_size)\n",
    "        self.current_generation = 0\n",
    "        return self.get_state()\n",
    "    \n",
    "class RLAgent:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def select_action(self,state):\n",
    "        # Example: Convert state to tensor and feed it to the model to get actions\n",
    "        \n",
    "        input1 = state['maf'].unsqueeze(0)\n",
    "        input2 = state['inbreeding_coefficient'].unsqueeze(0) \n",
    "        input3 = state['heterozygosity'].unsqueeze(0)\n",
    "#         input4 = state['genotype_frequencies'].unsqueeze(0)\n",
    "        input_matrix = state['ld_matrix'].unsqueeze(0)\n",
    "\n",
    "        actions = self.model(input1, input2, input3, input_matrix)\n",
    "        return actions\n",
    "    \n",
    "    \n",
    "    #initialize the settings\n",
    "n_chr = 5\n",
    "n_loci = 100\n",
    "founder_pop_size = 200\n",
    "\n",
    "G = Genome(n_chr, n_loci)\n",
    "founder_pop = create_pop(G, create_random_pop(G, founder_pop_size))\n",
    "T = Trait(G, founder_pop, target_mean=0.0, target_variance=1.0)\n",
    "\n",
    "sim = BreedingSimulation(G, T, h2=.99, reps=1, pop_size=founder_pop_size)\n",
    "\n",
    "model = MyNetwork(n_loci*n_chr, founder_pop_size)\n",
    "\n",
    "agent = RLAgent(model)\n",
    "\n",
    "# Define the actions\n",
    "action1 = [5, 10, 20, 50, 100] # top k\n",
    "action2 = [40, 20, 10, 4, 2] # number x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0725e9e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'avg_phenotype': tensor(-0.1129),\n",
       "  'phenotype_variance': tensor(0.8096),\n",
       "  'avg_breeding_value': tensor(-0.1137),\n",
       "  'heterozygosity': tensor([0.3500, 0.4300, 0.4500, 0.5100, 0.4000, 0.2700, 0.2700, 0.4500, 0.4800,\n",
       "          0.2900, 0.4800, 0.4400, 0.4800, 0.4800, 0.4200, 0.2700, 0.4700, 0.4100,\n",
       "          0.4900, 0.4000, 0.2700, 0.4300, 0.3800, 0.3200, 0.3100, 0.4400, 0.5300,\n",
       "          0.3100, 0.2900, 0.4300, 0.4900, 0.4900, 0.3500, 0.2900, 0.2900, 0.4300,\n",
       "          0.4800, 0.5900, 0.4500, 0.4600, 0.2000, 0.4300, 0.4700, 0.4700, 0.4800,\n",
       "          0.4700, 0.4500, 0.4800, 0.4600, 0.4300, 0.3200, 0.4200, 0.4500, 0.2900,\n",
       "          0.2700, 0.3500, 0.5300, 0.4200, 0.4500, 0.4800, 0.4500, 0.4800, 0.4000,\n",
       "          0.2000, 0.4800, 0.4700, 0.4400, 0.4700, 0.2000, 0.4300, 0.4800, 0.4600,\n",
       "          0.4900, 0.4700, 0.4800, 0.4800, 0.5900, 0.4100, 0.4900, 0.0000, 0.3300,\n",
       "          0.4500, 0.2900, 0.4800, 0.4800, 0.3200, 0.0000, 0.4900, 0.3200, 0.4300,\n",
       "          0.4600, 0.2700, 0.2900, 0.4700, 0.0000, 0.4200, 0.5300, 0.3200, 0.4200,\n",
       "          0.4800, 0.4900, 0.4000, 0.5300, 0.2000, 0.4300, 0.2700, 0.4900, 0.3200,\n",
       "          0.4900, 0.4000, 0.4600, 0.5100, 0.5600, 0.4300, 0.4900, 0.4700, 0.4500,\n",
       "          0.5300, 0.4400, 0.2700, 0.3500, 0.4400, 0.4300, 0.2900, 0.5100, 0.2900,\n",
       "          0.4200, 0.2900, 0.4200, 0.4700, 0.5200, 0.4300, 0.4300, 0.4100, 0.4300,\n",
       "          0.5100, 0.4900, 0.4000, 0.2900, 0.2700, 0.4900, 0.2700, 0.4300, 0.4500,\n",
       "          0.4300, 0.4300, 0.3500, 0.0000, 0.4700, 0.4800, 0.4000, 0.4000, 0.4800,\n",
       "          0.4700, 0.3800, 0.4000, 0.4900, 0.4900, 0.3800, 0.4400, 0.4400, 0.4300,\n",
       "          0.3200, 0.3700, 0.4200, 0.4500, 0.5400, 0.5300, 0.0000, 0.5000, 0.4800,\n",
       "          0.4400, 0.2900, 0.4000, 0.4200, 0.4800, 0.4000, 0.0000, 0.3500, 0.4900,\n",
       "          0.4400, 0.4800, 0.4500, 0.4300, 0.4400, 0.4700, 0.2900, 0.4200, 0.4800,\n",
       "          0.4600, 0.4800, 0.5600, 0.4500, 0.2700, 0.2900, 0.4600, 0.4300, 0.4800,\n",
       "          0.4300, 0.2900, 0.3500, 0.4000, 0.5100, 0.4700, 0.4300, 0.4700, 0.2000,\n",
       "          0.4200, 0.4500, 0.4200, 0.4200, 0.0000, 0.5500, 0.0000, 0.5400, 0.4600,\n",
       "          0.4900, 0.2700, 0.4700, 0.3700, 0.2700, 0.4400, 0.4400, 0.4500, 0.4300,\n",
       "          0.5400, 0.2900, 0.4000, 0.4700, 0.3500, 0.4600, 0.4000, 0.4900, 0.3500,\n",
       "          0.5800, 0.3800, 0.3500, 0.4000, 0.4900, 0.2900, 0.4600, 0.4200, 0.2900,\n",
       "          0.4500, 0.4900, 0.3500, 0.4000, 0.4300, 0.4700, 0.4900, 0.2900, 0.4500,\n",
       "          0.5100, 0.4900, 0.3500, 0.3500, 0.4900, 0.4300, 0.4600, 0.4900, 0.3200,\n",
       "          0.5300, 0.4400, 0.2700, 0.4300, 0.0000, 0.4000, 0.0000, 0.4500, 0.3500,\n",
       "          0.5000, 0.2900, 0.4400, 0.0000, 0.4900, 0.2000, 0.4300, 0.4400, 0.4200,\n",
       "          0.4800, 0.4700, 0.4300, 0.4600, 0.5300, 0.4900, 0.2000, 0.4200, 0.2000,\n",
       "          0.4200, 0.4600, 0.2900, 0.4500, 0.4000, 0.3500, 0.4900, 0.4900, 0.4800,\n",
       "          0.4500, 0.2700, 0.4300, 0.3200, 0.4400, 0.4300, 0.2000, 0.4500, 0.4400,\n",
       "          0.2700, 0.4300, 0.4700, 0.5600, 0.3800, 0.3300, 0.4900, 0.4300, 0.2900,\n",
       "          0.4000, 0.4200, 0.3500, 0.2000, 0.2900, 0.2900, 0.4500, 0.0000, 0.4000,\n",
       "          0.4200, 0.5200, 0.4800, 0.3500, 0.4400, 0.4300, 0.4800, 0.4200, 0.4900,\n",
       "          0.5100, 0.6200, 0.2000, 0.4300, 0.4500, 0.4900, 0.3800, 0.5100, 0.0000,\n",
       "          0.2700, 0.4300, 0.3800, 0.4900, 0.4600, 0.4300, 0.4200, 0.4300, 0.4600,\n",
       "          0.0000, 0.4200, 0.4400, 0.4200, 0.4900, 0.4700, 0.5100, 0.5100, 0.2000,\n",
       "          0.3500, 0.4700, 0.4300, 0.4900, 0.4700, 0.4500, 0.4900, 0.4900, 0.4800,\n",
       "          0.4200, 0.4700, 0.2900, 0.4200, 0.4200, 0.4200, 0.4700, 0.4600, 0.4200,\n",
       "          0.2900, 0.4100, 0.4100, 0.4900, 0.4000, 0.4500, 0.4100, 0.0000, 0.2700,\n",
       "          0.4300, 0.4000, 0.4000, 0.5700, 0.4900, 0.5300, 0.4600, 0.4400, 0.4800,\n",
       "          0.4900, 0.2000, 0.2700, 0.3200, 0.4800, 0.4800, 0.5400, 0.5100, 0.4800,\n",
       "          0.2700, 0.4300, 0.2900, 0.5200, 0.3200, 0.4200, 0.4400, 0.4200, 0.3800,\n",
       "          0.2900, 0.4600, 0.0000, 0.2900, 0.2900, 0.4800, 0.0000, 0.0000, 0.4300,\n",
       "          0.4000, 0.0000, 0.2900, 0.4600, 0.4700, 0.4300, 0.4200, 0.2900, 0.4900,\n",
       "          0.4900, 0.4100, 0.4500, 0.4300, 0.4300, 0.4200, 0.4500, 0.4700, 0.4900,\n",
       "          0.3200, 0.4900, 0.4900, 0.4600, 0.5700, 0.4300, 0.4600, 0.2700, 0.4900,\n",
       "          0.4900, 0.4800, 0.0000, 0.2000, 0.4300, 0.3200, 0.4600, 0.4900, 0.4200,\n",
       "          0.4200, 0.4500, 0.2700, 0.4900, 0.4200, 0.4000, 0.3500, 0.5400, 0.5300,\n",
       "          0.4800, 0.3300, 0.4300, 0.4900, 0.2000, 0.4200, 0.4900, 0.0000, 0.4500,\n",
       "          0.4100, 0.2900, 0.2000, 0.4200, 0.3200, 0.4900, 0.5800, 0.4400, 0.3200,\n",
       "          0.3100, 0.2000, 0.4000, 0.5600, 0.4500, 0.4500, 0.4500, 0.4600, 0.2900,\n",
       "          0.4900, 0.4000, 0.4600, 0.4600, 0.5000]),\n",
       "  'maf': tensor([0.2000, 0.4000, 0.5000, 0.4000, 0.3000, 0.2000, 0.2000, 0.4000, 0.4000,\n",
       "          0.2000, 0.4000, 0.4000, 0.3000, 0.5000, 0.3000, 0.2000, 0.4000, 0.3000,\n",
       "          0.4000, 0.3000, 0.2000, 0.4000, 0.3000, 0.2000, 0.2000, 0.4000, 0.5000,\n",
       "          0.2000, 0.2000, 0.4000, 0.4000, 0.4000, 0.2000, 0.2000, 0.2000, 0.4000,\n",
       "          0.5000, 0.4000, 0.4000, 0.3000, 0.1000, 0.4000, 0.3000, 0.4000, 0.3000,\n",
       "          0.4000, 0.3000, 0.4000, 0.4000, 0.4000, 0.2000, 0.4000, 0.4000, 0.2000,\n",
       "          0.2000, 0.2000, 0.4000, 0.4000, 0.4000, 0.4000, 0.3000, 0.4000, 0.3000,\n",
       "          0.1000, 0.5000, 0.4000, 0.3000, 0.4000, 0.1000, 0.4000, 0.5000, 0.4000,\n",
       "          0.5000, 0.4000, 0.5000, 0.4000, 0.4000, 0.3000, 0.4000, 0.0000, 0.2000,\n",
       "          0.4000, 0.2000, 0.4000, 0.4000, 0.2000, 0.0000, 0.4000, 0.2000, 0.4000,\n",
       "          0.4000, 0.2000, 0.2000, 0.3000, 0.0000, 0.4000, 0.5000, 0.2000, 0.4000,\n",
       "          0.5000, 0.3000, 0.3000, 0.5000, 0.1000, 0.4000, 0.2000, 0.4000, 0.2000,\n",
       "          0.4000, 0.3000, 0.4000, 0.5000, 0.5000, 0.4000, 0.5000, 0.4000, 0.5000,\n",
       "          0.5000, 0.4000, 0.2000, 0.2000, 0.3000, 0.4000, 0.2000, 0.5000, 0.2000,\n",
       "          0.3000, 0.2000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.3000, 0.4000,\n",
       "          0.5000, 0.3000, 0.3000, 0.2000, 0.2000, 0.4000, 0.2000, 0.4000, 0.3000,\n",
       "          0.4000, 0.4000, 0.2000, 0.0000, 0.4000, 0.4000, 0.3000, 0.3000, 0.5000,\n",
       "          0.3000, 0.3000, 0.3000, 0.5000, 0.4000, 0.3000, 0.3000, 0.4000, 0.4000,\n",
       "          0.2000, 0.3000, 0.3000, 0.4000, 0.5000, 0.5000, 0.0000, 0.5000, 0.4000,\n",
       "          0.4000, 0.2000, 0.3000, 0.3000, 0.5000, 0.3000, 0.0000, 0.2000, 0.4000,\n",
       "          0.3000, 0.5000, 0.3000, 0.4000, 0.4000, 0.4000, 0.2000, 0.4000, 0.5000,\n",
       "          0.4000, 0.5000, 0.5000, 0.4000, 0.2000, 0.2000, 0.4000, 0.4000, 0.5000,\n",
       "          0.4000, 0.2000, 0.2000, 0.3000, 0.4000, 0.4000, 0.4000, 0.4000, 0.1000,\n",
       "          0.4000, 0.4000, 0.4000, 0.4000, 0.0000, 0.4000, 0.0000, 0.5000, 0.4000,\n",
       "          0.4000, 0.2000, 0.4000, 0.3000, 0.2000, 0.4000, 0.4000, 0.3000, 0.4000,\n",
       "          0.5000, 0.2000, 0.3000, 0.4000, 0.2000, 0.4000, 0.3000, 0.4000, 0.2000,\n",
       "          0.4000, 0.3000, 0.2000, 0.3000, 0.4000, 0.2000, 0.4000, 0.3000, 0.2000,\n",
       "          0.4000, 0.4000, 0.2000, 0.3000, 0.4000, 0.4000, 0.5000, 0.2000, 0.4000,\n",
       "          0.5000, 0.4000, 0.2000, 0.2000, 0.4000, 0.4000, 0.4000, 0.4000, 0.2000,\n",
       "          0.5000, 0.4000, 0.2000, 0.4000, 0.0000, 0.3000, 0.0000, 0.4000, 0.2000,\n",
       "          0.5000, 0.2000, 0.4000, 0.0000, 0.4000, 0.1000, 0.4000, 0.3000, 0.3000,\n",
       "          0.3000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.1000, 0.4000, 0.1000,\n",
       "          0.3000, 0.3000, 0.2000, 0.4000, 0.3000, 0.2000, 0.4000, 0.4000, 0.5000,\n",
       "          0.5000, 0.2000, 0.4000, 0.2000, 0.3000, 0.4000, 0.1000, 0.4000, 0.4000,\n",
       "          0.2000, 0.3000, 0.4000, 0.4000, 0.3000, 0.2000, 0.4000, 0.4000, 0.2000,\n",
       "          0.3000, 0.4000, 0.2000, 0.1000, 0.2000, 0.2000, 0.4000, 0.0000, 0.3000,\n",
       "          0.4000, 0.5000, 0.5000, 0.2000, 0.4000, 0.4000, 0.5000, 0.4000, 0.4000,\n",
       "          0.5000, 0.4000, 0.1000, 0.4000, 0.4000, 0.4000, 0.3000, 0.5000, 0.0000,\n",
       "          0.2000, 0.4000, 0.3000, 0.5000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000,\n",
       "          0.0000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.5000, 0.5000, 0.1000,\n",
       "          0.2000, 0.4000, 0.4000, 0.4000, 0.3000, 0.3000, 0.5000, 0.4000, 0.5000,\n",
       "          0.4000, 0.4000, 0.2000, 0.3000, 0.4000, 0.3000, 0.4000, 0.4000, 0.3000,\n",
       "          0.2000, 0.3000, 0.3000, 0.4000, 0.3000, 0.4000, 0.3000, 0.0000, 0.2000,\n",
       "          0.4000, 0.3000, 0.3000, 0.4000, 0.4000, 0.5000, 0.4000, 0.4000, 0.3000,\n",
       "          0.4000, 0.1000, 0.2000, 0.2000, 0.5000, 0.4000, 0.5000, 0.5000, 0.5000,\n",
       "          0.2000, 0.4000, 0.2000, 0.5000, 0.2000, 0.3000, 0.4000, 0.3000, 0.3000,\n",
       "          0.2000, 0.4000, 0.0000, 0.2000, 0.2000, 0.4000, 0.0000, 0.0000, 0.4000,\n",
       "          0.3000, 0.0000, 0.2000, 0.4000, 0.3000, 0.3000, 0.4000, 0.2000, 0.4000,\n",
       "          0.4000, 0.3000, 0.4000, 0.4000, 0.3000, 0.3000, 0.3000, 0.5000, 0.4000,\n",
       "          0.2000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.4000, 0.2000, 0.4000,\n",
       "          0.4000, 0.5000, 0.0000, 0.1000, 0.4000, 0.2000, 0.3000, 0.4000, 0.3000,\n",
       "          0.4000, 0.4000, 0.2000, 0.4000, 0.4000, 0.3000, 0.2000, 0.5000, 0.5000,\n",
       "          0.5000, 0.2000, 0.4000, 0.4000, 0.1000, 0.3000, 0.4000, 0.0000, 0.5000,\n",
       "          0.3000, 0.2000, 0.1000, 0.4000, 0.2000, 0.4000, 0.4000, 0.4000, 0.2000,\n",
       "          0.2000, 0.1000, 0.3000, 0.5000, 0.4000, 0.4000, 0.4000, 0.4000, 0.2000,\n",
       "          0.4000, 0.2000, 0.4000, 0.4000, 0.5000]),\n",
       "  'inbreeding_coefficient': tensor([ 0.7417, -0.2915,  0.7856, -0.2282, -0.2623, -0.1648, -0.1502, -0.1648,\n",
       "          -0.2038,  0.7856, -0.1258, -0.2818, -0.1843, -0.2282, -0.2087, -0.1843,\n",
       "           0.7856, -0.2379, -0.2038, -0.2038, -0.2428, -0.1892,  0.7417, -0.1502,\n",
       "           0.8099,  0.8099,  0.7856, -0.2379, -0.1843, -0.1843, -0.2379,  0.7417,\n",
       "          -0.2038,  0.7856, -0.1648, -0.1258,  0.7856, -0.2087, -0.1843, -0.1843,\n",
       "           0.7856,  0.8099, -0.1843,  0.7417, -0.1502, -0.2477, -0.2428, -0.1258,\n",
       "          -0.1502, -0.2721, -0.2038, -0.1648, -0.3062, -0.2379,  0.7417, -0.2282,\n",
       "          -0.1648, -0.2428,  0.7417, -0.2087,  0.7417, -0.1892, -0.2623, -0.2915,\n",
       "          -0.1502,  0.7417, -0.2087, -0.1258, -0.2721,  0.7856,  0.7417, -0.2379,\n",
       "          -0.2038, -0.1843, -0.2477, -0.1648, -0.2087, -0.2818, -0.1892, -0.2038,\n",
       "           0.7417, -0.1258, -0.2379, -0.2721, -0.2477, -0.1648,  0.8099,  0.7856,\n",
       "          -0.2818, -0.2282, -0.1648, -0.2038, -0.3062, -0.2379,  0.7417, -0.1843,\n",
       "          -0.2379, -0.1843, -0.2915, -0.2477, -0.2477, -0.2379, -0.1843,  0.7417,\n",
       "          -0.2038, -0.1648, -0.2818, -0.1892, -0.1502,  0.8099, -0.1648,  0.7856,\n",
       "          -0.2038, -0.1502, -0.1648,  0.7856, -0.2379, -0.1843, -0.2623, -0.1648,\n",
       "          -0.1648, -0.1843, -0.2428, -0.2087, -0.3062, -0.2379, -0.1648, -0.2282,\n",
       "          -0.2721,  0.8099, -0.2379, -0.2818, -0.2282, -0.1843,  0.8099, -0.2721,\n",
       "           0.8099, -0.2428, -0.2282, -0.2379, -0.1258,  0.7856,  0.7417,  0.7856,\n",
       "          -0.2038, -0.2623,  0.7417, -0.1648, -0.2282, -0.2379,  0.7856, -0.2379,\n",
       "          -0.1648,  0.7417, -0.2038,  0.7856, -0.2477, -0.2038,  0.7417, -0.2428,\n",
       "           0.8099, -0.1502, -0.1648, -0.1892, -0.2818, -0.2477, -0.1502, -0.1648,\n",
       "          -0.1648, -0.2818, -0.2721,  0.7856, -0.2087, -0.2038, -0.1648,  0.7856,\n",
       "           0.7856,  0.8099,  0.7417,  0.7417, -0.1843, -0.2818, -0.1502, -0.3062,\n",
       "           0.8099, -0.2818, -0.2623, -0.2038, -0.1892, -0.2379, -0.2087,  0.7417,\n",
       "          -0.2915, -0.1843, -0.2282, -0.2087, -0.2428, -0.2721, -0.1258, -0.2282]),\n",
       "  'ld_matrix': tensor([[ 1.0000, -0.4464, -0.0125,  ..., -0.6171,  0.6171, -0.0263],\n",
       "          [-0.4464,  1.0000,  0.0278,  ...,  0.6605, -0.6605,  0.4177],\n",
       "          [-0.0125,  0.0278,  1.0000,  ..., -0.4100,  0.4100,  0.6198],\n",
       "          ...,\n",
       "          [-0.6171,  0.6605, -0.4100,  ...,  1.0000, -1.0000, -0.0300],\n",
       "          [ 0.6171, -0.6605,  0.4100,  ..., -1.0000,  1.0000,  0.0300],\n",
       "          [-0.0263,  0.4177,  0.6198,  ..., -0.0300,  0.0300,  1.0000]]),\n",
       "  'genotype_frequencies': tensor([0.0550, 0.0350, 0.0250, 0.0400, 0.0350, 0.0400, 0.0350, 0.0200, 0.0450,\n",
       "          0.0250, 0.0500, 0.0350, 0.0550, 0.0200, 0.0450, 0.0650, 0.0450, 0.0550,\n",
       "          0.0500, 0.0550, 0.0450, 0.0350, 0.0350, 0.0300, 0.0250])},\n",
       " tensor(-0.1129),\n",
       " False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# single cycle - no phenotyping, going purely off rewards and population statistics\n",
    "# print(sim.population.size)\n",
    "selection = agent.select_action(sim.get_state())\n",
    "# Get the indices of the maximum values for each parameter\n",
    "action_values = torch.argmax(selection)\n",
    "# print(action_values)\n",
    "sim.step(action_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82f667a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 finished with reward: 3.948824882507324\n",
      "Episode 2 finished with reward: 10.957321166992188\n",
      "Episode 3 finished with reward: 2.8256592750549316\n",
      "Episode 4 finished with reward: 15.277546882629395\n",
      "Episode 5 finished with reward: 10.964852333068848\n",
      "Episode 6 finished with reward: 20.088417053222656\n",
      "Episode 7 finished with reward: 25.220020294189453\n",
      "Episode 8 finished with reward: 4.583522319793701\n",
      "Episode 9 finished with reward: 17.95716667175293\n",
      "Episode 10 finished with reward: 10.594817161560059\n",
      "Episode 11 finished with reward: 22.944469451904297\n",
      "Episode 12 finished with reward: 6.967560291290283\n",
      "Episode 13 finished with reward: 7.690304279327393\n",
      "phenotype: no var\n",
      "Episode 14 finished with reward: 6.212752342224121\n",
      "Episode 15 finished with reward: 10.00609016418457\n",
      "Episode 16 finished with reward: 17.52028465270996\n",
      "Episode 17 finished with reward: 17.423736572265625\n",
      "Episode 18 finished with reward: 29.074827194213867\n",
      "Episode 19 finished with reward: 5.005224227905273\n",
      "Episode 20 finished with reward: 16.300434112548828\n",
      "Episode 21 finished with reward: 12.683609962463379\n",
      "phenotype: no var\n",
      "Episode 22 finished with reward: 12.116893768310547\n",
      "Episode 23 finished with reward: 3.8544721603393555\n",
      "Episode 24 finished with reward: 6.682844161987305\n",
      "Episode 25 finished with reward: 7.516794204711914\n",
      "Episode 26 finished with reward: 14.171304702758789\n",
      "Episode 27 finished with reward: 6.176507472991943\n",
      "Episode 28 finished with reward: 6.031752586364746\n",
      "Episode 29 finished with reward: 8.331236839294434\n",
      "Episode 30 finished with reward: -1.1160537004470825\n",
      "Episode 31 finished with reward: 19.303424835205078\n",
      "Episode 32 finished with reward: 0.3776658773422241\n",
      "Episode 33 finished with reward: 15.727025985717773\n",
      "Episode 34 finished with reward: 1.8465148210525513\n",
      "Episode 35 finished with reward: 1.7033069133758545\n",
      "Episode 36 finished with reward: 2.000493288040161\n",
      "Episode 37 finished with reward: 7.8894572257995605\n",
      "Episode 38 finished with reward: 17.589275360107422\n",
      "phenotype: no var\n",
      "Episode 39 finished with reward: 17.64148712158203\n",
      "Episode 40 finished with reward: 11.05457592010498\n",
      "Episode 41 finished with reward: 12.081893920898438\n",
      "phenotype: no var\n",
      "Episode 42 finished with reward: 5.660019874572754\n",
      "Episode 43 finished with reward: 11.000894546508789\n",
      "Episode 44 finished with reward: 22.29697608947754\n",
      "Episode 45 finished with reward: 5.764113426208496\n",
      "Episode 46 finished with reward: 16.466964721679688\n",
      "phenotype: no var\n",
      "Episode 47 finished with reward: 13.562219619750977\n",
      "Episode 48 finished with reward: 9.743671417236328\n",
      "Episode 49 finished with reward: 2.6312930583953857\n",
      "Episode 50 finished with reward: 7.701766490936279\n",
      "Episode 51 finished with reward: 7.048259735107422\n",
      "Episode 52 finished with reward: 8.56503963470459\n",
      "Episode 53 finished with reward: 11.590302467346191\n",
      "Episode 54 finished with reward: 14.796952247619629\n",
      "Episode 55 finished with reward: 7.206964015960693\n",
      "Episode 56 finished with reward: 10.218953132629395\n",
      "Episode 57 finished with reward: 9.283365249633789\n",
      "Episode 58 finished with reward: 6.3958539962768555\n",
      "Episode 59 finished with reward: 5.160587787628174\n",
      "Episode 60 finished with reward: 5.557117938995361\n",
      "Episode 61 finished with reward: 9.280817985534668\n",
      "Episode 62 finished with reward: 19.609249114990234\n",
      "phenotype: no var\n",
      "Episode 63 finished with reward: 10.457674026489258\n",
      "Episode 64 finished with reward: 8.449414253234863\n",
      "Episode 65 finished with reward: 22.235240936279297\n",
      "Episode 66 finished with reward: 12.703612327575684\n",
      "Episode 67 finished with reward: 4.911868572235107\n",
      "Episode 68 finished with reward: 7.463184356689453\n",
      "Episode 69 finished with reward: 11.199679374694824\n",
      "Episode 70 finished with reward: 11.77436637878418\n",
      "Episode 71 finished with reward: 11.584166526794434\n",
      "Episode 72 finished with reward: 24.352149963378906\n",
      "Episode 73 finished with reward: 31.035449981689453\n",
      "Episode 74 finished with reward: 9.901068687438965\n",
      "Episode 75 finished with reward: 17.798839569091797\n",
      "Episode 76 finished with reward: 7.300628662109375\n",
      "Episode 77 finished with reward: 14.96983528137207\n",
      "Episode 78 finished with reward: 13.529624938964844\n",
      "Episode 79 finished with reward: 12.111412048339844\n",
      "Episode 80 finished with reward: 8.579431533813477\n",
      "Episode 81 finished with reward: 14.789881706237793\n",
      "Episode 82 finished with reward: 10.40887451171875\n",
      "Episode 83 finished with reward: 19.32929229736328\n",
      "Episode 84 finished with reward: 3.281905174255371\n",
      "Episode 85 finished with reward: 19.013626098632812\n",
      "Episode 86 finished with reward: 21.64451026916504\n",
      "Episode 87 finished with reward: 14.218451499938965\n",
      "Episode 88 finished with reward: 6.954200744628906\n",
      "Episode 89 finished with reward: 5.382754802703857\n",
      "Episode 90 finished with reward: 20.658546447753906\n",
      "Episode 91 finished with reward: 10.942965507507324\n",
      "Episode 92 finished with reward: 16.927886962890625\n",
      "Episode 93 finished with reward: 11.115311622619629\n",
      "Episode 94 finished with reward: 24.2760066986084\n",
      "Episode 95 finished with reward: 15.075811386108398\n",
      "Episode 96 finished with reward: 13.568792343139648\n",
      "Episode 97 finished with reward: 5.437050819396973\n",
      "Episode 98 finished with reward: 14.33477783203125\n",
      "Episode 99 finished with reward: 2.1986231803894043\n",
      "Episode 100 finished with reward: 5.829108238220215\n"
     ]
    }
   ],
   "source": [
    "num_episodes=100\n",
    "# Training loop\n",
    "for episode in range(num_episodes):\n",
    "    state = sim.reset()\n",
    "    episode_reward = 0\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        action = agent.select_action(state)\n",
    "        next_state, reward, done = sim.step(action)\n",
    "        # Here you would update your agent (e.g., store experience, update Q-values)\n",
    "        episode_reward += reward\n",
    "        state = next_state\n",
    "    \n",
    "    print(f\"Episode {episode + 1} finished with reward: {episode_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1c6285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37ee39b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c64872b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
