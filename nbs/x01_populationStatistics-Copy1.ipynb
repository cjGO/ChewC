{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7570e93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x01_populationStatistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9e0107f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 2.7271245, 1: 4.927556, 2: 5.9933896, 3: 6.1237473, 4: 5.015103}\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import uuid\n",
    "import pdb\n",
    "import torch\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "device='cpu'\n",
    "\n",
    "### BREEDING SIMULATOR\n",
    "class Genome:\n",
    "    def __init__(self, n_chr, n_loci):\n",
    "        self.ploidy = 2\n",
    "        self.n_chr = n_chr\n",
    "        self.n_loci = n_loci\n",
    "        self.shape = (self.ploidy, self.n_chr, self.n_loci)\n",
    "\n",
    "class Population:\n",
    "    def __init__(self, genome, haplotypes, device=device):\n",
    "        self.genome = genome\n",
    "        self.device = device\n",
    "        self.phenotypes = None\n",
    "        self.bvs = None\n",
    "        self.haplotypes = haplotypes.to(device)\n",
    "        self.dosages = haplotypes.sum(dim=1).float().to(device)\n",
    "        self.size = haplotypes.shape[0]\n",
    "\n",
    "class Trait:\n",
    "    def __init__(self, genome, founder_population, target_mean, target_variance, device=device):\n",
    "        self.target_mean = target_mean\n",
    "        self.target_variance = target_variance\n",
    "        self.device = device\n",
    "        random_effects = torch.randn(genome.n_chr, genome.n_loci, device=self.device)\n",
    "        random_effects -= random_effects.mean()\n",
    "        founder_scores = torch.einsum('kl,hkl->h', random_effects, founder_population.dosages).to(device)\n",
    "        founder_mean, founder_var = founder_scores.mean(), founder_scores.var()\n",
    "        scaling_factors = torch.sqrt(self.target_variance / founder_var)\n",
    "        self.scaling_factors = scaling_factors\n",
    "        random_effects *= scaling_factors\n",
    "        self.effects = random_effects\n",
    "        self.intercept = founder_mean - target_mean\n",
    "\n",
    "\n",
    "def calculate_breeding_value(population, trait, device=device):\n",
    "    return torch.einsum('hjk,jk->h', population.dosages, trait.effects).to(device)\n",
    "\n",
    "def truncation_selection(population, trait, top_percent):\n",
    "    return torch.topk(population.phenotypes, top_percent).indices.to(device)\n",
    "\n",
    "# meiosis\n",
    "def recombine(parent_haplo_tensor, recombination_rate=0.1):\n",
    "    num_individuals, ploidy, num_chromosomes, num_loci = parent_haplo_tensor.shape\n",
    "    # Generate crossover masks\n",
    "    maternal, paternal = parent_haplo_tensor[:,0,:,:], parent_haplo_tensor[:,1,:,:]\n",
    "    crossovers = torch.bernoulli(torch.full((num_individuals, num_chromosomes, num_loci), recombination_rate, device=device))\n",
    "    progeny = maternal * (1 - crossovers) + paternal * crossovers\n",
    "    return progeny\n",
    "\n",
    "def phenotype(population, trait, h2):\n",
    "    breeding_values = calculate_breeding_value(population, trait)\n",
    "    population.breeding_values = breeding_values\n",
    "    if breeding_values.var() == 0:\n",
    "        environmental_variance = 0\n",
    "    else:\n",
    "        environmental_variance = (1 - h2) / h2 * breeding_values.var()\n",
    "\n",
    "    # Check if environmental_variance is zero before applying torch.sqrt and .clone()\n",
    "    if environmental_variance == 0:\n",
    "        environmental_noise = torch.zeros(breeding_values.shape, device=device)\n",
    "    else:\n",
    "        environmental_noise = torch.randn(breeding_values.shape, device=device) * torch.sqrt(environmental_variance).detach()\n",
    "\n",
    "    population.breeding_values = breeding_values\n",
    "    population.phenotypes = breeding_values + environmental_noise\n",
    "\n",
    "    return population.phenotypes.max()\n",
    "\n",
    "def create_random_pop(G, pop_size):\n",
    "    return torch.randint(0, 2, (pop_size, *G.shape), device=device)\n",
    "\n",
    "def truncation_selection(population, trait, top_percent):\n",
    "    return torch.topk(population.phenotypes, top_percent).indices.to(device)\n",
    "\n",
    "# meiosis\n",
    "def recombine(parent_haplo_tensor, recombination_rate=0.1):\n",
    "    num_individuals, ploidy, num_chromosomes, num_loci = parent_haplo_tensor.shape\n",
    "    # Generate crossover masks\n",
    "    maternal, paternal = parent_haplo_tensor[:,0,:,:], parent_haplo_tensor[:,1,:,:]\n",
    "    crossovers = torch.bernoulli(torch.full((num_individuals, num_chromosomes, num_loci), recombination_rate, device=device))\n",
    "    progeny = maternal * (1 - crossovers) + paternal * crossovers\n",
    "    return progeny\n",
    "\n",
    "def phenotype(population, trait, h2):\n",
    "    breeding_values = calculate_breeding_value(population, trait)\n",
    "    population.breeding_values = breeding_values\n",
    "    if breeding_values.var() == 0:\n",
    "        environmental_variance = 0\n",
    "    else:\n",
    "        environmental_variance = (1 - h2) / h2 * breeding_values.var()\n",
    "\n",
    "    # Check if environmental_variance is zero before applying torch.sqrt and .clone()\n",
    "    if environmental_variance == 0:\n",
    "        environmental_noise = torch.zeros(breeding_values.shape, device=device)\n",
    "    else:\n",
    "        environmental_noise = torch.randn(breeding_values.shape, device=device) * torch.sqrt(environmental_variance).detach()\n",
    "\n",
    "    population.breeding_values = breeding_values\n",
    "    population.phenotypes = breeding_values + environmental_noise\n",
    "\n",
    "    return population.phenotypes.max()\n",
    "\n",
    "def create_random_pop(G, pop_size):\n",
    "    return torch.randint(0, 2, (pop_size, *G.shape), device=device)\n",
    "\n",
    "def update_pop(population, haplotype_pop_tensor):\n",
    "    population.haplotypes = haplotype_pop_tensor\n",
    "    population.dosages = haplotype_pop_tensor.sum(dim=1).float()\n",
    "    return population\n",
    "\n",
    "# meiosis\n",
    "def recombine(parent_haplo_tensor, recombination_rate=0.1):\n",
    "    num_individuals, ploidy, num_chromosomes, num_loci = parent_haplo_tensor.shape\n",
    "    # Generate crossover masks\n",
    "    maternal, paternal = parent_haplo_tensor[:,0,:,:],parent_haplo_tensor[:,1,:,:],\n",
    "    crossovers = torch.bernoulli(torch.full((num_individuals, num_chromosomes, num_loci), recombination_rate, device=device))\n",
    "#     crossovers = torch.rand((num_individuals, num_chromosomes, num_loci), device=device) < recombination_rate\n",
    "    progeny = maternal * torch.logical_not(crossovers) + paternal * crossovers\n",
    "    return progeny\n",
    "\n",
    "def breed(mother_tensor, father_tensor, recombination_rate=0.1):\n",
    "    eggs = recombine(mother_tensor,recombination_rate)\n",
    "    pollens = recombine(father_tensor,recombination_rate)\n",
    "    return torch.stack((eggs,pollens), dim=1)\n",
    "\n",
    "def create_pop(G, haplotypes):\n",
    "    return Population(G, haplotypes=haplotypes)\n",
    "\n",
    "def bv(P,T):\n",
    "    P.breeding_values = calculate_breeding_value(P.dosages,T.effects)\n",
    "\n",
    "def create_progeny(mother_gametes, father_gametes, reps=1, device=device):\n",
    "    progeny = []\n",
    "    for _ in range(reps):\n",
    "        # Randomly shuffle the gametes from each parent\n",
    "        shuffled_mother_indices = torch.randperm(mother_gametes.shape[0], device=device)\n",
    "        shuffled_father_indices = torch.randperm(father_gametes.shape[0], device=device)\n",
    "\n",
    "        # Select the shuffled gametes\n",
    "        mother_gametes = mother_gametes[shuffled_mother_indices]\n",
    "        father_gametes = father_gametes[shuffled_father_indices]\n",
    "\n",
    "        # Stack the gametes to create progeny haplotypes\n",
    "        progeny_haplotypes = torch.stack((mother_gametes, father_gametes), dim=1)\n",
    "        progeny.append(progeny_haplotypes)\n",
    "    return torch.vstack(progeny)\n",
    "\n",
    "class SimParams:\n",
    "    def __init__(self,G,T,h2,reps,pop_size,max_generations,founder_pop):\n",
    "        self.G = G\n",
    "        self.T = T\n",
    "        self.h2 = h2\n",
    "        self.reps = reps\n",
    "        self.pop_size = pop_size\n",
    "        self.max_generations = max_generations\n",
    "        self.founder_pop = founder_pop\n",
    "\n",
    "#RL ENVIRONMENT\n",
    "class BreedingEnvironment(gym.Env):\n",
    "    def __init__(self, SP):\n",
    "        super(BreedingEnvironment, self).__init__()\n",
    "        self.SP = SP\n",
    "        self.current_generation = 0\n",
    "        self.max_generations = SP.max_generations\n",
    "\n",
    "\n",
    "        # Define action and observation space\n",
    "        self.action_space = gym.spaces.Discrete(5)  # 0, 1, 2, 3, or 4\n",
    "        self.action_history = []\n",
    "\n",
    "        self.observation_space = gym.spaces.Dict({\n",
    "            \"population\": gym.spaces.Box(low=0, high=1, shape=(200, 2, 1, 200), dtype=np.int32),\n",
    "            \"generation\": gym.spaces.Box(low=0, high=1, shape=(1,), dtype=np.float32)\n",
    "        })\n",
    "\n",
    "        self._action_to_direction = {0:(200,1),\n",
    "               1:(100,2),\n",
    "               2:(50,4),\n",
    "               3:(25,8),\n",
    "               4:(5,40),}\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return {\n",
    "            \"population\": self.population.haplotypes.cpu(),\n",
    "            \"generation\": torch.tensor([self.generation / self.SP.max_generations], dtype=torch.float32).cpu()\n",
    "        }\n",
    "\n",
    "    def _get_info(self):\n",
    "        return {\n",
    "            \"phenotype\": self.phenotype.cpu().item(),\n",
    "            \"genetic_variance\": self.population.breeding_values.var().cpu().item()\n",
    "        }\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.population = self.SP.founder_pop\n",
    "        self.phenotype = phenotype(self.population, self.SP.T, self.SP.h2)\n",
    "        self.generation = 0\n",
    "\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "        self.action_history = []\n",
    "        return observation, info\n",
    "\n",
    "    def step(self, action):\n",
    "        # Map the action (element of {0,1,2,3}) to the direction we walk in\n",
    "#         print(action)\n",
    "        total_parents, total_crosses = self._action_to_direction[int(action)] # top parents, number crosses per\n",
    "\n",
    "        top_k = torch.topk(self.population.phenotypes, total_parents).indices\n",
    "        selected = self.population.haplotypes[top_k]\n",
    "\n",
    "        # Breeding\n",
    "        m = recombine(selected)  # Mother gametes\n",
    "        f = recombine(selected)  # Father gametes\n",
    "        progeny = create_progeny(m, f, reps=total_crosses)\n",
    "\n",
    "        # Create new population from progeny\n",
    "        self.population = create_pop(self.SP.G, progeny)\n",
    "        self.phenotype = phenotype(self.population, self.SP.T, self.SP.h2)\n",
    "\n",
    "\n",
    "        self.generation+=1\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "        terminated = self.generation >= self.SP.max_generations\n",
    "        truncated = False\n",
    "        reward = self.phenotype\n",
    "        self.action_history.append((action))\n",
    "        self.current_generation += 1\n",
    "        done = self.current_generation >= self.max_generations\n",
    "\n",
    "        if done:\n",
    "            info['final_generation'] = {\n",
    "                'phenotype': self.phenotype,\n",
    "                'genetic_variance': self.population.breeding_values.var().item()\n",
    "            }\n",
    "        return observation, reward, terminated, truncated, info\n",
    "\n",
    "\n",
    "#RLAGENT\n",
    "\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define our custom feature extractor\n",
    "class CustomFeatureExtractor(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: gym.spaces.Dict, features_dim: int = 64):\n",
    "        super(CustomFeatureExtractor, self).__init__(observation_space, features_dim)\n",
    "\n",
    "        population_shape = observation_space['population'].shape\n",
    "        self.input_size = population_shape[0] * population_shape[1] * population_shape[3]  # Flattened population size\n",
    "\n",
    "        self.fc1 = nn.Linear(self.input_size + 1, features_dim).to(device)  # +1 for generation input\n",
    "        self.fc2 = nn.Linear(features_dim, features_dim).to(device)\n",
    "\n",
    "    def forward(self, observations):\n",
    "        population = observations['population'].float().to(device)\n",
    "        generation = observations['generation'].float().to(device)\n",
    "\n",
    "        # Flatten the population input\n",
    "        x = population.view(population.size(0), -1)\n",
    "\n",
    "        # Concatenate generation input\n",
    "        x = torch.cat([x, generation], dim=1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "# Define our custom policy\n",
    "class CustomActorCriticPolicy(ActorCriticPolicy):\n",
    "    def __init__(self, observation_space, action_space, lr_schedule, *args, **kwargs):\n",
    "        super(CustomActorCriticPolicy, self).__init__(\n",
    "            observation_space,\n",
    "            action_space,\n",
    "            lr_schedule,\n",
    "            net_arch=[dict(pi=[64, 64], vf=[64, 64])],\n",
    "            features_extractor_class=CustomFeatureExtractor,\n",
    "            features_extractor_kwargs=dict(features_dim=8),\n",
    "            *args,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "#LOGGING\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import numpy as np\n",
    "import torch\n",
    "import numpy as np\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "class AverageFinalGenerationCallback(BaseCallback):\n",
    "    def __init__(self, log_freq=100, verbose=0):\n",
    "        super(AverageFinalGenerationCallback, self).__init__(verbose)\n",
    "        self.log_freq = log_freq\n",
    "        self.phenotypes = []\n",
    "        self.genetic_variances = []\n",
    "        self.best_phenotype = -float('inf')\n",
    "        self.episode_count = 0\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        for env_idx, done in enumerate(self.locals['dones']):\n",
    "            if done:\n",
    "                info = self.locals['infos'][env_idx]\n",
    "                if 'final_generation' in info:\n",
    "                    self.episode_count += 1\n",
    "                    final_gen_info = info['final_generation']\n",
    "                    \n",
    "                    # Move tensor to CPU and convert to numpy\n",
    "                    phenotype = final_gen_info['phenotype']\n",
    "                    if isinstance(phenotype, torch.Tensor):\n",
    "                        phenotype = phenotype.cpu().numpy()\n",
    "                    self.phenotypes.append(phenotype)\n",
    "                    \n",
    "                    genetic_variance = final_gen_info['genetic_variance']\n",
    "                    if isinstance(genetic_variance, torch.Tensor):\n",
    "                        genetic_variance = genetic_variance.cpu().numpy()\n",
    "                    self.genetic_variances.append(genetic_variance)\n",
    "\n",
    "                    # Update best phenotype\n",
    "                    self.best_phenotype = max(self.best_phenotype, phenotype)\n",
    "\n",
    "                    # Log every log_freq episodes\n",
    "                    if self.episode_count % self.log_freq == 0:\n",
    "                        avg_phenotype = np.mean(self.phenotypes)\n",
    "                        avg_genetic_variance = np.mean(self.genetic_variances)\n",
    "\n",
    "                        self.logger.record(\"final_generation/avg_phenotype\", avg_phenotype)\n",
    "                        self.logger.record(\"final_generation/avg_genetic_variance\", avg_genetic_variance)\n",
    "                        self.logger.record(\"final_generation/best_phenotype\", self.best_phenotype)\n",
    "\n",
    "                        # Reset lists for next logging period\n",
    "                        self.phenotypes = []\n",
    "                        self.genetic_variances = []\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "class BaselineTensorboardCallback(BaseCallback):\n",
    "    def __init__(self, baselines, log_freq=1000, verbose=0):\n",
    "        super(BaselineTensorboardCallback, self).__init__(verbose)\n",
    "        self.baselines = baselines\n",
    "        self.log_freq = log_freq\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self.log_freq == 0:\n",
    "            for action, value in self.baselines.items():\n",
    "                self.logger.record(f\"baselines/action_{action}\", value)\n",
    "            \n",
    "            # Log the best baseline for comparison\n",
    "            best_baseline = max(self.baselines.values())\n",
    "            self.logger.record(\"baselines/best\", best_baseline)\n",
    "\n",
    "        return True\n",
    "\n",
    "n_chr = 1\n",
    "n_loci = 200\n",
    "founder_pop_size = 200\n",
    "h2 = 1\n",
    "reps=1\n",
    "max_generations=5\n",
    "G = Genome(n_chr, n_loci)\n",
    "founder_pop = create_pop(G, create_random_pop(G, founder_pop_size))\n",
    "T = Trait(G, founder_pop, target_mean=0.0, target_variance=1.0)\n",
    "SP = SimParams(G,T,h2, reps, founder_pop_size, max_generations, founder_pop)\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from gymnasium.spaces import Box\n",
    "import gymnasium.spaces as spaces\n",
    "\n",
    "#BASELINES\n",
    "# Create the environment\n",
    "env = BreedingEnvironment(SP)\n",
    "env.reset()\n",
    "#calculate naive (e.g. choosing the same option every time)\n",
    "results = {}\n",
    "REPS=30\n",
    "for a in range(5):\n",
    "    env.reset()\n",
    "    results[a] = []\n",
    "    for r in range(REPS): #reps\n",
    "        env.reset()\n",
    "        for i in range(env.SP.max_generations):\n",
    "            env.step(a)\n",
    "        results[a].append(env.phenotype.cpu().numpy())\n",
    "random_results = []\n",
    "baselines = {}\n",
    "for i in results.keys():\n",
    "    baselines[i] = (np.array(results[i]).mean())\n",
    "\n",
    "print(baselines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9f4c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d866e291",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tensorboard_log = \"./ppotb\"\n",
    "\n",
    "\n",
    "# for i in [2,5,10]:\n",
    "#   #hyperparameters\n",
    "#   bs = i\n",
    "#   lr = .0003\n",
    "#   n_steps = 10\n",
    "#   total_timesteps=250000\n",
    "#   log_freq = 1\n",
    "\n",
    "#   from stable_baselines3.common.callbacks import CallbackList\n",
    "\n",
    "#   # Create the BaselineTensorboardCallback\n",
    "#   baseline_callback = BaselineTensorboardCallback(baselines, log_freq=log_freq)  # Adjust log_freq as needed\n",
    "\n",
    "#   # Create the AverageFinalGenerationCallback\n",
    "#   avg_gen_callback = AverageFinalGenerationCallback(log_freq=log_freq, verbose=0)\n",
    "\n",
    "#   # Combine both callbacks into a CallbackList\n",
    "#   callback_list = CallbackList([baseline_callback, avg_gen_callback])\n",
    "\n",
    "#   # Create the model\n",
    "#   model = PPO(CustomActorCriticPolicy, env, batch_size=bs, n_steps=n_steps, learning_rate=lr, device='cuda', verbose=0,\n",
    "#               tensorboard_log=tensorboard_log)\n",
    "\n",
    "#   # Set the tensorboard log name\n",
    "#   tb_log_name = f\"PPO_bs_{bs}_nsteps_{bs*10}\"\n",
    "\n",
    "#   # Train the model with both callbacks\n",
    "#   model.learn(total_timesteps=total_timesteps, tb_log_name=tb_log_name, callback=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb5a07f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55baf24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerationStatsCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super(GenerationStatsCallback, self).__init__(verbose)\n",
    "        self.generation_phenotypes = []\n",
    "        self.generation_genetic_variances = []\n",
    "        self.max_generations = None\n",
    "        self.episode_count = 0\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        env = self.training_env.envs[0]\n",
    "        \n",
    "        if self.max_generations is None:\n",
    "            self.max_generations = env.SP.max_generations\n",
    "            self.generation_phenotypes = [[] for _ in range(self.max_generations)]\n",
    "            self.generation_genetic_variances = [[] for _ in range(self.max_generations)]\n",
    "\n",
    "        current_gen = env.generation\n",
    "        phenotype = env.phenotype.cpu().item()\n",
    "        genetic_variance = env.population.breeding_values.var().cpu().item()\n",
    "\n",
    "        self.generation_phenotypes[current_gen].append(phenotype)\n",
    "        self.generation_genetic_variances[current_gen].append(genetic_variance)\n",
    "\n",
    "        if env.generation >= env.SP.max_generations - 1:\n",
    "            self.episode_count += 1\n",
    "            if self.episode_count % 100 == 0:  # Log every 100 episodes\n",
    "                self._log_stats()\n",
    "\n",
    "        return True\n",
    "\n",
    "    def _log_stats(self):\n",
    "        for gen in range(self.max_generations):\n",
    "            avg_phenotype = np.mean(self.generation_phenotypes[gen])\n",
    "            avg_genetic_variance = np.mean(self.generation_genetic_variances[gen])\n",
    "            \n",
    "            self.logger.record(f\"generation_stats/avg_phenotype_gen_{gen}\", avg_phenotype)\n",
    "            self.logger.record(f\"generation_stats/avg_genetic_variance_gen_{gen}\", avg_genetic_variance)\n",
    "\n",
    "        # Reset the lists for the next logging period\n",
    "        self.generation_phenotypes = [[] for _ in range(self.max_generations)]\n",
    "        self.generation_genetic_variances = [[] for _ in range(self.max_generations)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd2d0197",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/glect/miniconda3/envs/breeding/lib/python3.11/site-packages/stable_baselines3/ppo/ppo.py:155: UserWarning: You have specified a mini-batch size of 4, but because the `RolloutBuffer` is of size `n_steps * n_envs = 10`, after every 2 untruncated mini-batches, there will be a truncated mini-batch of size 2\n",
      "We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\n",
      "Info: (n_steps=10 and n_envs=1)\n",
      "  warnings.warn(\n",
      "/home/glect/miniconda3/envs/breeding/lib/python3.11/site-packages/stable_baselines3/common/policies.py:486: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
      "  warnings.warn(\n",
      "/home/glect/miniconda3/envs/breeding/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.SP to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.SP` for environment variables or `env.get_wrapper_attr('SP')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/glect/miniconda3/envs/breeding/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.generation to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.generation` for environment variables or `env.get_wrapper_attr('generation')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/glect/miniconda3/envs/breeding/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.phenotype to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.phenotype` for environment variables or `env.get_wrapper_attr('phenotype')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/glect/miniconda3/envs/breeding/lib/python3.11/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.population to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.population` for environment variables or `env.get_wrapper_attr('population')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m tb_log_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabcPPO_bs_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_nsteps_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbs\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m10\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Train the model with both callbacks\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/breeding/lib/python3.11/site-packages/stable_baselines3/ppo/ppo.py:315\u001b[0m, in \u001b[0;36mPPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[1;32m    308\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    313\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    314\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[0;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/breeding/lib/python3.11/site-packages/stable_baselines3/common/on_policy_algorithm.py:313\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mep_info_buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    311\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dump_logs(iteration)\n\u001b[0;32m--> 313\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_end()\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/breeding/lib/python3.11/site-packages/stable_baselines3/ppo/ppo.py:282\u001b[0m, in \u001b[0;36mPPO.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;66;03m# Clip grad norm\u001b[39;00m\n\u001b[1;32m    281\u001b[0m     th\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_grad_norm)\n\u001b[0;32m--> 282\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_updates \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n",
      "File \u001b[0;32m~/miniconda3/envs/breeding/lib/python3.11/site-packages/torch/optim/optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m             )\n\u001b[0;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/breeding/lib/python3.11/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/miniconda3/envs/breeding/lib/python3.11/site-packages/torch/optim/adam.py:168\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    157\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    159\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    160\u001b[0m         group,\n\u001b[1;32m    161\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    166\u001b[0m         state_steps)\n\u001b[0;32m--> 168\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniconda3/envs/breeding/lib/python3.11/site-packages/torch/optim/adam.py:318\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 318\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/breeding/lib/python3.11/site-packages/torch/optim/adam.py:394\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m    393\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mlerp_(grad, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[0;32m--> 394\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n\u001b[1;32m    397\u001b[0m     step \u001b[38;5;241m=\u001b[39m step_t\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tensorboard_log = \"./ppotb\"\n",
    "\n",
    "\n",
    "bs = i\n",
    "lr = .00003\n",
    "n_steps = 10\n",
    "total_timesteps=25000\n",
    "log_freq = 1\n",
    "\n",
    "from stable_baselines3.common.callbacks import CallbackList\n",
    "\n",
    "# Create the BaselineTensorboardCallback\n",
    "baseline_callback = BaselineTensorboardCallback(baselines, log_freq=log_freq)  # Adjust log_freq as needed\n",
    "\n",
    "# Create the AverageFinalGenerationCallback\n",
    "avg_gen_callback = AverageFinalGenerationCallback(log_freq=log_freq, verbose=0)\n",
    "generation_stats_callback = GenerationStatsCallback()\n",
    "\n",
    "# Combine both callbacks into a CallbackList\n",
    "callback_list = CallbackList([baseline_callback, avg_gen_callback, generation_stats_callback])\n",
    "\n",
    "# Create the model\n",
    "model = PPO(CustomActorCriticPolicy, env, batch_size=bs, n_steps=n_steps, learning_rate=lr, device='cuda', verbose=0,\n",
    "          tensorboard_log=tensorboard_log)\n",
    "\n",
    "# Set the tensorboard log name\n",
    "tb_log_name = f\"abcPPO_bs_{bs}_nsteps_{bs*10}\"\n",
    "\n",
    "# Train the model with both callbacks\n",
    "model.learn(total_timesteps=total_timesteps, tb_log_name=tb_log_name, callback=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e987723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0286609",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import CallbackList\n",
    "\n",
    "# Create the callbacks\n",
    "gen_stats_callback = GenerationStatsCallback()\n",
    "avg_final_gen_callback = AverageFinalGenerationCallback(log_freq=10)\n",
    "baseline_callback = BaselineTensorboardCallback(baselines, log_freq=10)\n",
    "\n",
    "# Combine the callbacks\n",
    "callback_list = CallbackList([gen_stats_callback, avg_final_gen_callback, baseline_callback])\n",
    "# Set the tensorboard log name\n",
    "tb_log_name = f\"testgen_lowerLr\"\n",
    "\n",
    "# Use the callback list when training your model\n",
    "model = PPO(CustomActorCriticPolicy, env, verbose=1, tensorboard_log=tensorboard_log, learning_rate=.0008)\n",
    "model.learn(total_timesteps=1000000,tb_log_name=tb_log_name, callback=callback_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1eb8f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
