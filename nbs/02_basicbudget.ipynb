{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7570e93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x01_populationStatistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9e0107f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import uuid\n",
    "import pdb\n",
    "import torch\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "device='cpu'\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "\n",
    "from chewc.sim import *\n",
    "from chewc.callback import *\n",
    "from chewc.policy import *\n",
    "from chewc.lab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe1c121b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'phenotype' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 51\u001b[0m\n\u001b[1;32m     49\u001b[0m config \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_reward\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[1;32m     50\u001b[0m env \u001b[38;5;241m=\u001b[39m SelectionIntensityEnvironment(SP, config)\n\u001b[0;32m---> 51\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/Users/cltng/OneDrive/chatgpt/chewc/lab.py:63\u001b[0m, in \u001b[0;36mSelectionIntensityEnvironment.reset\u001b[0;34m(self, seed, options)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mreset(seed\u001b[38;5;241m=\u001b[39mseed)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSP\u001b[38;5;241m.\u001b[39mfounder_pop\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mphenotype \u001b[38;5;241m=\u001b[39m \u001b[43mphenotype\u001b[49m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSP\u001b[38;5;241m.\u001b[39mT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSP\u001b[38;5;241m.\u001b[39mh2)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_generation \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepisode_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'phenotype' is not defined"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import CallbackList\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Example usage\n",
    "n_chr = 1\n",
    "n_parents = 20\n",
    "n_loci = 500\n",
    "founder_pop_size = 500\n",
    "h2 = 1\n",
    "reps = 1\n",
    "max_generations = 10\n",
    "seed = 422  # Choose any integer for your seed\n",
    "G = Genome(n_chr, n_loci, seed=seed)\n",
    "\n",
    "\n",
    "\n",
    "#set up the initial population\n",
    "\n",
    "founder_haplotypes = np.load('./data/g2f_ch10.npy') \n",
    "random_parent_indicies =  np.random.choice(founder_haplotypes.shape[0], n_parents, replace=False)\n",
    "random_loci_indices = np.random.choice(founder_haplotypes.shape[2], n_loci, replace=False)\n",
    "founder_haplotypes = founder_haplotypes[random_parent_indicies,:,:]\n",
    "founder_haplotypes = founder_haplotypes[:,:,random_loci_indices]\n",
    "founder_haplotypes = torch.tensor(founder_haplotypes)\n",
    "founder_haplotypes = founder_haplotypes.unsqueeze(2) \n",
    "\n",
    "\n",
    "founder_pop = create_pop(G, founder_haplotypes)\n",
    "founder_pop = random_crosses(founder_pop.haplotypes,founder_pop_size)\n",
    "founder_pop = create_pop(G, founder_pop)\n",
    "\n",
    "\n",
    "\n",
    "T = Trait(G, founder_pop, target_mean=0.0, target_variance=1.0, seed=seed)\n",
    "SP = SimParams(G, T, h2, reps, founder_pop_size, max_generations, founder_pop, seed=seed)\n",
    "\n",
    "\n",
    "# Create your custom callbacks\n",
    "genetic_variance_callback = AverageFinalGenerationCallback(log_freq=100)\n",
    "action_callback = ActionTrackingCallback(log_freq=10)\n",
    "\n",
    "# Combine the callbacks using CallbackList\n",
    "combined_callbacks = CallbackList([genetic_variance_callback, action_callback])\n",
    "\n",
    "# Create the environment\n",
    "config = {'sparse_reward':True}\n",
    "env = SelectionIntensityEnvironment(SP, config)\n",
    "x = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e2cfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert torch tensor to numpy array if necessary\n",
    "phenotypes = env.population.breeding_values.numpy()\n",
    "\n",
    "# Calculate summary statistics\n",
    "mean_phenotype = np.mean(phenotypes)\n",
    "median_phenotype = np.median(phenotypes)\n",
    "std_phenotype = np.std(phenotypes)\n",
    "min_phenotype = np.min(phenotypes)\n",
    "max_phenotype = np.max(phenotypes)\n",
    "sum_phenotype = np.sum(phenotypes)\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"Summary Statistics:\")\n",
    "print(f\"Mean: {mean_phenotype:.2f}\")\n",
    "print(f\"Median: {median_phenotype:.2f}\")\n",
    "print(f\"Standard Deviation: {std_phenotype:.2f}\")\n",
    "print(f\"Minimum: {min_phenotype:.2f}\")\n",
    "print(f\"Maximum: {max_phenotype:.2f}\")\n",
    "print(f\"Sum: {sum_phenotype:.2f}\")\n",
    "\n",
    "# Create histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(phenotypes, bins=10, edgecolor='black')\n",
    "plt.title('Histogram of Phenotypes')\n",
    "plt.xlabel('Phenotype Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51202cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dfe431",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming SimulatedEnv and Population classes are already defined as in your code\n",
    "\n",
    "def collect_baselines(env, actions, repetitions=100, cycles=5):\n",
    "    results = {action: {'max_phenotype': [], 'gv': []} for action in actions}\n",
    "    \n",
    "    for action in actions:\n",
    "        for _ in range(repetitions):\n",
    "            env.reset()\n",
    "            cycle_max_phenotype = []\n",
    "            cycle_gv = []\n",
    "            max_phenotype = env.population.breeding_values.max()\n",
    "            gv = env.population.breeding_values.var()\n",
    "            cycle_max_phenotype.append(max_phenotype)\n",
    "            cycle_gv.append(gv)\n",
    "            for _ in range(cycles):\n",
    "                env.step(np.array(action))\n",
    "                max_phenotype = env.population.breeding_values.max()\n",
    "                gv = env.population.breeding_values.var()\n",
    "                cycle_max_phenotype.append(max_phenotype)\n",
    "                cycle_gv.append(gv)\n",
    "            \n",
    "            results[action]['max_phenotype'].append(cycle_max_phenotype)\n",
    "            results[action]['gv'].append(cycle_gv)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def plot_results(results, metric):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    for action, data in results.items():\n",
    "        mean_values = np.mean(data[metric], axis=0)\n",
    "        std_values = np.std(data[metric], axis=0)\n",
    "        cycles = range(1, len(mean_values) + 1)\n",
    "        \n",
    "        plt.plot(cycles, mean_values, label=f'Action {action}')\n",
    "        plt.fill_between(cycles, mean_values - std_values, mean_values + std_values, alpha=0.3)\n",
    "    \n",
    "    plt.xlabel('Cycle')\n",
    "    plt.ylabel(metric.replace('_', ' ').title())\n",
    "    plt.title(f'{metric.replace(\"_\", \" \").title()} over Cycles')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Set up the environment and actions\n",
    "actions = [.05, .5, .95 ]\n",
    "actions = [scale_values(x, to_range=(-1, 1), from_range=(env.action_low, env.action_high)) for x in actions]\n",
    "print(actions)\n",
    "# Collect baselines\n",
    "results = collect_baselines(env, actions, repetitions=30,cycles=SP.max_generations)\n",
    "\n",
    "# Plot results\n",
    "plot_results(results, 'max_phenotype')\n",
    "plot_results(results, 'gv')\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba53a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb75db7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "# Wrap the environment (required for SB3)\n",
    "env.reset()\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "# Create and train the model with the custom policy\n",
    "model = PPO(CustomActorCriticPolicy, env, verbose=1, tensorboard_log=\"./ppotb\")\n",
    "model.learn(total_timesteps=5000, callback=combined_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad71eef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Create the environment\n",
    "# config = {}\n",
    "# env = SelectionIntensityEnvironment(SP, config)\n",
    "\n",
    "# # Wrap the environment (required for SB3)\n",
    "# env = DummyVecEnv([lambda: env])\n",
    "\n",
    "# # Create and train the model with the custom policy\n",
    "# model = PPO(CustomActorCriticPolicy, env, verbose=1, tensorboard_log=\"./ppotb\")\n",
    "# model.learn(total_timesteps=100000, callback=combined_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb4aed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SP.max_generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0875922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d21fda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
