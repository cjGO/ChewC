{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7570e93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x01_populationStatistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12887f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chewc.callback import *\n",
    "from chewc.policy import *\n",
    "from chewc.sim import *\n",
    "from chewc.lab import *\n",
    "from chewc.config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9e0107f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import uuid\n",
    "import pdb\n",
    "import torch\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "device='cpu'\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "\n",
    "import gymnasium as gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.callbacks import CallbackList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ca90bdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_low : 0.05\n",
      "action_high : 0.95\n",
      "sparse_reward : False\n",
      "n_parents : 10\n",
      "n_chr : 1\n",
      "n_loci : 100\n",
      "pop_size : 200\n",
      "max_generations : 10\n",
      "h2 : 0.5\n",
      "target_mean : 0\n",
      "target_variance : 1\n",
      "reps : 1\n",
      "total_timesteps : 100000\n",
      "learning_rate : 0.0003\n",
      "gae_lambda : 0.95\n",
      "log_freq : 100\n",
      "start_gen : 10\n",
      "end_gen : 100\n",
      "start_gae_lambda : 0.9\n",
      "end_gae_lambda : 0.95\n",
      "seed : None\n"
     ]
    }
   ],
   "source": [
    "config = get_default_config()\n",
    "for i in config:\n",
    "    print(f\"{i} : {config[i]}\")\n",
    "env = create_simulation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e71b61ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'population': array([[[[0, 0, 1, ..., 0, 0, 0]],\n",
       "  \n",
       "          [[0, 0, 1, ..., 0, 0, 0]]],\n",
       "  \n",
       "  \n",
       "         [[[1, 0, 1, ..., 1, 1, 1]],\n",
       "  \n",
       "          [[0, 0, 1, ..., 0, 0, 0]]],\n",
       "  \n",
       "  \n",
       "         [[[0, 0, 0, ..., 0, 0, 0]],\n",
       "  \n",
       "          [[0, 0, 0, ..., 0, 0, 0]]],\n",
       "  \n",
       "  \n",
       "         ...,\n",
       "  \n",
       "  \n",
       "         [[[0, 1, 0, ..., 0, 1, 0]],\n",
       "  \n",
       "          [[0, 0, 0, ..., 0, 1, 0]]],\n",
       "  \n",
       "  \n",
       "         [[[0, 0, 1, ..., 0, 0, 0]],\n",
       "  \n",
       "          [[0, 0, 1, ..., 0, 0, 0]]],\n",
       "  \n",
       "  \n",
       "         [[[0, 0, 0, ..., 0, 1, 0]],\n",
       "  \n",
       "          [[0, 1, 1, ..., 0, 0, 0]]]], dtype=int32),\n",
       "  'generation': array([0.], dtype=float32)},\n",
       " {'max_phenotype': 4.192286491394043,\n",
       "  'genetic_variance': 1.0000001192092896,\n",
       "  'current_generation': 0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68dee42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def collect_baselines(env, actions, repetitions=10, cycles=5):\n",
    "    results = {action: {'max_phenotype': [], 'gv': []} for action in actions}\n",
    "    final_gen_averages = {}\n",
    "    \n",
    "    for action in actions:\n",
    "        final_gen_phenotypes = []\n",
    "        for _ in range(repetitions):\n",
    "            env.reset()\n",
    "            cycle_max_phenotype = []\n",
    "            cycle_gv = []\n",
    "            for _ in range(cycles):\n",
    "                env.step(np.array([action]))\n",
    "                max_phenotype = env.population.breeding_values.max()\n",
    "                gv = env.population.breeding_values.var()\n",
    "                cycle_max_phenotype.append(max_phenotype)\n",
    "                cycle_gv.append(gv)\n",
    "            \n",
    "            results[action]['max_phenotype'].append(cycle_max_phenotype)\n",
    "            results[action]['gv'].append(cycle_gv)\n",
    "            final_gen_phenotypes.append(cycle_max_phenotype[-1])\n",
    "        \n",
    "        final_gen_averages[action] = np.mean(final_gen_phenotypes)\n",
    "    \n",
    "    best_action = max(final_gen_averages, key=final_gen_averages.get)\n",
    "    best_average = final_gen_averages[best_action]\n",
    "    \n",
    "    return results, best_action, best_average\n",
    "\n",
    "def plot_best_run(results, best_action):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    max_phenotypes = np.array(results[best_action]['max_phenotype'])\n",
    "    mean_values = np.mean(max_phenotypes, axis=0)\n",
    "    std_values = np.std(max_phenotypes, axis=0)\n",
    "    cycles = range(len(mean_values))\n",
    "    \n",
    "    plt.plot(cycles, mean_values, label=f'Action {best_action:.3f}')\n",
    "    plt.fill_between(cycles, mean_values - std_values, mean_values + std_values, alpha=0.3)\n",
    "    \n",
    "    plt.xlabel('Cycle')\n",
    "    plt.ylabel('Max Phenotype')\n",
    "    plt.title(f'Max Phenotype over Cycles for Best Action')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Usage\n",
    "actions = np.linspace(-1, 0, 10)  # or however many actions you want to test\n",
    "results, best_action, best_average = collect_baselines(env, actions, repetitions=10, cycles=env.SP.max_generations)\n",
    "\n",
    "print(f\"Best action: {best_action:.3f}\")\n",
    "print(f\"Best average max phenotype in final generation: {best_average:.3f}\")\n",
    "\n",
    "# Plot only the best run\n",
    "plot_best_run(results, best_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245c374b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a3aefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np linear ( between -1 and 1 )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050415eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Create your custom callbacks\n",
    "genetic_variance_callback = AverageFinalGenerationCallback(log_freq=100)\n",
    "action_callback = ActionTrackingCallback(log_freq=10)\n",
    "\n",
    "# Combine the callbacks using CallbackList\n",
    "combined_callbacks = CallbackList([genetic_variance_callback, action_callback])\n",
    "vec_env = DummyVecEnv([lambda: env])\n",
    "# Create and train the model with the custom policy\n",
    "model = PPO(CustomActorCriticPolicy, vec_env, verbose=1, tensorboard_log=\"./ppotb\")\n",
    "model.learn(total_timesteps=config['total_timesteps'], callback=combined_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d977ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Assuming you have an environment 'env' properly wrapped in a VecEnv\n",
    "obs = vec_env.reset()\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = vec_env.step(action)\n",
    "    print(scale_values(action))\n",
    "    print(reward)\n",
    "    # Process the observation, reward, and info as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ab139a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3 import PPO  # Assuming you're using PPO\n",
    "\n",
    "def collect_baselines(env, actions, repetitions=10, cycles=5):\n",
    "    results = {action: {'max_phenotype': [], 'gv': []} for action in actions}\n",
    "    final_gen_averages = {}\n",
    "    \n",
    "    for action in actions:\n",
    "        final_gen_phenotypes = []\n",
    "        for _ in range(repetitions):\n",
    "            env.reset()\n",
    "            cycle_max_phenotype = []\n",
    "            cycle_gv = []\n",
    "            for _ in range(cycles):\n",
    "                env.step(np.array([action]))\n",
    "                max_phenotype = env.population.breeding_values.max()\n",
    "                gv = env.population.breeding_values.var()\n",
    "                cycle_max_phenotype.append(max_phenotype)\n",
    "                cycle_gv.append(gv)\n",
    "            \n",
    "            results[action]['max_phenotype'].append(cycle_max_phenotype)\n",
    "            results[action]['gv'].append(cycle_gv)\n",
    "            final_gen_phenotypes.append(cycle_max_phenotype[-1])\n",
    "        \n",
    "        final_gen_averages[action] = np.mean(final_gen_phenotypes)\n",
    "    \n",
    "    best_action = max(final_gen_averages, key=final_gen_averages.get)\n",
    "    best_average = final_gen_averages[best_action]\n",
    "    \n",
    "    return results, best_action, best_average\n",
    "\n",
    "def run_model(model, vec_env, num_runs=100):\n",
    "    all_max_phenotypes = []\n",
    "    \n",
    "    for _ in range(num_runs):\n",
    "        obs = vec_env.reset()\n",
    "        done = False\n",
    "        episode_max_phenotypes = []\n",
    "        \n",
    "        while not done:\n",
    "            action, _states = model.predict(obs, deterministic=True)\n",
    "            obs, reward, done, info = vec_env.step(action)\n",
    "            max_phenotype = vec_env.get_attr('population')[0].breeding_values.max()\n",
    "            episode_max_phenotypes.append(max_phenotype)\n",
    "        \n",
    "        all_max_phenotypes.append(episode_max_phenotypes)\n",
    "    \n",
    "    return np.array(all_max_phenotypes)\n",
    "\n",
    "def plot_comparison(baseline_results, best_action, model_results):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot baseline\n",
    "    baseline_max_phenotypes = np.array(baseline_results[best_action]['max_phenotype'])\n",
    "    baseline_mean = np.mean(baseline_max_phenotypes, axis=0)\n",
    "    baseline_std = np.std(baseline_max_phenotypes, axis=0)\n",
    "    cycles = range(len(baseline_mean))\n",
    "    \n",
    "    plt.plot(cycles, baseline_mean, label=f'Baseline (Action {best_action:.3f})', color='blue')\n",
    "    plt.fill_between(cycles, baseline_mean - baseline_std, baseline_mean + baseline_std, alpha=0.3, color='blue')\n",
    "    \n",
    "    # Plot model results\n",
    "    model_mean = np.mean(model_results, axis=0)\n",
    "    model_std = np.std(model_results, axis=0)\n",
    "    \n",
    "    plt.plot(cycles, model_mean, label='Model', color='red')\n",
    "    plt.fill_between(cycles, model_mean - model_std, model_mean + model_std, alpha=0.3, color='red')\n",
    "    \n",
    "    plt.xlabel('Cycle/Generation')\n",
    "    plt.ylabel('Max Phenotype')\n",
    "    plt.title('Comparison of Baseline vs Model: Max Phenotype over Cycles')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Usage\n",
    "actions = np.linspace(-1, 0, 20)\n",
    "baseline_results, best_action, best_average = collect_baselines(env, actions, repetitions=30, cycles=env.SP.max_generations)\n",
    "\n",
    "print(f\"Best baseline action: {best_action:.3f}\")\n",
    "print(f\"Best baseline average max phenotype in final generation: {best_average:.3f}\")\n",
    "\n",
    "# Load your trained model\n",
    "# model = PPO.load(\"path_to_your_model\")\n",
    "\n",
    "# Run the model\n",
    "model_results = run_model(model, vec_env, num_runs=100)\n",
    "\n",
    "# Plot comparison\n",
    "plot_comparison(baseline_results, best_action, model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b97c45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877af02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(env.population.breeding_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e2cfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert torch tensor to numpy array if necessary\n",
    "phenotypes = env.population.breeding_values.numpy()\n",
    "\n",
    "# Calculate summary statistics\n",
    "mean_phenotype = np.mean(phenotypes)\n",
    "median_phenotype = np.median(phenotypes)\n",
    "std_phenotype = np.std(phenotypes)\n",
    "min_phenotype = np.min(phenotypes)\n",
    "max_phenotype = np.max(phenotypes)\n",
    "sum_phenotype = np.sum(phenotypes)\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"Summary Statistics:\")\n",
    "print(f\"Mean: {mean_phenotype:.2f}\")\n",
    "print(f\"Median: {median_phenotype:.2f}\")\n",
    "print(f\"Standard Deviation: {std_phenotype:.2f}\")\n",
    "print(f\"Minimum: {min_phenotype:.2f}\")\n",
    "print(f\"Maximum: {max_phenotype:.2f}\")\n",
    "print(f\"Sum: {sum_phenotype:.2f}\")\n",
    "\n",
    "# Create histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(phenotypes, bins=10, edgecolor='black')\n",
    "plt.title('Histogram of Phenotypes')\n",
    "plt.xlabel('Phenotype Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d2693f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6b71de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca445a99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9422d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
