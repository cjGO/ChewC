{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fee3778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21795c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Optional, Dict\n",
    "from dataclasses import dataclass\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3 import PPO\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.logger import Figure\n",
    "\n",
    "inbred_parent_data = np.load('../nbs/data/g2f_ch10.npy', allow_pickle=True)\n",
    "device = 'cpu'\n",
    "\n",
    "@dataclass\n",
    "class SimulationConfig:\n",
    "    n_markers: int = 1000\n",
    "    starting_parents: int = 20\n",
    "    pop_size: int = 1000\n",
    "    h2: float = 1.0\n",
    "    sparse_reward: bool = True\n",
    "\n",
    "class Genome:\n",
    "    def __init__(self, n_markers: int):\n",
    "        self.ploidy: int = 2\n",
    "        self.n_markers: int = n_markers\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Genome(ploidy={self.ploidy}, n_markers={self.n_markers})\"\n",
    "\n",
    "class Population:\n",
    "    def __init__(self, pop_size: int, haplotypes:torch.tensor, genome: Genome, device: torch.device):\n",
    "        self.pop_size: int = pop_size\n",
    "        self.genome: Genome = genome\n",
    "        self.haplotypes: torch.Tensor = haplotypes\n",
    "        self.device: torch.device = device\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def to(self, device: torch.device) -> 'Population':\n",
    "        self.device = device\n",
    "        self.haplotypes = self.haplotypes.to(device)\n",
    "        return self\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Population(pop_size={self.pop_size}, genome={self.genome}, device={self.device})\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Trait:\n",
    "    def __init__(self, genome: Genome, population: Population, target_mean: float = 0.0, target_variance: float = 1.0):\n",
    "        self.genome: Genome = genome\n",
    "        self.device: torch.device = population.device\n",
    "        self.target_mean: float = target_mean\n",
    "        self.target_variance: float = target_variance\n",
    "\n",
    "        raw_effects = torch.randn(genome.n_markers, device=self.device)\n",
    "        centered_effects = raw_effects - raw_effects.mean()\n",
    "        dosages = population.haplotypes.sum(dim=1)\n",
    "        founder_values = torch.einsum('ij,j->i', dosages, centered_effects)\n",
    "        founder_mean = founder_values.mean()\n",
    "        founder_var = founder_values.var()\n",
    "\n",
    "        scaling_factor = torch.sqrt(self.target_variance / founder_var)\n",
    "        self.effects: torch.Tensor = centered_effects * scaling_factor\n",
    "        self.intercept: torch.Tensor = (torch.tensor(self.target_mean, device=self.device) - founder_mean).detach()\n",
    "\n",
    "    def to(self, device: torch.device) -> 'Trait':\n",
    "        self.device = device\n",
    "        self.effects = self.effects.to(device)\n",
    "        self.intercept = self.intercept.to(device)\n",
    "        return self\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Trait(target_mean={self.target_mean}, target_variance={self.target_variance}, device={self.device})\"\n",
    "\n",
    "class SimOps:\n",
    "    @staticmethod\n",
    "    def score_population(population: Population, trait: Trait, h2: float = 1.0) -> torch.Tensor:\n",
    "        dosages = population.haplotypes.sum(dim=1)\n",
    "        breeding_values = torch.einsum('ij,j->i', dosages, trait.effects)\n",
    "\n",
    "        bv_var = breeding_values.var()\n",
    "        if bv_var == 0 or h2 >= 1:\n",
    "            return breeding_values\n",
    "\n",
    "        env_variance = (1 - h2) / h2 * bv_var.item()\n",
    "        env_std = torch.sqrt(torch.tensor(env_variance, device=population.device))\n",
    "        env_effects = torch.randn_like(breeding_values) * env_std\n",
    "        return breeding_values + env_effects + trait.intercept\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def truncation_selection(population: Population, phenotypes: torch.Tensor, selection_intensity: float) -> torch.Tensor:\n",
    "        assert 0 < selection_intensity <= 1, \"Selection intensity must be between 0 and 1\"\n",
    "        assert population.haplotypes.shape[0] == phenotypes.shape[0], \"Mismatch between population size and phenotypes\"\n",
    "\n",
    "        num_select = max(1, min(int(selection_intensity * population.pop_size), population.pop_size - 1))\n",
    "        _, top_indices = torch.topk(phenotypes, num_select)\n",
    "        return population.haplotypes[top_indices]\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def meiosis(selected_haplotypes: torch.Tensor, num_crossovers: int = 1, num_gametes_per_parent: int = 1) -> torch.Tensor:\n",
    "        num_parents, ploidy, num_markers = selected_haplotypes.shape\n",
    "\n",
    "        # Repeat each parent's haplotypes num_gametes_per_parent times\n",
    "        expanded_haplotypes = selected_haplotypes.repeat_interleave(num_gametes_per_parent, dim=0)\n",
    "\n",
    "        # The rest of the function remains largely the same, but operates on the expanded haplotypes\n",
    "        total_gametes = num_parents * num_gametes_per_parent\n",
    "\n",
    "        crossover_points = torch.randint(1, num_markers, (total_gametes, num_crossovers), device=selected_haplotypes.device)\n",
    "        crossover_points, _ = torch.sort(crossover_points, dim=1)\n",
    "\n",
    "        crossover_mask = torch.zeros((total_gametes, num_markers), dtype=torch.bool, device=selected_haplotypes.device)\n",
    "        crossover_mask.scatter_(1, crossover_points, 1)\n",
    "        crossover_mask = torch.cumsum(crossover_mask, dim=1) % 2 == 1\n",
    "\n",
    "        crossover_mask = crossover_mask.unsqueeze(1).expand(-1, ploidy, -1)\n",
    "\n",
    "        start_chromosome = torch.randint(0, ploidy, (total_gametes, 1), device=selected_haplotypes.device)\n",
    "        start_mask = start_chromosome.unsqueeze(-1).expand(-1, -1, num_markers)\n",
    "\n",
    "        final_mask = crossover_mask ^ start_mask.bool()\n",
    "\n",
    "        offspring_haplotypes = torch.where(final_mask, expanded_haplotypes, expanded_haplotypes.roll(shifts=1, dims=1))\n",
    "\n",
    "        # Return only the first haplotype for each meiosis event\n",
    "        return offspring_haplotypes[:, 0, :]\n",
    "    @staticmethod\n",
    "    def check_cuda(tensor: torch.Tensor, name: str) -> None:\n",
    "        print(f\"{name} is on: {tensor.device}\")\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def random_cross(gamete_tensor: torch.Tensor, total_crosses: int) -> torch.Tensor:\n",
    "        num_gametes, n_markers = gamete_tensor.shape\n",
    "\n",
    "        # Double the gamete tensor until we have enough for the total crosses\n",
    "        while num_gametes < 2 * total_crosses:\n",
    "            gamete_tensor = torch.cat([gamete_tensor, gamete_tensor], dim=0)\n",
    "            num_gametes *= 2\n",
    "\n",
    "        # Randomly select gametes for crossing\n",
    "        gamete_indices = torch.randperm(num_gametes, device=gamete_tensor.device)\n",
    "        parent1_indices = gamete_indices[:total_crosses]\n",
    "        parent2_indices = gamete_indices[total_crosses:2*total_crosses]\n",
    "\n",
    "        # Create the new population haplotype tensor\n",
    "        new_population = torch.stack([\n",
    "            gamete_tensor[parent1_indices],\n",
    "            gamete_tensor[parent2_indices]\n",
    "        ], dim=1)\n",
    "\n",
    "        return new_population\n",
    "    \n",
    "def grab_inbred_parents(starting_parents, genome, device=device):\n",
    "\n",
    "        inbred_data = inbred_parent_data\n",
    "        \n",
    "        if starting_parents > inbred_data.shape[0]:\n",
    "            raise ValueError(\"Total parents requested exceed the number of available parents.\")\n",
    "        if genome.n_markers > inbred_data.shape[2]:\n",
    "            raise ValueError(\"Total markers requested exceed the number of available markers.\")\n",
    "        # Randomly sample parents\n",
    "        sampled_parents_indices = np.random.choice(inbred_data.shape[0], starting_parents, replace=False)\n",
    "        sampled_parents = inbred_data[sampled_parents_indices, :, :]\n",
    "        # Randomly sample markers\n",
    "        sampled_markers_indices = np.random.choice(inbred_data.shape[2], genome.n_markers, replace=False)\n",
    "        return torch.tensor(sampled_parents[:, :, sampled_markers_indices], device=device).float()\n",
    "\n",
    "##################\n",
    "\n",
    "class SimParams:\n",
    "    def __init__(self, config: SimulationConfig):\n",
    "        self.config = config\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.genome = Genome(config.n_markers)\n",
    "        self.population = Population(config.pop_size, grab_inbred_parents(5,genome), genome,device)\n",
    "        f1 = self.perform_meiosis(self.population.haplotypes, num_crossovers=3, num_gametes_per_parent=((2000//self.population.haplotypes.shape[0]) *self.population.haplotypes.shape[0] + 100))\n",
    "        self.create_next_generation(f1, total_crosses=2000)\n",
    "        num_gametes_per_parent = (self.population.haplotypes.shape[0] / config.pop_size) + 2 \n",
    "        segregating_pop = self.perform_meiosis(self.population.haplotypes, num_crossovers=3, num_gametes_per_parent=100)\n",
    "        self.create_next_generation(segregating_pop, total_crosses=config.pop_size)\n",
    "\n",
    "        \n",
    "        self.trait = Trait(self.genome, self.population)\n",
    "\n",
    "\n",
    "    def score_population(self, h2: Optional[float] = None) -> torch.Tensor:\n",
    "        h2 = h2 if h2 is not None else self.config.h2\n",
    "        return SimOps.score_population(self.population, self.trait, h2)\n",
    "\n",
    "    def truncation_selection(self, selection_intensity: Optional[float] = None, phenotypes: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        selection_intensity = selection_intensity if selection_intensity is not None else self.config.selection_intensity\n",
    "        if phenotypes is None:\n",
    "            phenotypes = self.score_population()\n",
    "        return SimOps.truncation_selection(self.population, phenotypes, selection_intensity)\n",
    "\n",
    "    def check_device(self) -> None:\n",
    "        SimOps.check_cuda(self.population.haplotypes, \"Population haplotypes\")\n",
    "        SimOps.check_cuda(self.trait.effects, \"Trait effects\")\n",
    "        SimOps.check_cuda(self.trait.intercept, \"Trait intercept\")\n",
    "\n",
    "    def to(self, device: torch.device) -> 'SimParams':\n",
    "        self.device = device\n",
    "        self.population = self.population.to(device)\n",
    "        self.trait = self.trait.to(device)\n",
    "        return self\n",
    "    def perform_meiosis(self, selected_haplotypes: torch.Tensor, num_crossovers: int = 1, num_gametes_per_parent: int = 1) -> torch.Tensor:\n",
    "        return SimOps.meiosis(selected_haplotypes, num_crossovers, num_gametes_per_parent)\n",
    "\n",
    "    def create_next_generation(self, gametes: torch.Tensor, total_crosses: int) -> None:\n",
    "        new_population_haplotypes = SimOps.random_cross(gametes, total_crosses)\n",
    "        # assert new_population_haplotypes.shape[0] == self.config.pop_size, \"Population size changed unexpectedly\"\n",
    "        self.population.haplotypes = new_population_haplotypes\n",
    "        self.population.pop_size = total_crosses\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30b561b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0, log_interval=100, plot_interval=1000, window_size=100):\n",
    "        super().__init__(verbose)\n",
    "        self.log_interval = log_interval\n",
    "        self.plot_interval = plot_interval\n",
    "        self.window_size = window_size\n",
    "        self.step_counter = 0\n",
    "        self.generation_data = {}\n",
    "        self.moving_avg_data = {}\n",
    "        self.timesteps_history = []\n",
    "        self.writer = None\n",
    "\n",
    "    def _on_training_start(self):\n",
    "        self.writer = SummaryWriter(self.logger.dir)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        info = self.locals['infos'][0]\n",
    "        current_generation = info['current_generation']\n",
    "        \n",
    "        if current_generation not in self.generation_data:\n",
    "            self.generation_data[current_generation] = {\n",
    "                'max_phenotypes': [],\n",
    "                'genetic_variances': [],\n",
    "                'si': [],\n",
    "                'timesteps': []\n",
    "            }\n",
    "            self.moving_avg_data[current_generation] = {\n",
    "                'max_phenotypes': [],\n",
    "                'genetic_variances': [],\n",
    "                'si': [],\n",
    "                'timesteps': []\n",
    "            }\n",
    "        \n",
    "        self.generation_data[current_generation]['max_phenotypes'].append(info['max_phenotype'])\n",
    "        self.generation_data[current_generation]['genetic_variances'].append(info['genetic_variance'])\n",
    "        self.generation_data[current_generation]['si'].append(info['selection_intensity'])\n",
    "        self.generation_data[current_generation]['timesteps'].append(self.num_timesteps)\n",
    "        \n",
    "        self.step_counter += 1\n",
    "        \n",
    "        if self.step_counter % self.log_interval == 0:\n",
    "            self._update_moving_averages()\n",
    "\n",
    "        if self.step_counter % self.plot_interval == 0:\n",
    "            self._log_to_tensorboard()\n",
    "            \n",
    "        if self.step_counter % self.plot_interval == 0:\n",
    "            self._plot_data()\n",
    "\n",
    "        return True\n",
    "\n",
    "    def _update_moving_averages(self):\n",
    "        for gen in self.generation_data:\n",
    "            data = self.generation_data[gen]\n",
    "            if len(data['max_phenotypes']) >= self.window_size:\n",
    "                avg_phenotype = np.mean(data['max_phenotypes'][-self.window_size:])\n",
    "                avg_variance = np.mean(data['genetic_variances'][-self.window_size:])\n",
    "                avg_si = np.mean(data['si'][-self.window_size:])\n",
    "                avg_timestep = data['timesteps'][-1]\n",
    "                \n",
    "                self.moving_avg_data[gen]['max_phenotypes'].append(avg_phenotype)\n",
    "                self.moving_avg_data[gen]['genetic_variances'].append(avg_variance)\n",
    "                self.moving_avg_data[gen]['si'].append(avg_si)\n",
    "                self.moving_avg_data[gen]['timesteps'].append(avg_timestep)\n",
    "\n",
    "    def _plot_data(self):\n",
    "        clear_output(wait=True)\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        for gen in sorted(self.moving_avg_data.keys()):\n",
    "            data = self.moving_avg_data[gen]\n",
    "            plt.plot(data['timesteps'], data['max_phenotypes'], label=f'Gen {gen}')\n",
    "        \n",
    "        plt.xlabel('Timesteps')\n",
    "        plt.ylabel('Max Phenotype (Moving Average)')\n",
    "        plt.title('Max Phenotype by Generation')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def on_training_end(self):\n",
    "        self._plot_data()  # Final plot at the end of training\n",
    "        \n",
    "    def _log_to_tensorboard(self):\n",
    "        for gen in sorted(self.moving_avg_data.keys()):\n",
    "            data = self.moving_avg_data[gen]\n",
    "            for i, (timestep, max_phenotype, genetic_variance, avg_si) in enumerate(zip(data['timesteps'], data['max_phenotypes'], data['genetic_variances'], data['si'])):\n",
    "                self.writer.add_scalar(f'Max_Phenotype/Gen_{gen}', max_phenotype, timestep)\n",
    "                self.writer.add_scalar(f'Genetic_Variance/Gen_{gen}', genetic_variance, timestep)\n",
    "                self.writer.add_scalar(f'action/Gen_{gen}', avg_si, timestep)\n",
    "\n",
    "    def on_training_end(self):\n",
    "        self._log_to_tensorboard()\n",
    "        if self.writer:\n",
    "            self.writer.close()\n",
    "            \n",
    "def collect_baselines(env, num_episodes=10, selection_intensities=[0.1, 0.2, 0.3, 0.4, 0.5], num_reps=5):\n",
    "    baselines = {}\n",
    "    for intensity in selection_intensities:\n",
    "        all_rewards = []\n",
    "        for _ in range(num_reps):\n",
    "            rewards = []\n",
    "            for _ in range(num_episodes):\n",
    "                obs, _ = env.reset()\n",
    "                done = False\n",
    "                episode_reward = 0\n",
    "                while not done:\n",
    "                    action = np.array([intensity])\n",
    "                    obs, reward, done, _, _ = env.step(action)\n",
    "                    episode_reward += reward\n",
    "                rewards.append(episode_reward)\n",
    "            all_rewards.extend(rewards)\n",
    "        baselines[intensity] = all_rewards\n",
    "    return baselines\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def visualize_baselines(baselines):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(data=[[r for r in baselines[i]] for i in baselines.keys()])\n",
    "    plt.xlabel('Selection Intensity')\n",
    "    plt.ylabel('Total Reward')\n",
    "    plt.title('Baseline Performance for Different Selection Intensities')\n",
    "    plt.xticks(range(len(baselines)), list(baselines.keys()))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "307164f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'genome' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Assuming you have already defined your environment\u001b[39;00m\n\u001b[1;32m      5\u001b[0m config \u001b[38;5;241m=\u001b[39m SimulationConfig(n_markers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, pop_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, h2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, starting_parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m SP \u001b[38;5;241m=\u001b[39m \u001b[43mSimParams\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m visualize_baselines(collect_baselines(env))\n",
      "Cell \u001b[0;32mIn[1], line 186\u001b[0m, in \u001b[0;36mSimParams.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenome \u001b[38;5;241m=\u001b[39m Genome(config\u001b[38;5;241m.\u001b[39mn_markers)\n\u001b[0;32m--> 186\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation \u001b[38;5;241m=\u001b[39m Population(config\u001b[38;5;241m.\u001b[39mpop_size, grab_inbred_parents(\u001b[38;5;241m5\u001b[39m,\u001b[43mgenome\u001b[49m), genome,device)\n\u001b[1;32m    187\u001b[0m f1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mperform_meiosis(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation\u001b[38;5;241m.\u001b[39mhaplotypes, num_crossovers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, num_gametes_per_parent\u001b[38;5;241m=\u001b[39m((\u001b[38;5;241m2000\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation\u001b[38;5;241m.\u001b[39mhaplotypes\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation\u001b[38;5;241m.\u001b[39mhaplotypes\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m100\u001b[39m))\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_next_generation(f1, total_crosses\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'genome' is not defined"
     ]
    }
   ],
   "source": [
    "total_timesteps= 2000\n",
    "max_generations = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Assuming you have already defined your environment\n",
    "config = SimulationConfig(n_markers=500, pop_size=100, h2=1.0, starting_parents=10)\n",
    "SP = SimParams(config)\n",
    "\n",
    "visualize_baselines(collect_baselines(env))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aeed72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just genetic var\n",
    "class SelectionIntensityEnvironment(gym.Env):\n",
    "    def __init__(self, SP, config, max_generations=10):\n",
    "        super(SelectionIntensityEnvironment, self).__init__()\n",
    "        self.SP = SP\n",
    "        self.config = config\n",
    "        self.max_generations = max_generations\n",
    "        self.current_generation = 0\n",
    "        self.founder_population = self.SP.population.haplotypes\n",
    "\n",
    "        self.action_space = gym.spaces.Box(low=0.01, high=0.99, shape=(1,), dtype=np.float32)\n",
    "        #genetic var\n",
    "        self.observation_space = gym.spaces.Box(low=-2, high=-1, shape=(1,), dtype=np.float32)\n",
    "\n",
    "\n",
    "        # self.observation_space = gym.spaces.Dict({\n",
    "        #     \"generation_percent_remaining\": gym.spaces.Box(low=0, high=max_generations, shape=(1,), dtype=np.float32),\n",
    "        #     \"genetic_var\": gym.spaces.Box(low=-np.inf, high=np.inf, shape=(1,), dtype=np.float32),\n",
    "        # })\n",
    "\n",
    "        self.current_population = self.SP.population.haplotypes.clone()\n",
    "        self.phenotypes = self.SP.score_population()\n",
    "\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.current_generation = 0\n",
    "        self.SP.population.haplotypes = self.founder_population.clone()\n",
    "        self.phenotypes = self.SP.score_population()\n",
    "        return self._get_observation(), {}\n",
    "\n",
    "    def _get_observation(self):\n",
    "        return self.phenotypes.var().item()\n",
    "\n",
    "        # return {\n",
    "        #     \"generation_percent_remaining\": (self.max_generations - self.current_generation) / self.max_generations,\n",
    "        #     # \"genetic_var\": self.phenotypes.var().item()\n",
    "        # }\n",
    "\n",
    "    def step(self, action):\n",
    "        selection_intensity = action\n",
    "\n",
    "        selected_haplotypes = self.SP.truncation_selection(selection_intensity, self.phenotypes)\n",
    "        total_crosses = self.config.pop_size\n",
    "        total_gametes_needed = total_crosses * 2  # Each offspring needs 2 gametes\n",
    "        num_parents = selected_haplotypes.shape[0]\n",
    "\n",
    "        # Calculate gametes per parent, rounding up to ensure we have enough\n",
    "        num_gametes_per_parent = -(-total_gametes_needed // num_parents)  # Ceiling division\n",
    "\n",
    "        # Add a small buffer to ensure we have more than enough gametes\n",
    "        num_gametes_per_parent += 2\n",
    "        gametes = self.SP.perform_meiosis(selected_haplotypes, num_crossovers=3, num_gametes_per_parent=num_gametes_per_parent)\n",
    "        self.SP.create_next_generation(gametes, total_crosses)\n",
    "        self.phenotypes = self.SP.score_population()\n",
    "        \n",
    "        self.current_generation += 1\n",
    "        done = self.current_generation >= self.max_generations\n",
    "        # Implement sparse reward\n",
    "        if self.config.sparse_reward:\n",
    "            if done:\n",
    "                # Only give reward at the end of the episode\n",
    "                reward = float(self.phenotypes.max().item())\n",
    "            else:\n",
    "                reward = 0.0\n",
    "        else:\n",
    "            # Dense reward (existing implementation)\n",
    "            reward = float(self.phenotypes.max().item())\n",
    "        observation = self._get_observation()\n",
    "\n",
    "        info = {\n",
    "            'max_phenotype': float(self.phenotypes.max().item()),\n",
    "            'genetic_variance': float(self.phenotypes.var().item()),\n",
    "            'selection_intensity': float(action),\n",
    "            'current_generation': self.current_generation\n",
    "        }\n",
    "\n",
    "        return observation, reward, done, False, info\n",
    "\n",
    "\n",
    "\n",
    "### USAGE\n",
    "\n",
    "from stable_baselines3 import PPO  # or any other RL algorithm you're using\n",
    "tensorboard_log = './ppotb'\n",
    "env = SelectionIntensityEnvironment(SP, config, max_generations=max_generations)\n",
    "# Initialize your environment and model\n",
    "# env = SelectionIntensityEnvironment(SP, config, max_generations=3)\n",
    "model = PPO(\"MlpPolicy\", env, device='cuda', verbose=1, tensorboard_log=tensorboard_log, learning_rate=.0005)\n",
    "# Create the custom callback\n",
    "custom_callback = CustomCallback()\n",
    "# Train the model with the custom callback\n",
    "model.learn(total_timesteps=total_timesteps, callback=custom_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb549463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee444c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66ce5c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef4090",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
