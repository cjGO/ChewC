{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a46138f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/cltng/OneDrive/chatgpt/dev_nbs\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8af6bf36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from typing import Optional, Dict\n",
    "from dataclasses import dataclass\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3 import PPO\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.logger import Figure\n",
    "tensorboard_log = './ppotb'\n",
    "device='cpu'\n",
    "inbred_parent_data = np.load('../nbs/data/g2f_ch10.npy', allow_pickle=True)\n",
    "\n",
    "@dataclass\n",
    "class SimulationConfig:\n",
    "    n_markers: int = 1000\n",
    "    starting_parents: int = 20\n",
    "    pop_size: int = 1000\n",
    "    h2: float = 1.0\n",
    "    sparse_reward: bool = True\n",
    "\n",
    "class Genome:\n",
    "    def __init__(self, n_markers: int):\n",
    "        self.ploidy: int = 2\n",
    "        self.n_markers: int = n_markers\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Genome(ploidy={self.ploidy}, n_markers={self.n_markers})\"\n",
    "\n",
    "class Population:\n",
    "    def __init__(self, pop_size: int, haplotypes:torch.tensor, genome: Genome, device: torch.device):\n",
    "        self.pop_size: int = pop_size\n",
    "        self.genome: Genome = genome\n",
    "        self.haplotypes: torch.Tensor = haplotypes\n",
    "        self.device: torch.device = device\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def to(self, device: torch.device) -> 'Population':\n",
    "        self.device = device\n",
    "        self.haplotypes = self.haplotypes.to(device)\n",
    "        return self\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Population(pop_size={self.pop_size}, genome={self.genome}, device={self.device})\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Trait:\n",
    "    def __init__(self, genome: Genome, population: Population, target_mean: float = 0.0, target_variance: float = 1.0):\n",
    "        self.genome: Genome = genome\n",
    "        self.device: torch.device = population.device\n",
    "        self.target_mean: float = target_mean\n",
    "        self.target_variance: float = target_variance\n",
    "\n",
    "        raw_effects = torch.randn(genome.n_markers, device=self.device)\n",
    "        centered_effects = raw_effects - raw_effects.mean()\n",
    "        dosages = population.haplotypes.sum(dim=1)\n",
    "        founder_values = torch.einsum('ij,j->i', dosages, centered_effects)\n",
    "        founder_mean = founder_values.mean()\n",
    "        founder_var = founder_values.var()\n",
    "\n",
    "        scaling_factor = torch.sqrt(self.target_variance / founder_var)\n",
    "        self.effects: torch.Tensor = centered_effects * scaling_factor\n",
    "        self.intercept: torch.Tensor = (torch.tensor(self.target_mean, device=self.device) - founder_mean).detach()\n",
    "\n",
    "    def to(self, device: torch.device) -> 'Trait':\n",
    "        self.device = device\n",
    "        self.effects = self.effects.to(device)\n",
    "        self.intercept = self.intercept.to(device)\n",
    "        return self\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Trait(target_mean={self.target_mean}, target_variance={self.target_variance}, device={self.device})\"\n",
    "\n",
    "class SimOps:\n",
    "    @staticmethod\n",
    "    def score_population(population: Population, trait: Trait, h2: float = 1.0) -> torch.Tensor:\n",
    "        dosages = population.haplotypes.sum(dim=1)\n",
    "        breeding_values = torch.einsum('ij,j->i', dosages, trait.effects)\n",
    "\n",
    "        bv_var = breeding_values.var()\n",
    "        if bv_var == 0 or h2 >= 1:\n",
    "            return breeding_values\n",
    "\n",
    "        env_variance = (1 - h2) / h2 * bv_var.item()\n",
    "        env_std = torch.sqrt(torch.tensor(env_variance, device=population.device))\n",
    "        env_effects = torch.randn_like(breeding_values) * env_std\n",
    "        return breeding_values + env_effects + trait.intercept\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def truncation_selection(population: Population, phenotypes: torch.Tensor, selection_intensity: float, return_indices: bool = False) -> torch.Tensor:\n",
    "        assert 0 < selection_intensity <= 1, \"Selection intensity must be between 0 and 1\"\n",
    "        assert population.haplotypes.shape[0] == phenotypes.shape[0], \"Mismatch between population size and phenotypes\"\n",
    "        num_select = max(1, min(int(selection_intensity * population.pop_size), population.pop_size - 1))\n",
    "        _, top_indices = torch.topk(phenotypes, num_select)\n",
    "        if return_indices:\n",
    "            return top_indices\n",
    "        return population.haplotypes[top_indices]\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def meiosis(selected_haplotypes: torch.Tensor, num_crossovers: int = 1, num_gametes_per_parent: int = 1) -> torch.Tensor:\n",
    "        num_parents, ploidy, num_markers = selected_haplotypes.shape\n",
    "\n",
    "        # Repeat each parent's haplotypes num_gametes_per_parent times\n",
    "        expanded_haplotypes = selected_haplotypes.repeat_interleave(num_gametes_per_parent, dim=0)\n",
    "\n",
    "        # The rest of the function remains largely the same, but operates on the expanded haplotypes\n",
    "        total_gametes = num_parents * num_gametes_per_parent\n",
    "\n",
    "        crossover_points = torch.randint(1, num_markers, (total_gametes, num_crossovers), device=selected_haplotypes.device)\n",
    "        crossover_points, _ = torch.sort(crossover_points, dim=1)\n",
    "\n",
    "        crossover_mask = torch.zeros((total_gametes, num_markers), dtype=torch.bool, device=selected_haplotypes.device)\n",
    "        crossover_mask.scatter_(1, crossover_points, 1)\n",
    "        crossover_mask = torch.cumsum(crossover_mask, dim=1) % 2 == 1\n",
    "\n",
    "        crossover_mask = crossover_mask.unsqueeze(1).expand(-1, ploidy, -1)\n",
    "\n",
    "        start_chromosome = torch.randint(0, ploidy, (total_gametes, 1), device=selected_haplotypes.device)\n",
    "        start_mask = start_chromosome.unsqueeze(-1).expand(-1, -1, num_markers)\n",
    "\n",
    "        final_mask = crossover_mask ^ start_mask.bool()\n",
    "\n",
    "        offspring_haplotypes = torch.where(final_mask, expanded_haplotypes, expanded_haplotypes.roll(shifts=1, dims=1))\n",
    "\n",
    "        # Return only the first haplotype for each meiosis event\n",
    "        return offspring_haplotypes[:, 0, :]\n",
    "    @staticmethod\n",
    "    def check_cuda(tensor: torch.Tensor, name: str) -> None:\n",
    "        print(f\"{name} is on: {tensor.device}\")\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def random_cross(gamete_tensor: torch.Tensor, total_crosses: int) -> torch.Tensor:\n",
    "        num_gametes, n_markers = gamete_tensor.shape\n",
    "\n",
    "        # Double the gamete tensor until we have enough for the total crosses\n",
    "        while num_gametes < 2 * total_crosses:\n",
    "            gamete_tensor = torch.cat([gamete_tensor, gamete_tensor], dim=0)\n",
    "            num_gametes *= 2\n",
    "\n",
    "        # Randomly select gametes for crossing\n",
    "        gamete_indices = torch.randperm(num_gametes, device=gamete_tensor.device)\n",
    "        parent1_indices = gamete_indices[:total_crosses]\n",
    "        parent2_indices = gamete_indices[total_crosses:2*total_crosses]\n",
    "\n",
    "        # Create the new population haplotype tensor\n",
    "        new_population = torch.stack([\n",
    "            gamete_tensor[parent1_indices],\n",
    "            gamete_tensor[parent2_indices]\n",
    "        ], dim=1)\n",
    "\n",
    "        return new_population\n",
    "    \n",
    "def grab_inbred_parents(starting_parents, genome, device=device):\n",
    "\n",
    "        inbred_data = inbred_parent_data\n",
    "        \n",
    "        if starting_parents > inbred_data.shape[0]:\n",
    "            raise ValueError(\"Total parents requested exceed the number of available parents.\")\n",
    "        if genome.n_markers > inbred_data.shape[2]:\n",
    "            raise ValueError(\"Total markers requested exceed the number of available markers.\")\n",
    "        # Randomly sample parents\n",
    "        sampled_parents_indices = np.random.choice(inbred_data.shape[0], starting_parents, replace=False)\n",
    "        sampled_parents = inbred_data[sampled_parents_indices, :, :]\n",
    "        # Randomly sample markers\n",
    "        sampled_markers_indices = np.random.choice(inbred_data.shape[2], genome.n_markers, replace=False)\n",
    "        return torch.tensor(sampled_parents[:, :, sampled_markers_indices], device=device).float()\n",
    "\n",
    "##################\n",
    "\n",
    "class SimParams:\n",
    "    def __init__(self, config: SimulationConfig):\n",
    "        self.config = config\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.genome = Genome(config.n_markers)\n",
    "        self.population = Population(config.pop_size, grab_inbred_parents(5,self.genome), self.genome,device)\n",
    "        f1 = self.perform_meiosis(self.population.haplotypes, num_crossovers=3, num_gametes_per_parent=((2000//self.population.haplotypes.shape[0]) *self.population.haplotypes.shape[0] + 100))\n",
    "        self.create_next_generation(f1, total_crosses=2000)\n",
    "        num_gametes_per_parent = (self.population.haplotypes.shape[0] / config.pop_size) + 2 \n",
    "        segregating_pop = self.perform_meiosis(self.population.haplotypes, num_crossovers=3, num_gametes_per_parent=100)\n",
    "        self.create_next_generation(segregating_pop, total_crosses=config.pop_size)\n",
    "\n",
    "        \n",
    "        self.trait = Trait(self.genome, self.population)\n",
    "\n",
    "\n",
    "    def score_population(self, h2: Optional[float] = None) -> torch.Tensor:\n",
    "        h2 = h2 if h2 is not None else self.config.h2\n",
    "        return SimOps.score_population(self.population, self.trait, h2)\n",
    "\n",
    "    def truncation_selection(self, selection_intensity: Optional[float] = None, phenotypes: Optional[torch.Tensor] = None, return_indices: bool = False) -> torch.Tensor:\n",
    "        selection_intensity = selection_intensity if selection_intensity is not None else self.config.selection_intensity\n",
    "        if phenotypes is None:\n",
    "            phenotypes = self.score_population()\n",
    "        return SimOps.truncation_selection(self.population, phenotypes, selection_intensity, return_indices)\n",
    "\n",
    "    def check_device(self) -> None:\n",
    "        SimOps.check_cuda(self.population.haplotypes, \"Population haplotypes\")\n",
    "        SimOps.check_cuda(self.trait.effects, \"Trait effects\")\n",
    "        SimOps.check_cuda(self.trait.intercept, \"Trait intercept\")\n",
    "\n",
    "    def to(self, device: torch.device) -> 'SimParams':\n",
    "        self.device = device\n",
    "        self.population = self.population.to(device)\n",
    "        self.trait = self.trait.to(device)\n",
    "        return self\n",
    "    def perform_meiosis(self, selected_haplotypes: torch.Tensor, num_crossovers: int = 1, num_gametes_per_parent: int = 1) -> torch.Tensor:\n",
    "        return SimOps.meiosis(selected_haplotypes, num_crossovers, num_gametes_per_parent)\n",
    "\n",
    "    def create_next_generation(self, gametes: torch.Tensor, total_crosses: int) -> None:\n",
    "        new_population_haplotypes = SimOps.random_cross(gametes, total_crosses)\n",
    "        # assert new_population_haplotypes.shape[0] == self.config.pop_size, \"Population size changed unexpectedly\"\n",
    "        self.population.haplotypes = new_population_haplotypes\n",
    "        self.population.pop_size = total_crosses\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "\n",
    "class SelectionIntensityEnvironment(gym.Env):\n",
    "    def __init__(self, SP, config, max_generations=10):\n",
    "        super(SelectionIntensityEnvironment, self).__init__()\n",
    "        self.SP = SP\n",
    "        self.config = config\n",
    "        self.max_generations = max_generations\n",
    "        self.current_generation = 0\n",
    "        self.founder_population = self.SP.population.haplotypes\n",
    "        self.action_space = gym.spaces.Box(low=0.01, high=0.99, shape=(1,), dtype=np.float32)\n",
    "        self.observation_space = gym.spaces.Dict({\n",
    "            \"generation_percent_remaining\": gym.spaces.Box(low=0, high=1, shape=(1,), dtype=np.float32),\n",
    "            \"genetic_var\": gym.spaces.Box(low=0, high=np.inf, shape=(1,), dtype=np.float32),\n",
    "            \"selection_differential\": gym.spaces.Box(low=-np.inf, high=np.inf, shape=(1,), dtype=np.float32),\n",
    "            \"average_episode_actions\": gym.spaces.Box(low=0, high=1, shape=(1,), dtype=np.float32),\n",
    "            \"inbreeding_coefficient\": gym.spaces.Box(low=0, high=1, shape=(1,), dtype=np.float32),\n",
    "        })\n",
    "        self.current_population = self.SP.population.haplotypes.clone()\n",
    "        self.phenotypes = self.SP.score_population()\n",
    "        self.action_history = []\n",
    "        self.inbreeding_coefficient = self.calculate_inbreeding_coefficient()\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.current_generation = 0\n",
    "        self.SP.population.haplotypes = self.founder_population.clone()\n",
    "        self.phenotypes = self.SP.score_population()\n",
    "        self.action_history = []\n",
    "        self.inbreeding_coefficient = self.calculate_inbreeding_coefficient()\n",
    "        return self._get_observation(), {}\n",
    "\n",
    "    def _get_observation(self):\n",
    "        return {\n",
    "            \"generation_percent_remaining\": (self.max_generations - self.current_generation) / self.max_generations,\n",
    "            \"genetic_var\": self.phenotypes.var().item(),\n",
    "            \"selection_differential\": self.calculate_selection_differential(),\n",
    "            \"average_episode_actions\": np.mean(self.action_history) if self.action_history else 0,\n",
    "            \"inbreeding_coefficient\": self.inbreeding_coefficient,\n",
    "        }\n",
    "\n",
    "    def calculate_inbreeding_coefficient(self):\n",
    "        heterozygosity = (self.SP.population.haplotypes[:, 0, :] != self.SP.population.haplotypes[:, 1, :]).float().mean()\n",
    "        inbreeding_coeff = 1 - (heterozygosity / 0.5)\n",
    "        return inbreeding_coeff.item()\n",
    "\n",
    "    def calculate_selection_differential(self):\n",
    "        if not hasattr(self, 'last_selected_phenotypes'):\n",
    "            return 0\n",
    "        return (self.last_selected_phenotypes.mean() - self.phenotypes.mean()).item()\n",
    "\n",
    "    def step(self, action):\n",
    "        selection_intensity = action[0]\n",
    "        selected_indices = self.SP.truncation_selection(selection_intensity, self.phenotypes, return_indices=True)\n",
    "        self.last_selected_phenotypes = self.phenotypes[selected_indices]\n",
    "        selected_haplotypes = self.SP.population.haplotypes[selected_indices]\n",
    "        \n",
    "        self.last_selected_phenotypes = self.phenotypes[self.SP.truncation_selection(selection_intensity, self.phenotypes, return_indices=True)]\n",
    "        \n",
    "        total_crosses = self.config.pop_size\n",
    "        total_gametes_needed = total_crosses * 2\n",
    "        num_parents = selected_haplotypes.shape[0]\n",
    "        num_gametes_per_parent = -(-total_gametes_needed // num_parents) + 2\n",
    "        \n",
    "        gametes = self.SP.perform_meiosis(selected_haplotypes, num_crossovers=3, num_gametes_per_parent=num_gametes_per_parent)\n",
    "        self.SP.create_next_generation(gametes, total_crosses)\n",
    "        self.phenotypes = self.SP.score_population()\n",
    "        self.inbreeding_coefficient = self.calculate_inbreeding_coefficient()\n",
    "        self.current_generation += 1\n",
    "\n",
    "        done = self.current_generation >= self.max_generations\n",
    "\n",
    "        if self.config.sparse_reward:\n",
    "            reward = float(self.phenotypes.max().item()) if done else 0.0\n",
    "        else:\n",
    "            reward = float(self.phenotypes.max().item())\n",
    "\n",
    "        observation = self._get_observation()\n",
    "        info = {\n",
    "            'max_phenotype': float(self.phenotypes.max().item()),\n",
    "            'genetic_variance': float(self.phenotypes.var().item()),\n",
    "            'selection_intensity': float(action[0]),\n",
    "            'current_generation': self.current_generation,\n",
    "            'inbreeding_coefficient': self.inbreeding_coefficient,\n",
    "        }\n",
    "\n",
    "        return observation, reward, done, False, info\n",
    "\n",
    "total_timesteps= 1000000\n",
    "max_generations = 5\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming you have already defined your environment\n",
    "config = SimulationConfig(n_markers=50, pop_size=100, h2=1.0, starting_parents=1)\n",
    "SP = SimParams(config)\n",
    "env =  SelectionIntensityEnvironment(SP, config, max_generations=max_generations)\n",
    "\n",
    "# Set up the environment\n",
    "\n",
    "# Set up the model and callback\n",
    "model = PPO(\"MultiInputPolicy\", env, device='cuda', verbose=1, tensorboard_log=tensorboard_log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1462f3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./ppotb/PPO_49\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 5        |\n",
      "|    ep_rew_mean     | 9.27     |\n",
      "| time/              |          |\n",
      "|    fps             | 601      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 9.17        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 586         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012921128 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | -0.0106     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.502       |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    std                  | 0.98        |\n",
      "|    value_loss           | 17.8        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 5          |\n",
      "|    ep_rew_mean          | 9.43       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 608        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 10         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01185701 |\n",
      "|    clip_fraction        | 0.0805     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.36      |\n",
      "|    explained_variance   | -0.204     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.478      |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0154    |\n",
      "|    std                  | 0.919      |\n",
      "|    value_loss           | 1.04       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 9.56        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 616         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011015909 |\n",
      "|    clip_fraction        | 0.0974      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.00248     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.303       |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    std                  | 0.874       |\n",
      "|    value_loss           | 0.838       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 9.77        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 607         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009801584 |\n",
      "|    clip_fraction        | 0.0915      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.0296      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.36        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 0.853       |\n",
      "|    value_loss           | 0.818       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 9.92        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 602         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009369615 |\n",
      "|    clip_fraction        | 0.074       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.0805      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.212       |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00836    |\n",
      "|    std                  | 0.817       |\n",
      "|    value_loss           | 0.535       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 10          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 606         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008777624 |\n",
      "|    clip_fraction        | 0.0712      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.131       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.232       |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00737    |\n",
      "|    std                  | 0.785       |\n",
      "|    value_loss           | 0.519       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5            |\n",
      "|    ep_rew_mean          | 10           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 603          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068141515 |\n",
      "|    clip_fraction        | 0.0841       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.16        |\n",
      "|    explained_variance   | 0.148        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.147        |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00996     |\n",
      "|    std                  | 0.754        |\n",
      "|    value_loss           | 0.458        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5            |\n",
      "|    ep_rew_mean          | 10.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 605          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066706124 |\n",
      "|    clip_fraction        | 0.0595       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.11        |\n",
      "|    explained_variance   | 0.17         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.186        |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00627     |\n",
      "|    std                  | 0.72         |\n",
      "|    value_loss           | 0.391        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5            |\n",
      "|    ep_rew_mean          | 10.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 609          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 33           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049457094 |\n",
      "|    clip_fraction        | 0.0452       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.184        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.166        |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00577     |\n",
      "|    std                  | 0.694        |\n",
      "|    value_loss           | 0.394        |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5            |\n",
      "|    ep_rew_mean          | 10.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 611          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 36           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051163547 |\n",
      "|    clip_fraction        | 0.0612       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0.164        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.227        |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00586     |\n",
      "|    std                  | 0.666        |\n",
      "|    value_loss           | 0.375        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5            |\n",
      "|    ep_rew_mean          | 10.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 610          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 40           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051118275 |\n",
      "|    clip_fraction        | 0.0383       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.995       |\n",
      "|    explained_variance   | 0.176        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.172        |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00291     |\n",
      "|    std                  | 0.646        |\n",
      "|    value_loss           | 0.401        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5            |\n",
      "|    ep_rew_mean          | 10.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 612          |\n",
      "|    iterations           | 13           |\n",
      "|    time_elapsed         | 43           |\n",
      "|    total_timesteps      | 26624        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037287408 |\n",
      "|    clip_fraction        | 0.0388       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.964       |\n",
      "|    explained_variance   | 0.177        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.177        |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00235     |\n",
      "|    std                  | 0.626        |\n",
      "|    value_loss           | 0.357        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 5          |\n",
      "|    ep_rew_mean          | 10.2       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 614        |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 46         |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00523181 |\n",
      "|    clip_fraction        | 0.0232     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.921     |\n",
      "|    explained_variance   | 0.135      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.117      |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | -0.00308   |\n",
      "|    std                  | 0.594      |\n",
      "|    value_loss           | 0.354      |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5            |\n",
      "|    ep_rew_mean          | 10.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 615          |\n",
      "|    iterations           | 15           |\n",
      "|    time_elapsed         | 49           |\n",
      "|    total_timesteps      | 30720        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054329718 |\n",
      "|    clip_fraction        | 0.0483       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.872       |\n",
      "|    explained_variance   | 0.185        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.152        |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    std                  | 0.568        |\n",
      "|    value_loss           | 0.37         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5            |\n",
      "|    ep_rew_mean          | 10.1         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 612          |\n",
      "|    iterations           | 16           |\n",
      "|    time_elapsed         | 53           |\n",
      "|    total_timesteps      | 32768        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046701087 |\n",
      "|    clip_fraction        | 0.0349       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.833       |\n",
      "|    explained_variance   | 0.164        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.152        |\n",
      "|    n_updates            | 150          |\n",
      "|    policy_gradient_loss | -0.00259     |\n",
      "|    std                  | 0.547        |\n",
      "|    value_loss           | 0.355        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5            |\n",
      "|    ep_rew_mean          | 10.2         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 613          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 56           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036188997 |\n",
      "|    clip_fraction        | 0.0259       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.787       |\n",
      "|    explained_variance   | 0.148        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.162        |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    std                  | 0.519        |\n",
      "|    value_loss           | 0.37         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 10.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 615         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006772049 |\n",
      "|    clip_fraction        | 0.0484      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.744      |\n",
      "|    explained_variance   | 0.166       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.15        |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.00341    |\n",
      "|    std                  | 0.502       |\n",
      "|    value_loss           | 0.335       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5            |\n",
      "|    ep_rew_mean          | 10.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 616          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 63           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051191365 |\n",
      "|    clip_fraction        | 0.0253       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.701       |\n",
      "|    explained_variance   | 0.163        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.137        |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00266     |\n",
      "|    std                  | 0.476        |\n",
      "|    value_loss           | 0.334        |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5            |\n",
      "|    ep_rew_mean          | 10.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 616          |\n",
      "|    iterations           | 20           |\n",
      "|    time_elapsed         | 66           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044372818 |\n",
      "|    clip_fraction        | 0.0516       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.66        |\n",
      "|    explained_variance   | 0.164        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.161        |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00266     |\n",
      "|    std                  | 0.462        |\n",
      "|    value_loss           | 0.346        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5           |\n",
      "|    ep_rew_mean          | 10.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 617         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003014702 |\n",
      "|    clip_fraction        | 0.0331      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.632      |\n",
      "|    explained_variance   | 0.19        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.264       |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00119    |\n",
      "|    std                  | 0.45        |\n",
      "|    value_loss           | 0.379       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5            |\n",
      "|    ep_rew_mean          | 10.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 618          |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 72           |\n",
      "|    total_timesteps      | 45056        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061206757 |\n",
      "|    clip_fraction        | 0.0428       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.597       |\n",
      "|    explained_variance   | 0.157        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.287        |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    std                  | 0.431        |\n",
      "|    value_loss           | 0.305        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5            |\n",
      "|    ep_rew_mean          | 10.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 619          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 76           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034615546 |\n",
      "|    clip_fraction        | 0.0286       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.558       |\n",
      "|    explained_variance   | 0.18         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.152        |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00142     |\n",
      "|    std                  | 0.416        |\n",
      "|    value_loss           | 0.314        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5            |\n",
      "|    ep_rew_mean          | 10.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 620          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 79           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037654452 |\n",
      "|    clip_fraction        | 0.0221       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.527       |\n",
      "|    explained_variance   | 0.206        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.164        |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.000736    |\n",
      "|    std                  | 0.405        |\n",
      "|    value_loss           | 0.338        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5            |\n",
      "|    ep_rew_mean          | 10.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 620          |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 82           |\n",
      "|    total_timesteps      | 51200        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039065485 |\n",
      "|    clip_fraction        | 0.0244       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.493       |\n",
      "|    explained_variance   | 0.159        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.142        |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00152     |\n",
      "|    std                  | 0.39         |\n",
      "|    value_loss           | 0.348        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 5            |\n",
      "|    ep_rew_mean          | 10.3         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 621          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 85           |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029571822 |\n",
      "|    clip_fraction        | 0.0297       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.457       |\n",
      "|    explained_variance   | 0.174        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.138        |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00132     |\n",
      "|    std                  | 0.376        |\n",
      "|    value_loss           | 0.312        |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 5          |\n",
      "|    ep_rew_mean          | 10.3       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 619        |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 89         |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00345833 |\n",
      "|    clip_fraction        | 0.0221     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.422     |\n",
      "|    explained_variance   | 0.184      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.157      |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.00173   |\n",
      "|    std                  | 0.364      |\n",
      "|    value_loss           | 0.337      |\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "model.learn(total_timesteps=total_timesteps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f200304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9508b26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74619f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
