{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f785dfa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a46138f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/cltng/OneDrive/chatgpt/dev_nbs\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c8e1fc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Optional, Dict\n",
    "from dataclasses import dataclass\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3 import PPO\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.logger import Figure\n",
    "tensorboard_log = './ppotb'\n",
    "device='cpu'\n",
    "inbred_parent_data = np.load('../nbs/data/g2f_ch10.npy', allow_pickle=True)\n",
    "\n",
    "@dataclass\n",
    "class SimulationConfig:\n",
    "    n_markers: int = 1000\n",
    "    starting_parents: int = 20\n",
    "    pop_size: int = 1000\n",
    "    h2: float = 1.0\n",
    "    sparse_reward: bool = True\n",
    "\n",
    "class Genome:\n",
    "    def __init__(self, n_markers: int):\n",
    "        self.ploidy: int = 2\n",
    "        self.n_markers: int = n_markers\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Genome(ploidy={self.ploidy}, n_markers={self.n_markers})\"\n",
    "\n",
    "class Population:\n",
    "    def __init__(self, pop_size: int, haplotypes:torch.tensor, genome: Genome, device: torch.device):\n",
    "        self.pop_size: int = pop_size\n",
    "        self.genome: Genome = genome\n",
    "        self.haplotypes: torch.Tensor = haplotypes\n",
    "        self.device: torch.device = device\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    def to(self, device: torch.device) -> 'Population':\n",
    "        self.device = device\n",
    "        self.haplotypes = self.haplotypes.to(device)\n",
    "        return self\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Population(pop_size={self.pop_size}, genome={self.genome}, device={self.device})\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Trait:\n",
    "    def __init__(self, genome: Genome, population: Population, target_mean: float = 0.0, target_variance: float = 1.0):\n",
    "        self.genome: Genome = genome\n",
    "        self.device: torch.device = population.device\n",
    "        self.target_mean: float = target_mean\n",
    "        self.target_variance: float = target_variance\n",
    "\n",
    "        raw_effects = torch.randn(genome.n_markers, device=self.device)\n",
    "        centered_effects = raw_effects - raw_effects.mean()\n",
    "        dosages = population.haplotypes.sum(dim=1)\n",
    "        founder_values = torch.einsum('ij,j->i', dosages, centered_effects)\n",
    "        founder_mean = founder_values.mean()\n",
    "        founder_var = founder_values.var()\n",
    "\n",
    "        scaling_factor = torch.sqrt(self.target_variance / founder_var)\n",
    "        self.effects: torch.Tensor = centered_effects * scaling_factor\n",
    "        self.intercept: torch.Tensor = (torch.tensor(self.target_mean, device=self.device) - founder_mean).detach()\n",
    "\n",
    "    def to(self, device: torch.device) -> 'Trait':\n",
    "        self.device = device\n",
    "        self.effects = self.effects.to(device)\n",
    "        self.intercept = self.intercept.to(device)\n",
    "        return self\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Trait(target_mean={self.target_mean}, target_variance={self.target_variance}, device={self.device})\"\n",
    "\n",
    "class SimOps:\n",
    "    @staticmethod\n",
    "    def score_population(population: Population, trait: Trait, h2: float = 1.0) -> torch.Tensor:\n",
    "        dosages = population.haplotypes.sum(dim=1)\n",
    "        breeding_values = torch.einsum('ij,j->i', dosages, trait.effects)\n",
    "\n",
    "        bv_var = breeding_values.var()\n",
    "        if bv_var == 0 or h2 >= 1:\n",
    "            return breeding_values\n",
    "\n",
    "        env_variance = (1 - h2) / h2 * bv_var.item()\n",
    "        env_std = torch.sqrt(torch.tensor(env_variance, device=population.device))\n",
    "        env_effects = torch.randn_like(breeding_values) * env_std\n",
    "        return breeding_values + env_effects + trait.intercept\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def truncation_selection(population: Population, phenotypes: torch.Tensor, selection_intensity: float, return_indices: bool = False) -> torch.Tensor:\n",
    "        assert 0 < selection_intensity <= 1, \"Selection intensity must be between 0 and 1\"\n",
    "        assert population.haplotypes.shape[0] == phenotypes.shape[0], \"Mismatch between population size and phenotypes\"\n",
    "        num_select = max(1, min(int(selection_intensity * population.pop_size), population.pop_size - 1))\n",
    "        _, top_indices = torch.topk(phenotypes, num_select)\n",
    "        if return_indices:\n",
    "            return top_indices\n",
    "        return population.haplotypes[top_indices]\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def meiosis(selected_haplotypes: torch.Tensor, num_crossovers: int = 1, num_gametes_per_parent: int = 1) -> torch.Tensor:\n",
    "        num_parents, ploidy, num_markers = selected_haplotypes.shape\n",
    "\n",
    "        # Repeat each parent's haplotypes num_gametes_per_parent times\n",
    "        expanded_haplotypes = selected_haplotypes.repeat_interleave(num_gametes_per_parent, dim=0)\n",
    "\n",
    "        # The rest of the function remains largely the same, but operates on the expanded haplotypes\n",
    "        total_gametes = num_parents * num_gametes_per_parent\n",
    "\n",
    "        crossover_points = torch.randint(1, num_markers, (total_gametes, num_crossovers), device=selected_haplotypes.device)\n",
    "        crossover_points, _ = torch.sort(crossover_points, dim=1)\n",
    "\n",
    "        crossover_mask = torch.zeros((total_gametes, num_markers), dtype=torch.bool, device=selected_haplotypes.device)\n",
    "        crossover_mask.scatter_(1, crossover_points, 1)\n",
    "        crossover_mask = torch.cumsum(crossover_mask, dim=1) % 2 == 1\n",
    "\n",
    "        crossover_mask = crossover_mask.unsqueeze(1).expand(-1, ploidy, -1)\n",
    "\n",
    "        start_chromosome = torch.randint(0, ploidy, (total_gametes, 1), device=selected_haplotypes.device)\n",
    "        start_mask = start_chromosome.unsqueeze(-1).expand(-1, -1, num_markers)\n",
    "\n",
    "        final_mask = crossover_mask ^ start_mask.bool()\n",
    "\n",
    "        offspring_haplotypes = torch.where(final_mask, expanded_haplotypes, expanded_haplotypes.roll(shifts=1, dims=1))\n",
    "\n",
    "        # Return only the first haplotype for each meiosis event\n",
    "        return offspring_haplotypes[:, 0, :]\n",
    "    @staticmethod\n",
    "    def check_cuda(tensor: torch.Tensor, name: str) -> None:\n",
    "        print(f\"{name} is on: {tensor.device}\")\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def random_cross(gamete_tensor: torch.Tensor, total_crosses: int) -> torch.Tensor:\n",
    "        num_gametes, n_markers = gamete_tensor.shape\n",
    "\n",
    "        # Double the gamete tensor until we have enough for the total crosses\n",
    "        while num_gametes < 2 * total_crosses:\n",
    "            gamete_tensor = torch.cat([gamete_tensor, gamete_tensor], dim=0)\n",
    "            num_gametes *= 2\n",
    "\n",
    "        # Randomly select gametes for crossing\n",
    "        gamete_indices = torch.randperm(num_gametes, device=gamete_tensor.device)\n",
    "        parent1_indices = gamete_indices[:total_crosses]\n",
    "        parent2_indices = gamete_indices[total_crosses:2*total_crosses]\n",
    "\n",
    "        # Create the new population haplotype tensor\n",
    "        new_population = torch.stack([\n",
    "            gamete_tensor[parent1_indices],\n",
    "            gamete_tensor[parent2_indices]\n",
    "        ], dim=1)\n",
    "\n",
    "        return new_population\n",
    "    \n",
    "def grab_inbred_parents(starting_parents, genome, device=device):\n",
    "\n",
    "        inbred_data = inbred_parent_data\n",
    "        \n",
    "        if starting_parents > inbred_data.shape[0]:\n",
    "            raise ValueError(\"Total parents requested exceed the number of available parents.\")\n",
    "        if genome.n_markers > inbred_data.shape[2]:\n",
    "            raise ValueError(\"Total markers requested exceed the number of available markers.\")\n",
    "        # Randomly sample parents\n",
    "        sampled_parents_indices = np.random.choice(inbred_data.shape[0], starting_parents, replace=False)\n",
    "        sampled_parents = inbred_data[sampled_parents_indices, :, :]\n",
    "        # Randomly sample markers\n",
    "        sampled_markers_indices = np.random.choice(inbred_data.shape[2], genome.n_markers, replace=False)\n",
    "        return torch.tensor(sampled_parents[:, :, sampled_markers_indices], device=device).float()\n",
    "\n",
    "##################\n",
    "\n",
    "class SimParams:\n",
    "    def __init__(self, config: SimulationConfig):\n",
    "        self.config = config\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.genome = Genome(config.n_markers)\n",
    "        self.population = Population(config.pop_size, grab_inbred_parents(5,self.genome), self.genome,device)\n",
    "        f1 = self.perform_meiosis(self.population.haplotypes, num_crossovers=3, num_gametes_per_parent=((2000//self.population.haplotypes.shape[0]) *self.population.haplotypes.shape[0] + 100))\n",
    "        self.create_next_generation(f1, total_crosses=2000)\n",
    "        num_gametes_per_parent = (self.population.haplotypes.shape[0] / config.pop_size) + 2 \n",
    "        segregating_pop = self.perform_meiosis(self.population.haplotypes, num_crossovers=3, num_gametes_per_parent=100)\n",
    "        self.create_next_generation(segregating_pop, total_crosses=config.pop_size)\n",
    "\n",
    "        \n",
    "        self.trait = Trait(self.genome, self.population)\n",
    "        # Calculate initial statistics for normalization\n",
    "        initial_phenotypes = self.score_population()\n",
    "        self.initial_max_phenotype = initial_phenotypes.max().item()\n",
    "        self.initial_phenotype_std = initial_phenotypes.std().item()\n",
    "\n",
    "    def normalize_reward(self, reward: float) -> float:\n",
    "        \"\"\"Normalize the reward based on initial population statistics.\"\"\"\n",
    "        normalized_reward = (reward - self.initial_max_phenotype) / self.initial_phenotype_std\n",
    "        return normalized_reward\n",
    "    \n",
    "    def score_population(self, h2: Optional[float] = None) -> torch.Tensor:\n",
    "        h2 = h2 if h2 is not None else self.config.h2\n",
    "        return SimOps.score_population(self.population, self.trait, h2)\n",
    "\n",
    "    def truncation_selection(self, selection_intensity: Optional[float] = None, phenotypes: Optional[torch.Tensor] = None, return_indices: bool = False) -> torch.Tensor:\n",
    "        selection_intensity = selection_intensity if selection_intensity is not None else self.config.selection_intensity\n",
    "        if phenotypes is None:\n",
    "            phenotypes = self.score_population()\n",
    "        return SimOps.truncation_selection(self.population, phenotypes, selection_intensity, return_indices)\n",
    "\n",
    "    def check_device(self) -> None:\n",
    "        SimOps.check_cuda(self.population.haplotypes, \"Population haplotypes\")\n",
    "        SimOps.check_cuda(self.trait.effects, \"Trait effects\")\n",
    "        SimOps.check_cuda(self.trait.intercept, \"Trait intercept\")\n",
    "\n",
    "    def to(self, device: torch.device) -> 'SimParams':\n",
    "        self.device = device\n",
    "        self.population = self.population.to(device)\n",
    "        self.trait = self.trait.to(device)\n",
    "        return self\n",
    "    def perform_meiosis(self, selected_haplotypes: torch.Tensor, num_crossovers: int = 1, num_gametes_per_parent: int = 1) -> torch.Tensor:\n",
    "        return SimOps.meiosis(selected_haplotypes, num_crossovers, num_gametes_per_parent)\n",
    "\n",
    "    def create_next_generation(self, gametes: torch.Tensor, total_crosses: int) -> None:\n",
    "        new_population_haplotypes = SimOps.random_cross(gametes, total_crosses)\n",
    "        # assert new_population_haplotypes.shape[0] == self.config.pop_size, \"Population size changed unexpectedly\"\n",
    "        self.population.haplotypes = new_population_haplotypes\n",
    "        self.population.pop_size = total_crosses\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "\n",
    "class SelectionIntensityEnvironment(gym.Env):\n",
    "    def __init__(self, SP, config, max_generations=10):\n",
    "        super(SelectionIntensityEnvironment, self).__init__()\n",
    "        self.SP = SP\n",
    "        self.config = config\n",
    "        self.max_generations = max_generations\n",
    "        self.current_generation = 0\n",
    "        self.founder_population = self.SP.population.haplotypes\n",
    "        self.action_space = gym.spaces.Box(low=-1, high=1, shape=(1,), dtype=np.float32)\n",
    "        self.observation_space = gym.spaces.Dict({\n",
    "            \"generation_percent_remaining\": gym.spaces.Box(low=0, high=1, shape=(1,), dtype=np.float32),\n",
    "            \"genetic_var\": gym.spaces.Box(low=0, high=np.inf, shape=(1,), dtype=np.float32),\n",
    "            \"selection_differential\": gym.spaces.Box(low=-np.inf, high=np.inf, shape=(1,), dtype=np.float32),\n",
    "            \"average_episode_actions\": gym.spaces.Box(low=0, high=1, shape=(1,), dtype=np.float32),\n",
    "#             \"inbreeding_coefficient\": gym.spaces.Box(low=0, high=1, shape=(1,), dtype=np.float32),\n",
    "        })\n",
    "        self.current_population = self.SP.population.haplotypes.clone()\n",
    "        self.phenotypes = self.SP.score_population()\n",
    "        self.action_history = []\n",
    "        self.inbreeding_coefficient = self.calculate_inbreeding_coefficient()\n",
    "        self.last_selected_phenotypes = None\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.current_generation = 0\n",
    "        self.SP.population.haplotypes = self.founder_population.clone()\n",
    "        self.phenotypes = self.SP.score_population()\n",
    "        self.action_history = []\n",
    "        self.inbreeding_coefficient = self.calculate_inbreeding_coefficient()\n",
    "        self.last_selected_phenotypes = None\n",
    "        return self._get_observation(), {}\n",
    "\n",
    "    def _get_observation(self):\n",
    "        return {\n",
    "            \"generation_percent_remaining\": np.array([(self.max_generations - self.current_generation) / self.max_generations], dtype=np.float32),\n",
    "            \"genetic_var\": np.array([self.phenotypes.var().item()], dtype=np.float32),\n",
    "            \"selection_differential\": np.array([self.calculate_selection_differential()], dtype=np.float32),\n",
    "            \"average_episode_actions\": np.array([np.mean(self.action_history) if self.action_history else 0], dtype=np.float32),\n",
    "#             \"inbreeding_coefficient\": np.array([self.inbreeding_coefficient], dtype=np.float32),\n",
    "        }\n",
    "\n",
    "    def calculate_inbreeding_coefficient(self):\n",
    "        heterozygosity = (self.SP.population.haplotypes[:, 0, :] != self.SP.population.haplotypes[:, 1, :]).float().mean()\n",
    "        inbreeding_coeff = 1 - (heterozygosity / 0.5)\n",
    "        return inbreeding_coeff.item()\n",
    "\n",
    "    def calculate_selection_differential(self):\n",
    "        if self.last_selected_phenotypes is None:\n",
    "            return 0\n",
    "\n",
    "        # Calculate the raw selection differential\n",
    "        raw_differential = (self.last_selected_phenotypes.mean() - self.phenotypes.mean()).item()\n",
    "\n",
    "        # Normalize by the phenotypic standard deviation\n",
    "        phenotypic_std = self.phenotypes.std().item()\n",
    "\n",
    "        if phenotypic_std == 0:\n",
    "            return 0  # Avoid division by zero\n",
    "\n",
    "        normalized_differential = raw_differential / phenotypic_std\n",
    "\n",
    "        return normalized_differential\n",
    "\n",
    "    def step(self, action):\n",
    "        # Rescale action from [-1, 1] to [0.01, 0.99]\n",
    "        selection_intensity = (action[0] + 1) / 2 * 0.98 + 0.01\n",
    "        self.action_history.append(selection_intensity)\n",
    "\n",
    "\n",
    "        # Select parents\n",
    "        selected_indices = self.SP.truncation_selection(selection_intensity, self.phenotypes, return_indices=True)\n",
    "        self.last_selected_phenotypes = self.phenotypes[selected_indices]\n",
    "        selected_haplotypes = self.SP.population.haplotypes[selected_indices]\n",
    "\n",
    "        # Calculate selection differential before creating the next generation\n",
    "        self.selection_differential = self.calculate_selection_differential()\n",
    "\n",
    "        # Create next generation\n",
    "        total_crosses = self.config.pop_size\n",
    "        total_gametes_needed = total_crosses * 2\n",
    "        num_parents = selected_haplotypes.shape[0]\n",
    "        num_gametes_per_parent = -(-total_gametes_needed // num_parents) + 2\n",
    "        gametes = self.SP.perform_meiosis(selected_haplotypes, num_crossovers=3, num_gametes_per_parent=num_gametes_per_parent)\n",
    "        self.SP.create_next_generation(gametes, total_crosses)\n",
    "\n",
    "        # Update phenotypes and other variables for the new generation\n",
    "        self.phenotypes = self.SP.score_population()\n",
    "        self.inbreeding_coefficient = self.calculate_inbreeding_coefficient()\n",
    "        self.current_generation += 1\n",
    "\n",
    "        done = self.current_generation >= self.max_generations\n",
    "\n",
    "        if self.config.sparse_reward:\n",
    "            raw_reward = float(self.phenotypes.max().item()) if done else 0.0\n",
    "        else:\n",
    "            raw_reward = float(self.phenotypes.max().item())\n",
    "        reward = self.SP.normalize_reward(raw_reward)\n",
    "\n",
    "        observation = self._get_observation()\n",
    "        info = {\n",
    "            'max_phenotype': float(self.phenotypes.max().item()),\n",
    "            'genetic_variance': float(self.phenotypes.var().item()),\n",
    "            'selection_intensity': float(action[0]),\n",
    "            'selection_differential': self.selection_differential,\n",
    "            'current_generation': self.current_generation,\n",
    "#             'inbreeding_coefficient': self.inbreeding_coefficient,\n",
    "        }\n",
    "\n",
    "        return observation, reward, done, False, info\n",
    "    \n",
    "    \n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "\n",
    "class GeneralizedVisualizationCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0, log_freq=2000, baseline_value=None, best_action=None, baseline_results=None):\n",
    "        super().__init__(verbose)\n",
    "        self.data = defaultdict(lambda: defaultdict(list))\n",
    "        self.log_freq = log_freq\n",
    "        self.excluded_metrics = ['TimeLimit.truncated', 'current_generation']\n",
    "        self.baseline_value = baseline_value\n",
    "        self.best_action = best_action\n",
    "        self.baseline_results = baseline_results\n",
    "        \n",
    "    def _on_step(self) -> bool:\n",
    "        info = self.locals['infos'][0]\n",
    "        obs = self.locals['new_obs']\n",
    "        \n",
    "        current_generation = info['current_generation']\n",
    "        \n",
    "        # Track all scalar values from the observation space\n",
    "        for key, value in obs.items():\n",
    "            if np.isscalar(value) and key not in self.excluded_metrics:\n",
    "                self.data[key][current_generation].append(value)\n",
    "        \n",
    "        # Also track any scalar values from the info dict\n",
    "        for key, value in info.items():\n",
    "            if np.isscalar(value) and key not in self.excluded_metrics:\n",
    "                self.data[key][current_generation].append(value)\n",
    "\n",
    "        if self.num_timesteps % self.log_freq == 0:\n",
    "            self.visualize()\n",
    "\n",
    "        return True\n",
    "    \n",
    "    def action_to_selection_intensity(self,action):\n",
    "        return (action + 1) / 2 * 0.98 + 0.01\n",
    "\n",
    "    def visualize(self, window_size=100):\n",
    "        num_metrics = len(self.data)\n",
    "        fig, axes = plt.subplots(num_metrics, 1, figsize=(12, 6*num_metrics), sharex=True)\n",
    "        if num_metrics == 1:\n",
    "            axes = [axes]\n",
    "\n",
    "        for idx, (metric, generations) in enumerate(self.data.items()):\n",
    "            ax = axes[idx]\n",
    "            num_generations = len(generations)\n",
    "            blue_cmap = plt.cm.Blues\n",
    "            red_cmap = plt.cm.Reds\n",
    "            blue_colors = blue_cmap(np.linspace(0.3, 1, num_generations))\n",
    "            red_colors = red_cmap(np.linspace(0.3, 1, num_generations))\n",
    "\n",
    "            for i, (generation, values) in enumerate(generations.items()):\n",
    "                steps = np.arange(len(values))\n",
    "                if metric == 'selection_intensity':\n",
    "                    values = [self.action_to_selection_intensity(v) for v in values]\n",
    "\n",
    "                # Calculate rolling moving average with specified window size\n",
    "                rolling_avg = np.convolve(values, np.ones(window_size), 'valid') / window_size\n",
    "                rolling_steps = steps[window_size-1:]\n",
    "\n",
    "                ax.plot(rolling_steps, rolling_avg, label=f'Agent {generation}', color=blue_colors[i])\n",
    "                ax.set_title(f'{metric.capitalize()} per Generation')\n",
    "                ax.set_ylabel(f'Rolling Avg {metric.capitalize()}')\n",
    "                ax.grid(True)\n",
    "\n",
    "            # Add baseline results for max_phenotype and genetic_variance with gradient\n",
    "            if self.baseline_results is not None:\n",
    "                if metric == 'max_phenotype':\n",
    "                    baseline_data = self.baseline_results[0]\n",
    "                    for gen, value in enumerate(baseline_data):\n",
    "                        ax.axhline(y=value, color=red_colors[gen], linestyle='--', alpha=0.7, label=f'Baseline {gen+1}')\n",
    "                elif metric == 'genetic_variance':\n",
    "                    baseline_data = self.baseline_results[1]\n",
    "                    for gen, value in enumerate(baseline_data):\n",
    "                        ax.axhline(y=value, color=red_colors[gen], linestyle='--', alpha=0.7, label=f'Baseline {gen+1}')\n",
    "\n",
    "            # Add best_action line for selection_intensity chart\n",
    "            if metric == 'selection_intensity' and self.best_action is not None:\n",
    "                best_action_intensity = self.action_to_selection_intensity(self.best_action)\n",
    "                ax.axhline(y=best_action_intensity, color='r', linestyle='--', label='Best Constant Action')\n",
    "\n",
    "            # Set y-axis limits for selection_intensity\n",
    "            if metric == 'selection_intensity':\n",
    "                ax.set_ylim(0, 1)\n",
    "\n",
    "            # Create a custom legend\n",
    "            handles, labels = ax.get_legend_handles_labels()\n",
    "            by_label = dict(zip(labels, handles))\n",
    "            ax.legend(by_label.values(), by_label.keys(), loc='upper left', fontsize='small')\n",
    "\n",
    "        axes[-1].set_xlabel('Steps within Generation')\n",
    "        plt.tight_layout()\n",
    "        clear_output(wait=True)\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "\n",
    "def get_constant_action_baseline(env, num_reps=30):\n",
    "    action_grid = np.linspace(-.99, -.3, 30)\n",
    "    best_action = None\n",
    "    best_mean_max_phenotype = float('-inf')\n",
    "    best_results = None\n",
    "\n",
    "    max_generations = env.max_generations\n",
    "\n",
    "    for action in action_grid:\n",
    "        all_max_phenotypes = np.zeros((num_reps, max_generations))\n",
    "        all_genetic_variances = np.zeros((num_reps, max_generations))\n",
    "\n",
    "        for rep in range(num_reps):\n",
    "            obs, _ = env.reset()\n",
    "            done = False\n",
    "            gen = 0\n",
    "            while not done:\n",
    "                obs, reward, done, _, info = env.step([action])\n",
    "                all_max_phenotypes[rep, gen] = info['max_phenotype']\n",
    "                all_genetic_variances[rep, gen] = info['genetic_variance']\n",
    "                gen += 1\n",
    "\n",
    "        mean_max_phenotypes = np.mean(all_max_phenotypes, axis=0)\n",
    "        mean_genetic_variances = np.mean(all_genetic_variances, axis=0)\n",
    "        \n",
    "        final_mean_max_phenotype = mean_max_phenotypes[-1]\n",
    "\n",
    "        if final_mean_max_phenotype > best_mean_max_phenotype:\n",
    "            best_mean_max_phenotype = final_mean_max_phenotype\n",
    "            best_action = action\n",
    "            best_results = np.vstack((mean_max_phenotypes, mean_genetic_variances))\n",
    "\n",
    "    return best_action, best_mean_max_phenotype, best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4a9fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_generations=5\n",
    "total_timesteps = 2000000\n",
    "config = SimulationConfig(n_markers=150, starting_parents=1,pop_size=100)\n",
    "SP = SimParams(config)\n",
    "\n",
    "env = SelectionIntensityEnvironment(SP, config, max_generations=max_generations)\n",
    "best_action, best_mean_max_phenotype, baseline_results = get_constant_action_baseline(env,)\n",
    "print(best_action, best_mean_max_phenotype)\n",
    "model = PPO(\"MultiInputPolicy\", env, device='cuda', verbose=1, tensorboard_log=tensorboard_log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ca2bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a08a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO(\"MultiInputPolicy\", env, device='cuda', verbose=1, tensorboard_log=tensorboard_log)\n",
    "\n",
    "# Set up the model and callback\n",
    "vis_callback = GeneralizedVisualizationCallback(log_freq=1000,     baseline_results=baseline_results, best_action=best_action)\n",
    "\n",
    "# Train the model\n",
    "model.learn(total_timesteps=total_timesteps, callback=vis_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6174bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(model, env, num_episodes=10):\n",
    "    max_phenotypes = []\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "        obs, _ = env.reset()\n",
    "        done = False\n",
    "        episode_phenotypes = []\n",
    "        \n",
    "        while not done:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, _, done, _, info = env.step(action)\n",
    "            episode_phenotypes.append(info['max_phenotype'])\n",
    "        \n",
    "        max_phenotypes.append(episode_phenotypes)\n",
    "    \n",
    "    return np.array(max_phenotypes)\n",
    "\n",
    "tss = evaluate_model(model, env, num_episodes=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6652e27d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final mean max phenotype: 5.9740\n",
      "Final standard deviation: 0.2275\n",
      "Overall mean max phenotype: 5.0788\n",
      "Overall standard deviation: 0.1801\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_fixed_actions(env, action_list, num_episodes=1000):\n",
    "    max_phenotypes = []\n",
    "    \n",
    "    for episode in range(num_episodes):\n",
    "        obs, _ = env.reset()\n",
    "        done = False\n",
    "        episode_phenotypes = []\n",
    "        action_index = 0\n",
    "        \n",
    "        while not done:\n",
    "            action = [action_list[action_index]]\n",
    "            obs, _, done, _, info = env.step(action)\n",
    "            episode_phenotypes.append(info['max_phenotype'])\n",
    "            action_index = (action_index + 1) % len(action_list)\n",
    "        \n",
    "        max_phenotypes.append(episode_phenotypes)\n",
    "    \n",
    "    return np.array(max_phenotypes)\n",
    "\n",
    "# Define your action list\n",
    "action_list = [.084,.084,.084,.084,.084]\n",
    "\n",
    "# Evaluate the model with fixed actions\n",
    "results = evaluate_fixed_actions(env, action_list, num_episodes=1000)\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "mean_results = np.mean(results, axis=0)\n",
    "std_results = np.std(results, axis=0)\n",
    "# Print some statistics\n",
    "print(f\"Final mean max phenotype: {mean_results[-1]:.4f}\")\n",
    "print(f\"Final standard deviation: {std_results[-1]:.4f}\")\n",
    "print(f\"Overall mean max phenotype: {np.mean(mean_results):.4f}\")\n",
    "print(f\"Overall standard deviation: {np.mean(std_results):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "12198617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final mean max phenotype: 5.8221\n",
      "Final standard deviation: 0.1819\n",
      "Overall mean max phenotype: 5.1266\n",
      "Overall standard deviation: 0.1530\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define your action list\n",
    "action_list = [.02,.084,.084,.44,.084]\n",
    "\n",
    "# Evaluate the model with fixed actions\n",
    "results = evaluate_fixed_actions(env, action_list, num_episodes=1000)\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "mean_results = np.mean(results, axis=0)\n",
    "std_results = np.std(results, axis=0)\n",
    "# Print some statistics\n",
    "print(f\"Final mean max phenotype: {mean_results[-1]:.4f}\")\n",
    "print(f\"Final standard deviation: {std_results[-1]:.4f}\")\n",
    "print(f\"Overall mean max phenotype: {np.mean(mean_results):.4f}\")\n",
    "print(f\"Overall standard deviation: {np.mean(std_results):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f01e8b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1    0.0875 0.075  0.0625 0.05  ]\n",
      "Final mean max phenotype: 6.0192\n",
      "Final standard deviation: 0.2388\n",
      "Overall mean max phenotype: 5.1157\n",
      "Overall standard deviation: 0.1910\n"
     ]
    }
   ],
   "source": [
    "action_list = np.linspace(.1,.05,5)\n",
    "print(action_list)\n",
    "\n",
    "# Evaluate the model with fixed actions\n",
    "results = evaluate_fixed_actions(env, action_list, num_episodes=1000)\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "mean_results = np.mean(results, axis=0)\n",
    "std_results = np.std(results, axis=0)\n",
    "# Print some statistics\n",
    "print(f\"Final mean max phenotype: {mean_results[-1]:.4f}\")\n",
    "print(f\"Final standard deviation: {std_results[-1]:.4f}\")\n",
    "print(f\"Overall mean max phenotype: {np.mean(mean_results):.4f}\")\n",
    "print(f\"Overall standard deviation: {np.mean(std_results):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998247ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
