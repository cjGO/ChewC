{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb3311cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stable_baselines3 is not installed. Installing now...\n",
      "Collecting stable_baselines3\n",
      "  Downloading stable_baselines3-2.3.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting gymnasium<0.30,>=0.28.1 (from stable_baselines3)\n",
      "  Downloading gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (1.26.3)\n",
      "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.1.1+cu121)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.2.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.2.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.7.3)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3) (4.9.0)\n",
      "Collecting farama-notifications>=0.0.1 (from gymnasium<0.30,>=0.28.1->stable_baselines3)\n",
      "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable_baselines3) (3.13.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable_baselines3) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable_baselines3) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable_baselines3) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable_baselines3) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13->stable_baselines3) (2.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib->stable_baselines3) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->stable_baselines3) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13->stable_baselines3) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.13->stable_baselines3) (1.3.0)\n",
      "Downloading stable_baselines3-2.3.2-py3-none-any.whl (182 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.3/182.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Installing collected packages: farama-notifications, gymnasium, stable_baselines3\n",
      "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1 stable_baselines3-2.3.2\n",
      "stable_baselines3 has been successfully installed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "def check_and_install(libraries):\n",
    "    for lib in libraries:\n",
    "        try:\n",
    "            importlib.import_module(lib)\n",
    "            print(f\"{lib} is already installed.\")\n",
    "        except ImportError:\n",
    "            print(f\"{lib} is not installed. Installing now...\")\n",
    "            install_package(lib)\n",
    "            print(f\"{lib} has been successfully installed.\")\n",
    "\n",
    "# List of libraries to check and install\n",
    "libraries_to_check = ['stable_baselines3', 'torch', 'matplotlib', 'gdown', 'gymnasium', 'tqdm','rich']\n",
    "\n",
    "check_and_install(libraries_to_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd72d1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "# URL of the raw file (note the change from blob to raw)\n",
    "url = \"https://github.com/kora-labs/chromax/raw/master/chromax/sample_data/genome.npy\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Get the filename from the URL\n",
    "    filename = os.path.basename(url)\n",
    "    \n",
    "    # Save the content to a file in the current working directory\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    \n",
    "    print(f\"File '{filename}' has been downloaded to the current working directory.\")\n",
    "else:\n",
    "    print(\"Failed to download the file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1d17a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "genome = np.load('genome.npy', allow_pickle=True)\n",
    "reshaped_genome = np.transpose(genome, (0, 2, 1)) ; print(reshaped_genome.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1a4ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Optional, Dict\n",
    "from dataclasses import dataclass\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3 import PPO\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.logger import Figure\n",
    "tensorboard_log = './ppotb'\n",
    "device= torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d8595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9973b2b",
   "metadata": {},
   "source": [
    "# Breeding Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1474532",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "This breeding simulation will simulate a single additive trait.\n",
    "\n",
    "State: [ genetic variance, generations remaining, remaining budget, average actions(deprecated)]\n",
    "Action : [ spending budget %, selection_intensity, budget_split(new)]\n",
    "Reward : Max phenotype of final cycle\n",
    "\n",
    "new feature:budget_split will be added in this notebook.\n",
    "\n",
    "(budget_split * spent_budget) = truncation_budget\n",
    "((1-budget_split) * spent_budget) = random selection\n",
    "        \n",
    "the truncation budget will randomly select from the top part\n",
    "the random budget will randomly select from the bottom part\n",
    "\n",
    "Our hopes for longer breeder programs that we will see interesting behavior from the agent to highlight\n",
    "the benefits of increased genetic variance. This should give the agent a higher level of control over\n",
    "the breeding program\n",
    "\n",
    "side features: we will make updates to the baseline function to visualize the 3d action space.\n",
    "\n",
    "refer to 002_blog_bonus.ipynb for most recent notebook featuring 2 actions\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "## BREEDING SIMULATOR\n",
    "    \n",
    "class Genome:\n",
    "    def __init__(self, n_markers: int):\n",
    "        self.ploidy: int = 2\n",
    "        self.n_markers: int = n_markers\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Genome(ploidy={self.ploidy}, n_markers={self.n_markers})\"\n",
    "\n",
    "class Population:\n",
    "    def __init__(self, pop_size: int, haplotypes:torch.tensor, genome: Genome, device: torch.device):\n",
    "        self.pop_size: int = pop_size\n",
    "        self.genome: Genome = genome\n",
    "        self.haplotypes: torch.Tensor = haplotypes\n",
    "        self.device: torch.device = device\n",
    "        \n",
    "    def to(self, device: torch.device) -> 'Population':\n",
    "        self.device = device\n",
    "        self.haplotypes = self.haplotypes.to(device)\n",
    "        return self\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Population(pop_size={self.pop_size}, genome={self.genome}, device={self.device})\"\n",
    "\n",
    "class Trait:\n",
    "    def __init__(self, genome: Genome, population: Population, target_mean: float = 0.0, target_variance: float = 1):\n",
    "        self.genome: Genome = genome\n",
    "        self.device: torch.device = population.device\n",
    "        self.target_mean: float = target_mean\n",
    "        self.target_variance: float = target_variance\n",
    "\n",
    "        # Use torch.randn with a generator for reproducibility\n",
    "        generator = torch.Generator(device=self.device)\n",
    "        generator.manual_seed(torch.initial_seed())  # Use the seed set by torch.manual_seed()\n",
    "        raw_effects = torch.randn(genome.n_markers, device=self.device, generator=generator)\n",
    "\n",
    "        centered_effects = raw_effects - raw_effects.mean()\n",
    "        dosages = population.haplotypes.sum(dim=1)\n",
    "        founder_values = torch.einsum('ij,j->i', dosages, centered_effects)\n",
    "        founder_mean = founder_values.mean()\n",
    "        founder_var = founder_values.var()\n",
    "\n",
    "        scaling_factor = torch.sqrt(self.target_variance / founder_var)\n",
    "        self.effects: torch.Tensor = centered_effects * scaling_factor\n",
    "        self.intercept: torch.Tensor = (torch.tensor(self.target_mean, device=self.device) - founder_mean).detach()\n",
    "\n",
    "    def to(self, device: torch.device) -> 'Trait':\n",
    "        self.device = device\n",
    "        self.effects = self.effects.to(device)\n",
    "        self.intercept = self.intercept.to(device)\n",
    "        return self\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Trait(target_mean={self.target_mean}, target_variance={self.target_variance}, device={self.device})\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The logic of the breeding simulation. Meiosis(Recombination) + Crossing\n",
    "\n",
    "All operate on tensors\n",
    "\"\"\"\n",
    "@staticmethod\n",
    "def meiosis(selected_haplotypes: torch.Tensor, num_crossovers: int = 1, num_gametes_per_parent: int = 1) -> torch.Tensor:\n",
    "    \"\"\" takes a tensor of parent genomes, (selected_haplotypes) and generates gametes for each parent\"\"\"\n",
    "    num_parents, ploidy, num_markers = selected_haplotypes.shape\n",
    "\n",
    "    # Repeat each parent's haplotypes num_gametes_per_parent times\n",
    "    expanded_haplotypes = selected_haplotypes.repeat_interleave(num_gametes_per_parent, dim=0)\n",
    "\n",
    "    # The rest of the function remains largely the same, but operates on the expanded haplotypes\n",
    "    total_gametes = num_parents * num_gametes_per_parent\n",
    "\n",
    "    crossover_points = torch.randint(1, num_markers, (total_gametes, num_crossovers), device=selected_haplotypes.device, generator=torch.Generator(device=selected_haplotypes.device).manual_seed(torch.initial_seed()))\n",
    "    crossover_points, _ = torch.sort(crossover_points, dim=1)\n",
    "\n",
    "    crossover_mask = torch.zeros((total_gametes, num_markers), dtype=torch.bool, device=selected_haplotypes.device)\n",
    "    crossover_mask.scatter_(1, crossover_points, 1)\n",
    "    crossover_mask = torch.cumsum(crossover_mask, dim=1) % 2 == 1\n",
    "\n",
    "    crossover_mask = crossover_mask.unsqueeze(1).expand(-1, ploidy, -1)\n",
    "\n",
    "    start_chromosome = torch.randint(0, ploidy, (total_gametes, 1), device=selected_haplotypes.device)\n",
    "    start_mask = start_chromosome.unsqueeze(-1).expand(-1, -1, num_markers)\n",
    "\n",
    "    final_mask = crossover_mask ^ start_mask.bool()\n",
    "\n",
    "    offspring_haplotypes = torch.where(final_mask, expanded_haplotypes, expanded_haplotypes.roll(shifts=1, dims=1))\n",
    "\n",
    "    # Return only the first haplotype for each meiosis event\n",
    "    return offspring_haplotypes[:, 0, :]\n",
    "\n",
    "@staticmethod\n",
    "def random_cross(gamete_tensor: torch.Tensor, total_crosses: int) -> torch.Tensor:\n",
    "    \"\"\" takes output from meiosis (gamete tensor) and outputs offspring \"\"\"\n",
    "    num_gametes, n_markers = gamete_tensor.shape\n",
    "\n",
    "    # Double the gamete tensor until we have enough for the total crosses\n",
    "    while num_gametes < 2 * total_crosses:\n",
    "        gamete_tensor = torch.cat([gamete_tensor, gamete_tensor], dim=0)\n",
    "        num_gametes *= 2\n",
    "\n",
    "    # Randomly select gametes for crossing\n",
    "    gamete_indices = torch.randperm(num_gametes, device=gamete_tensor.device)\n",
    "    parent1_indices = gamete_indices[:total_crosses]\n",
    "    parent2_indices = gamete_indices[total_crosses:2*total_crosses]\n",
    "\n",
    "    # Create the new population haplotype tensor\n",
    "    new_population = torch.stack([\n",
    "        gamete_tensor[parent1_indices],\n",
    "        gamete_tensor[parent2_indices]\n",
    "    ], dim=1)\n",
    "\n",
    "    return new_population\n",
    "    \n",
    "\n",
    "@staticmethod\n",
    "def score_population(haplotypes: torch.Tensor, trait: Trait, h2: float = 1.0, founder_mean: float = 0, founder_std: float = 1):\n",
    "    dosages = haplotypes.sum(dim=1)\n",
    "    breeding_values = torch.einsum('ij,j->i', dosages, trait.effects)\n",
    "    bv_var = breeding_values.var()\n",
    "\n",
    "    if bv_var == 0 or h2 >= 1:\n",
    "        phenotypes = breeding_values\n",
    "    else:\n",
    "        env_variance = (1 - h2) / (h2 * bv_var.item()+.001)\n",
    "        env_std = torch.sqrt(torch.tensor(env_variance, device=trait.device))\n",
    "        env_effects = torch.randn_like(breeding_values) * env_std\n",
    "        phenotypes = breeding_values + env_effects + trait.intercept\n",
    "\n",
    "    # Normalize phenotypes\n",
    "    normalized_phenotypes = (phenotypes - founder_mean) / (founder_std + 1e-6)\n",
    "    return breeding_values, normalized_phenotypes\n",
    "\n",
    "\n",
    "class SimParams:\n",
    "    \"\"\"inits and stores core data structures for a breeding simulation.\"\"\"\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.genome = Genome(config.n_markers)\n",
    "\n",
    "        # Load and prepare genome\n",
    "        genome = np.load('g2f.npy')\n",
    "        # reshaped_genome = np.transpose(genome, (0, 2, 1))\n",
    "        reshaped_genome = torch.tensor(genome, device=self.device).float()\n",
    "        \n",
    "        # Sample parents\n",
    "        random_indices = torch.randperm(reshaped_genome.shape[0])[:config.starting_parents]\n",
    "        parents = reshaped_genome[random_indices]\n",
    "        \n",
    "        # Sample markers\n",
    "        random_indices = torch.randperm(parents.shape[2])[:config.n_markers]\n",
    "        parents = parents[:,:,random_indices]\n",
    "\n",
    "        f1_gametes = meiosis(parents, num_crossovers=config.num_crossovers, num_gametes_per_parent=config.pop_size)\n",
    "        f1 = random_cross(gamete_tensor=f1_gametes, total_crosses=config.pop_size)\n",
    "        f2_gametes = meiosis(f1, num_crossovers=config.num_crossovers, num_gametes_per_parent=config.pop_size)\n",
    "        f2 = random_cross(gamete_tensor=f2_gametes, total_crosses=config.pop_size)\n",
    "\n",
    "        self.founder_pop = Population(config.pop_size, f2, self.genome, self.device)\n",
    "        self.trait = Trait(self.genome, self.founder_pop)\n",
    "        # Calculate founder population statistics\n",
    "        founder_bv, founder_phenotypes = score_population(self.founder_pop.haplotypes, self.trait, h2=self.config.h2)\n",
    "        self.founder_mean = founder_phenotypes.mean().item()\n",
    "        self.founder_std = founder_phenotypes.std().item()\n",
    "\n",
    "        # Perform burn-in\n",
    "        new_pop, new_mean = self.burn_in(num_generations=config.burnin_years, genetic_variance_threshold=config.burnin_gvt)\n",
    "        \n",
    "        # Update founder population\n",
    "        self.founder_pop.haplotypes = new_pop\n",
    "        \n",
    "        # Calculate normalization parameters based on burn-in population\n",
    "        _, burn_in_phenotypes = score_population(new_pop, self.trait, h2=self.config.h2)\n",
    "        self.normalization_mean = burn_in_phenotypes.mean().item()\n",
    "        self.normalization_std = burn_in_phenotypes.std().item()\n",
    "        \n",
    "        mean_start_pop = (score_population(new_pop, self.trait, h2 = self.config.h2)[0].mean())\n",
    "        # Update trait intercept\n",
    "        self.trait.intercept = torch.tensor(mean_start_pop, device=self.trait.device)\n",
    "\n",
    "        \n",
    "    def burn_in(self, num_generations=50, h2=0.1, selection_intensity=0.9, mutation_rate=0.001, genetic_variance_threshold=.4):\n",
    "        current_pop = self.founder_pop.haplotypes\n",
    "        current_size = self.config.pop_size\n",
    "\n",
    "        for generation in range(num_generations):\n",
    "            # Score the current population\n",
    "            breeding_values, phenotypes = score_population(current_pop, self.trait)\n",
    "\n",
    "            # Calculate genetic variance\n",
    "            genetic_variance = breeding_values.var().item()\n",
    "\n",
    "            # Introduce mutations if genetic variance is below the threshold\n",
    "            if genetic_variance < genetic_variance_threshold:\n",
    "                mutation_mask = torch.rand_like(current_pop) < mutation_rate\n",
    "                current_pop = torch.where(mutation_mask, 1 - current_pop, current_pop)\n",
    "            else:\n",
    "                # Select top individuals\n",
    "                num_selected = max(int(current_size * selection_intensity), 2)  # Ensure at least 2 parents\n",
    "                selection = torch.topk(phenotypes, num_selected).indices\n",
    "                selected_parents = current_pop[selection]\n",
    "\n",
    "                # Create next generation\n",
    "                gametes = meiosis(selected_parents, num_gametes_per_parent=self.config.pop_size // num_selected + 1)\n",
    "                current_pop = random_cross(gametes, total_crosses=self.config.pop_size)\n",
    "\n",
    "            if generation % 10 == 0 or generation == num_generations - 1:\n",
    "                print(f\"Generation {generation + 1}: \"\n",
    "                    f\"Max phenotype = {phenotypes.max().item():.4f}, \"\n",
    "                    f\"Max breeding value = {breeding_values.max().item():.4f}, \"\n",
    "                    f\"Genetic variance = {genetic_variance:.4f}\")\n",
    "\n",
    "        # Calculate new mean\n",
    "        final_breeding_values, _ = score_population(current_pop, self.trait, h2=1.0)\n",
    "        new_mean = final_breeding_values.mean().item()\n",
    "\n",
    "        return current_pop, new_mean\n",
    "    \n",
    "\n",
    "@dataclass\n",
    "class SimulationConfig:\n",
    "    #training\n",
    "    total_timesteps: int = 2000\n",
    "    seed: int = 100\n",
    "    max_generations: int= 50\n",
    "    #breeding sim parameters\n",
    "    n_markers: int = 500\n",
    "    starting_parents: int = 200\n",
    "    pop_size: int = 500 \n",
    "    h2: float = 0.5\n",
    "    num_crossovers: int=3\n",
    "    sparse_reward: bool=False\n",
    "    #burnin\n",
    "    burnin_years : int =  20\n",
    "    burnin_gvt : float = .4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9908cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, display\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "class GeneralizedVisualizationCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0, log_freq=2000, window_size=50, target_phenotype=None, best_action_pair=None):\n",
    "        super().__init__(verbose)\n",
    "        self.data = defaultdict(lambda: defaultdict(list))\n",
    "        self.log_freq = log_freq\n",
    "        self.excluded_metrics = ['TimeLimit.truncated', 'current_generation']\n",
    "        self.target_phenotype = target_phenotype\n",
    "        self.best_action_pair = best_action_pair  # Updated to store action pair\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        info = self.locals['infos'][0]\n",
    "        obs = self.locals['new_obs']\n",
    "        \n",
    "        current_generation = info['current_generation']\n",
    "        \n",
    "        # Track all scalar values from the observation space\n",
    "        for key, value in obs.items():\n",
    "            if np.isscalar(value) and key not in self.excluded_metrics:\n",
    "                self.data[key][current_generation].append(value)\n",
    "        \n",
    "        # Also track any scalar values from the info dict\n",
    "        for key, value in info.items():\n",
    "            if np.isscalar(value) and key not in self.excluded_metrics:\n",
    "                self.data[key][current_generation].append(value)\n",
    "\n",
    "        if self.num_timesteps % self.log_freq == 0:\n",
    "            self.visualize()\n",
    "\n",
    "        return True\n",
    "\n",
    "    def visualize(self):\n",
    "        num_metrics = len(self.data)\n",
    "        fig, axes = plt.subplots(num_metrics, 1, figsize=(16, 6*num_metrics), sharex=True)\n",
    "        if num_metrics == 1:\n",
    "            axes = [axes]\n",
    "\n",
    "        for idx, (metric, generations) in enumerate(self.data.items()):\n",
    "            ax = axes[idx]\n",
    "            num_generations = len(generations)\n",
    "            colors = plt.cm.viridis(np.linspace(0, 1, num_generations))\n",
    "\n",
    "            for i, (generation, values) in enumerate(generations.items()):\n",
    "                if len(values) == 0:\n",
    "                    continue  # Skip empty data\n",
    "\n",
    "                steps = np.arange(len(values))\n",
    "\n",
    "                # Dynamically adjust window size\n",
    "                effective_window = min(self.window_size, len(values))\n",
    "                if effective_window < 2:\n",
    "                    effective_window = 2  # Minimum window size\n",
    "\n",
    "                # Calculate rolling moving average with adjusted window size\n",
    "                rolling_avg = np.convolve(values, np.ones(effective_window), 'valid') / effective_window\n",
    "                rolling_steps = steps[effective_window-1:]\n",
    "\n",
    "                ax.plot(rolling_steps, rolling_avg, label=f'Generation {generation}', color=colors[i])\n",
    "                ax.set_title(f'{metric.capitalize()} per Generation')\n",
    "                ax.set_ylabel(f'Rolling Avg {metric.capitalize()}')\n",
    "                ax.grid(True)\n",
    "\n",
    "            # Add target_phenotype line for max_phenotype chart\n",
    "            if metric == 'max_phenotype' and self.target_phenotype is not None:\n",
    "                ax.axhline(y=self.target_phenotype, color='r', linestyle='--', label='Target Phenotype')\n",
    "\n",
    "            # Add best_action lines for selection_intensity and budget_spent charts\n",
    "            if self.best_action_pair is not None:\n",
    "                if metric == 'selection_intensity':\n",
    "                    best_selection_intensity = (self.best_action_pair[0] + 1) / 2 * 0.98 + 0.01\n",
    "                    ax.axhline(y=best_selection_intensity, color='g', linestyle='--', label='Best Selection Intensity')\n",
    "                if metric == 'budget_spent':\n",
    "                    best_budget_allocation = (self.best_action_pair[1] + 1) / 2\n",
    "                    # ax.axhline(y=best_budget_allocation, color='r', linestyle='--', label='Best Budget Allocation')\n",
    "\n",
    "        axes[-1].set_xlabel('Steps within Generation')\n",
    "        plt.tight_layout()\n",
    "        clear_output(wait=True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8c9618",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb396491",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4f15f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e59e71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import torch\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# ... (Previous code for Genome, Population, Trait, meiosis, random_cross, score_population, SimParams)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SimulationConfig:\n",
    "    # training\n",
    "    total_timesteps: int = 2000\n",
    "    seed: int = 100\n",
    "    max_generations: int = 50\n",
    "    # breeding sim parameters\n",
    "    n_markers: int = 500\n",
    "    starting_parents: int = 200\n",
    "    pop_size: int = 10\n",
    "    h2: float = 0.5\n",
    "    num_crossovers: int = 3\n",
    "    sparse_reward: bool = True\n",
    "    # burnin\n",
    "    burnin_years: int = 20\n",
    "    burnin_gvt: float = .5\n",
    "    init_pop_size: int = 100\n",
    "\n",
    "\n",
    "class TripleEnv(gym.Env):\n",
    "    def __init__(self, sim_params: SimParams, starting_budget=1000):\n",
    "        super(TripleEnv, self).__init__()\n",
    "\n",
    "        self.SP = sim_params\n",
    "        self.max_generations = sim_params.config.max_generations\n",
    "        self.current_generation = 0\n",
    "        self.current_pop = sim_params.founder_pop.haplotypes\n",
    "        self.selection_intensities = []\n",
    "        self.founder_mean = sim_params.founder_mean\n",
    "        self.founder_std = sim_params.founder_std\n",
    "        self.action_sum = 0.0\n",
    "        self.starting_budget = starting_budget\n",
    "        self.remaining_budget = starting_budget\n",
    "        self.budget_history = []\n",
    "\n",
    "        # Define action and observation spaces\n",
    "        # Action space includes selection intensity [0], budget allocation [1], and budget split [2]\n",
    "        self.action_space = spaces.Box(low=np.array([-1, -1, -1]), high=np.array([1, 1, 1]), shape=(3,), dtype=np.float32)\n",
    "        self.observation_space = spaces.Dict({\n",
    "            'genetic_variance': spaces.Box(low=0, high=np.inf, shape=(1,), dtype=np.float32),\n",
    "            'remaining_cycles': spaces.Box(low=0, high=self.max_generations, shape=(1,), dtype=np.float32),\n",
    "            'remaining_budget': spaces.Box(low=0, high=self.starting_budget, shape=(1,), dtype=np.float32),\n",
    "        })\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.current_generation = 0\n",
    "        self.current_pop = self.SP.founder_pop.haplotypes\n",
    "        self.selection_intensities = []\n",
    "        self.action_sum = 0.0\n",
    "        self.remaining_budget = self.starting_budget\n",
    "        self.budget_history = []\n",
    "        return self._get_obs(), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        # Extract selection intensity, budget allocation, and budget split from action\n",
    "        selection_intensity = (action[0] + 1) / 2 * 0.98 + 0.01  # to [0.01,0.99]\n",
    "        budget_allocation = (action[1] + 1) / 2  # Normalized to [0, 1]\n",
    "        budget_split = (action[2] + 1) / 2  # Normalized to [0, 1]\n",
    "\n",
    "        # Calculate budget to spend\n",
    "        budget_to_spend = self.remaining_budget * budget_allocation\n",
    "\n",
    "        # Update remaining budget\n",
    "        self.remaining_budget -= budget_to_spend\n",
    "        self.budget_history.append(budget_to_spend)\n",
    "\n",
    "        self.selection_intensities.append(selection_intensity)\n",
    "        self.action_sum += selection_intensity\n",
    "\n",
    "        breeding_values, phenotypes = score_population(self.current_pop, self.SP.trait, h2=self.SP.config.h2)\n",
    "\n",
    "        # Split population based on budget split\n",
    "        pop_size = self.current_pop.shape[0]\n",
    "        truncation_pop_size = int(pop_size * budget_split)\n",
    "        random_pop_size = pop_size - truncation_pop_size\n",
    "\n",
    "        # Sort phenotypes for truncation selection\n",
    "        sorted_indices = torch.argsort(phenotypes, descending=True)\n",
    "        truncation_indices = sorted_indices[:truncation_pop_size]\n",
    "        random_indices = sorted_indices[truncation_pop_size:]\n",
    "\n",
    "        # Select parents based on budget allocation and split\n",
    "        truncation_parents = self.current_pop[truncation_indices]\n",
    "        random_parents = self.current_pop[random_indices]\n",
    "\n",
    "        # Calculate offspring for each part\n",
    "        truncation_offspring = self._calculate_offspring(truncation_pop_size, budget_to_spend * budget_split)\n",
    "        random_offspring = self._calculate_offspring(random_pop_size, budget_to_spend * (1 - budget_split))\n",
    "\n",
    "        # Generate offspring\n",
    "        truncation_gametes = meiosis(truncation_parents, num_gametes_per_parent=truncation_offspring // truncation_pop_size + 1)\n",
    "        truncation_offspring_pop = random_cross(truncation_gametes, total_crosses=truncation_offspring)\n",
    "\n",
    "        random_gametes = meiosis(random_parents, num_gametes_per_parent=random_offspring // random_pop_size + 1)\n",
    "        random_offspring_pop = random_cross(random_gametes, total_crosses=random_offspring)\n",
    "\n",
    "        # Combine offspring\n",
    "        self.current_pop = torch.cat([truncation_offspring_pop, random_offspring_pop], dim=0)\n",
    "\n",
    "        self.current_generation += 1\n",
    "\n",
    "        new_breeding_values, new_phenotypes = score_population(self.current_pop, self.SP.trait, h2=self.SP.config.h2)\n",
    "        done = self.current_generation >= self.max_generations\n",
    "\n",
    "        reward = new_breeding_values.max().item() - self.founder_mean if done else 0\n",
    "\n",
    "        observation = self._get_obs()\n",
    "        info = {\n",
    "            'max_phenotype': new_phenotypes.max().item(),\n",
    "            'current_generation': self.current_generation,\n",
    "            'genetic_variance': new_breeding_values.var().item(),\n",
    "            'selection_intensity': selection_intensity,\n",
    "            'budget_action': budget_allocation,\n",
    "            'budget_spent': budget_to_spend,\n",
    "            'budget_split': budget_split\n",
    "        }\n",
    "\n",
    "        return observation, reward, done, False, info\n",
    "\n",
    "    def _get_obs(self):\n",
    "        breeding_values, _ = score_population(self.current_pop, self.SP.trait, h2=self.SP.config.h2)\n",
    "        genetic_variance = breeding_values.var().item()\n",
    "        remaining_cycles = self.max_generations - self.current_generation\n",
    "\n",
    "        return {\n",
    "            'genetic_variance': np.array([genetic_variance], dtype=np.float32),\n",
    "            'remaining_cycles': np.array([remaining_cycles], dtype=np.float32),\n",
    "            'remaining_budget': np.array([self.remaining_budget], dtype=np.float32),\n",
    "        }\n",
    "\n",
    "    def _calculate_offspring(self, base_offspring, budget_spent):\n",
    "        # Define a function to calculate offspring based on budget spent\n",
    "        # This is a placeholder, you'll need to implement a suitable logic here\n",
    "        # For example, you could use a linear or exponential relationship\n",
    "        return int(base_offspring + budget_spent * 1)  # Example: 10 offspring per budget unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ca187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SimulationConfig()\n",
    "SP = SimParams(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dfa10c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4391166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83e196e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631ce0a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367938bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "606150ea",
   "metadata": {},
   "source": [
    "## budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0708b2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BudgetEnv(gym.Env):\n",
    "    def __init__(self, sim_params: SimParams, starting_budget=1000):\n",
    "        super(BudgetEnv, self).__init__()\n",
    "        \n",
    "        self.SP = sim_params\n",
    "        self.max_generations = sim_params.config.max_generations\n",
    "        self.current_generation = 0\n",
    "        self.current_pop = sim_params.founder_pop.haplotypes\n",
    "        self.selection_intensities = []\n",
    "        self.founder_mean = sim_params.founder_mean\n",
    "        self.founder_std = sim_params.founder_std\n",
    "        self.action_sum = 0.0\n",
    "        self.starting_budget = starting_budget\n",
    "        self.remaining_budget = starting_budget\n",
    "        self.budget_history = []\n",
    "\n",
    "        # Define action and observation spaces\n",
    "        # Action space includes selection intensity [0] and budget allocation [1]\n",
    "        self.action_space = spaces.Box(low=np.array([-1, -1]), high=np.array([1, 1]), shape=(2,), dtype=np.float32)\n",
    "        self.observation_space = spaces.Dict({\n",
    "            'genetic_variance': spaces.Box(low=0, high=np.inf, shape=(1,), dtype=np.float32),\n",
    "            'remaining_cycles': spaces.Box(low=0, high=self.max_generations, shape=(1,), dtype=np.float32),\n",
    "            'remaining_budget': spaces.Box(low=0, high=self.starting_budget, shape=(1,), dtype=np.float32),\n",
    "        })\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.current_generation = 0\n",
    "        self.current_pop = self.SP.founder_pop.haplotypes\n",
    "        self.selection_intensities = []\n",
    "        self.action_sum = 0.0\n",
    "        self.remaining_budget = self.starting_budget\n",
    "        self.budget_history = []\n",
    "        return self._get_obs(), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        # Extract selection intensity and budget allocation from action\n",
    "        selection_intensity = (action[0] + 1) / 2 * 0.98 + 0.01 # to [0.01,0.99]\n",
    "        budget_allocation = (action[1] + 1) / 2  # Normalized to [0, 1]\n",
    "\n",
    "        # Calculate budget to spend\n",
    "        budget_to_spend = self.remaining_budget * budget_allocation\n",
    "\n",
    "        # Update remaining budget\n",
    "        self.remaining_budget -= budget_to_spend\n",
    "        self.budget_history.append(budget_to_spend)\n",
    "\n",
    "        self.selection_intensities.append(selection_intensity)\n",
    "        self.action_sum += selection_intensity\n",
    "        \n",
    "        breeding_values, phenotypes = score_population(self.current_pop, self.SP.trait, h2=self.SP.config.h2)\n",
    "        \n",
    "        # Increase offspring based on budget spent (you'll need to define a function for this)\n",
    "        num_offspring = self._calculate_offspring(self.SP.config.pop_size, budget_to_spend)\n",
    "        num_selected = max(int(self.current_pop.shape[0] * selection_intensity), 2)\n",
    "        \n",
    "        selection = torch.topk(phenotypes, num_selected).indices\n",
    "        selected_parents = self.current_pop[selection]\n",
    "        \n",
    "        gametes = meiosis(selected_parents, num_gametes_per_parent=num_offspring // num_selected + 1)\n",
    "        self.current_pop = random_cross(gametes, total_crosses=num_offspring)\n",
    "        \n",
    "        self.current_generation += 1\n",
    "        \n",
    "        new_breeding_values, new_phenotypes = score_population(self.current_pop, self.SP.trait, h2=self.SP.config.h2)\n",
    "        done = self.current_generation >= self.max_generations\n",
    "\n",
    "        reward = new_breeding_values.max().item() - self.founder_mean if done else 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        observation = self._get_obs()\n",
    "        info = {\n",
    "            'max_phenotype': new_phenotypes.max().item(),\n",
    "            'current_generation': self.current_generation,\n",
    "            'genetic_variance': new_breeding_values.var().item(),\n",
    "            'selection_intensity': selection_intensity,\n",
    "            'budget_action': budget_allocation,\n",
    "            'budget_spent': budget_to_spend\n",
    "        }\n",
    "\n",
    "        return observation, reward, done, False, info\n",
    "\n",
    "    def _get_obs(self):\n",
    "        breeding_values, _ = score_population(self.current_pop, self.SP.trait, h2=self.SP.config.h2)\n",
    "        genetic_variance = breeding_values.var().item()\n",
    "        remaining_cycles = self.max_generations - self.current_generation\n",
    "        \n",
    "        return {\n",
    "            'genetic_variance': np.array([genetic_variance], dtype=np.float32),\n",
    "            'remaining_cycles': np.array([remaining_cycles], dtype=np.float32),\n",
    "            'remaining_budget': np.array([self.remaining_budget], dtype=np.float32),\n",
    "        }\n",
    "\n",
    "    def _calculate_offspring(self, base_offspring, budget_spent):\n",
    "        # Define a function to calculate offspring based on budget spent\n",
    "        # This is a placeholder, you'll need to implement a suitable logic here\n",
    "        # For example, you could use a linear or exponential relationship\n",
    "        return int(base_offspring + budget_spent * 1)  # Example: 10 offspring per budget unit\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9ff29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "config = SimulationConfig()\n",
    "config.max_generations = 5\n",
    "config.sparse_reward = True\n",
    "SP = SimParams(config)\n",
    "breeder_env = BudgetEnv(SP, starting_budget=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c538f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SimulationConfig:\n",
    "    #training\n",
    "    total_timesteps: int = 2000\n",
    "    seed: int = 100\n",
    "    max_generations: int= 50\n",
    "    #breeding sim parameters\n",
    "    n_markers: int = 500\n",
    "    starting_parents: int = 200\n",
    "    pop_size: int = 10\n",
    "    h2: float = 0.5\n",
    "    num_crossovers: int=3\n",
    "    sparse_reward: bool=True\n",
    "    #burnin\n",
    "    burnin_years : int =  20\n",
    "    burnin_gvt : float = .5\n",
    "    init_pop_size: int = 100\n",
    "\n",
    "\n",
    "class BudgetEnv(gym.Env):\n",
    "    def __init__(self, sim_params: SimParams, starting_budget=1000):\n",
    "        super(BudgetEnv, self).__init__()\n",
    "        \n",
    "        self.SP = sim_params\n",
    "        self.max_generations = sim_params.config.max_generations\n",
    "        self.current_generation = 0\n",
    "        self.current_pop = sim_params.founder_pop.haplotypes\n",
    "        self.selection_intensities = []\n",
    "        self.founder_mean = sim_params.founder_mean\n",
    "        self.founder_std = sim_params.founder_std\n",
    "        self.action_sum = 0.0\n",
    "        self.starting_budget = starting_budget\n",
    "        self.remaining_budget = starting_budget\n",
    "        self.budget_history = []\n",
    "\n",
    "        # Define action and observation spaces\n",
    "        # Action space includes selection intensity [0] and budget allocation [1]\n",
    "        self.action_space = spaces.Box(low=np.array([-1, -1]), high=np.array([1, 1]), shape=(2,), dtype=np.float32)\n",
    "        self.observation_space = spaces.Dict({\n",
    "            'genetic_variance': spaces.Box(low=0, high=np.inf, shape=(1,), dtype=np.float32),\n",
    "            'remaining_cycles': spaces.Box(low=0, high=self.max_generations, shape=(1,), dtype=np.float32),\n",
    "            'remaining_budget': spaces.Box(low=0, high=self.starting_budget, shape=(1,), dtype=np.float32),\n",
    "        })\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.current_generation = 0\n",
    "        self.current_pop = self.SP.founder_pop.haplotypes\n",
    "        self.selection_intensities = []\n",
    "        self.action_sum = 0.0\n",
    "        self.remaining_budget = self.starting_budget\n",
    "        self.budget_history = []\n",
    "        return self._get_obs(), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        # Extract selection intensity and budget allocation from action\n",
    "        selection_intensity = (action[0] + 1) / 2 * 0.98 + 0.01 # to [0.01,0.99]\n",
    "        budget_allocation = (action[1] + 1) / 2  # Normalized to [0, 1]\n",
    "\n",
    "        # Calculate budget to spend\n",
    "        budget_to_spend = self.remaining_budget * budget_allocation\n",
    "\n",
    "        # Update remaining budget\n",
    "        self.remaining_budget -= budget_to_spend\n",
    "        self.budget_history.append(budget_to_spend)\n",
    "\n",
    "        self.selection_intensities.append(selection_intensity)\n",
    "        self.action_sum += selection_intensity\n",
    "        \n",
    "        breeding_values, phenotypes = score_population(self.current_pop, self.SP.trait, h2=self.SP.config.h2)\n",
    "        \n",
    "        # Increase offspring based on budget spent (you'll need to define a function for this)\n",
    "        num_offspring = self._calculate_offspring(self.SP.config.pop_size, budget_to_spend)\n",
    "        num_selected = max(int(self.current_pop.shape[0] * selection_intensity), 2)\n",
    "        \n",
    "        selection = torch.topk(phenotypes, num_selected).indices\n",
    "        selected_parents = self.current_pop[selection]\n",
    "        \n",
    "        gametes = meiosis(selected_parents, num_gametes_per_parent=num_offspring // num_selected + 1)\n",
    "        self.current_pop = random_cross(gametes, total_crosses=num_offspring)\n",
    "        \n",
    "        self.current_generation += 1\n",
    "        \n",
    "        new_breeding_values, new_phenotypes = score_population(self.current_pop, self.SP.trait, h2=self.SP.config.h2)\n",
    "        done = self.current_generation >= self.max_generations\n",
    "\n",
    "        reward = new_breeding_values.max().item() - self.founder_mean if done else 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        observation = self._get_obs()\n",
    "        info = {\n",
    "            'max_phenotype': new_phenotypes.max().item(),\n",
    "            'current_generation': self.current_generation,\n",
    "            'genetic_variance': new_breeding_values.var().item(),\n",
    "            'selection_intensity': selection_intensity,\n",
    "            'budget_action': budget_allocation,\n",
    "            'budget_spent': budget_to_spend\n",
    "        }\n",
    "\n",
    "        return observation, reward, done, False, info\n",
    "\n",
    "    def _get_obs(self):\n",
    "        breeding_values, _ = score_population(self.current_pop, self.SP.trait, h2=self.SP.config.h2)\n",
    "        genetic_variance = breeding_values.var().item()\n",
    "        remaining_cycles = self.max_generations - self.current_generation\n",
    "        \n",
    "        return {\n",
    "            'genetic_variance': np.array([genetic_variance], dtype=np.float32),\n",
    "            'remaining_cycles': np.array([remaining_cycles], dtype=np.float32),\n",
    "            'remaining_budget': np.array([self.remaining_budget], dtype=np.float32),\n",
    "        }\n",
    "\n",
    "    def _calculate_offspring(self, base_offspring, budget_spent):\n",
    "        # Define a function to calculate offspring based on budget spent\n",
    "        # This is a placeholder, you'll need to implement a suitable logic here\n",
    "        # For example, you could use a linear or exponential relationship\n",
    "        return int(base_offspring + budget_spent * 1)  # Example: 10 offspring per budget unit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8dca11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c924d635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a46b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def run_constant_action_pair_baseline_analysis(env, num_episodes=10, num_selection_intensity_actions=20, num_budget_allocation_actions=10):\n",
    "    def run_constant_action_pair_baseline(env, action_pair, num_episodes):\n",
    "        results = []\n",
    "        for _ in range(num_episodes):\n",
    "            obs, _ = env.reset()\n",
    "            done = False\n",
    "            max_phenotypes = []  # Track max phenotypes for each episode\n",
    "\n",
    "            while not done:\n",
    "                obs, _, done, _, info = env.step(np.array(action_pair))\n",
    "                max_phenotypes.append(info['max_phenotype'])\n",
    "\n",
    "            results.append({'max_phenotypes': max_phenotypes})  # Store results\n",
    "\n",
    "        return results\n",
    "\n",
    "    # Define ranges of constant actions to test\n",
    "    selection_intensity_actions = np.linspace(-1, 1, num_selection_intensity_actions)\n",
    "    budget_allocation_actions = np.linspace(-1, 1, num_budget_allocation_actions)\n",
    "\n",
    "    # Collect baseline results\n",
    "    baseline_results = {}\n",
    "    best_action_pair = None\n",
    "    best_max_phenotype = float('-inf')\n",
    "\n",
    "    for selection_intensity_action in selection_intensity_actions:\n",
    "        for budget_allocation_action in budget_allocation_actions:\n",
    "            action_pair = [selection_intensity_action, budget_allocation_action]\n",
    "            baseline_results[tuple(action_pair)] = run_constant_action_pair_baseline(env, action_pair, num_episodes)\n",
    "\n",
    "            # Calculate average max phenotype for this action pair\n",
    "            avg_max_phenotype = np.mean([max(r['max_phenotypes']) for r in baseline_results[tuple(action_pair)]])\n",
    "\n",
    "            # Update best action pair if this pair performs better\n",
    "            if avg_max_phenotype > best_max_phenotype:\n",
    "                best_action_pair = action_pair\n",
    "                best_max_phenotype = avg_max_phenotype\n",
    "\n",
    "    # Create heatmap data using average max phenotype\n",
    "    heatmap_data = np.zeros((num_budget_allocation_actions, num_selection_intensity_actions))\n",
    "    for i, selection_intensity_action in enumerate(selection_intensity_actions):\n",
    "        for j, budget_allocation_action in enumerate(budget_allocation_actions):\n",
    "            action_pair = (selection_intensity_action, budget_allocation_action)\n",
    "            if action_pair in baseline_results:\n",
    "                avg_max_phenotype = np.mean([max(r['max_phenotypes']) for r in baseline_results[action_pair]])\n",
    "                heatmap_data[j, i] = avg_max_phenotype\n",
    "\n",
    "    # Plot heatmap\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    im = ax.imshow(heatmap_data, cmap='viridis', origin='lower', aspect='auto')\n",
    "\n",
    "    # Set tick labels\n",
    "    ax.set_xticks(np.arange(num_selection_intensity_actions))\n",
    "    ax.set_yticks(np.arange(num_budget_allocation_actions))\n",
    "    ax.set_xticklabels([f'{val:.2f}' for val in selection_intensity_actions], rotation=45, ha='right')\n",
    "    ax.set_yticklabels([f'{val:.2f}' for val in budget_allocation_actions])\n",
    "\n",
    "    # Add colorbar\n",
    "    cbar = ax.figure.colorbar(im, ax=ax)\n",
    "    cbar.ax.set_ylabel('Average Max Phenotype', rotation=-90, va=\"bottom\")\n",
    "\n",
    "    # Set labels\n",
    "    ax.set_xlabel('Selection Intensity Action')\n",
    "    ax.set_ylabel('Budget Allocation Action')\n",
    "    ax.set_title('Heatmap of Average Max Phenotype for Action Pairs')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print best action pair information\n",
    "    best_selection_intensity = (best_action_pair[0] + 1) / 2 * 0.98 + 0.01\n",
    "    best_budget_allocation = (best_action_pair[1] + 1) / 2\n",
    "\n",
    "    print(\"\\nBest Action Pair Information:\")\n",
    "    print(f\"Best Selection Intensity Action: {best_action_pair[0]:.2f} (SI: {best_selection_intensity:.2f})\")\n",
    "    print(f\"Best Budget Allocation Action: {best_action_pair[1]:.2f} (Allocation: {best_budget_allocation:.2f})\")\n",
    "    print(f\"Best Average Max Phenotype: {best_max_phenotype:.2f}\")\n",
    "\n",
    "    return best_action_pair, best_selection_intensity, best_budget_allocation, best_max_phenotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ca2756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "best_action_pair, best_si, best_budget_allocation, best_phenotype = run_constant_action_pair_baseline_analysis(breeder_env, num_episodes=50, num_selection_intensity_actions=40, num_budget_allocation_actions=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3fb9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_action_pair, best_si, best_budget_allocation, best_phenotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098ff744",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_action_pair = (best_si,best_budget_allocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390010d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agent = PPO(\"MultiInputPolicy\", breeder_env)\n",
    "callback = GeneralizedVisualizationCallback(log_freq=1000, window_size=100,\n",
    "#  best_action_pair=best_action_pair,\n",
    "  target_phenotype=best_phenotype,\n",
    "  )\n",
    "\n",
    "agent.learn(total_timesteps=3000000 ,callback = callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93766a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.learn(total_timesteps=1000000 ,callback = callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfc22ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9103d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = SimulationConfig()\n",
    "config.max_generations = 10\n",
    "config.sparse_reward = True\n",
    "config.seed = 2\n",
    "SP = SimParams(config)\n",
    "breeder_env = BudgetEnv(SP, starting_budget=5000)\n",
    "\n",
    "agent = PPO(\"MultiInputPolicy\", breeder_env)\n",
    "agent.learn(total_timesteps=1000000 ,callback = callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45deb1ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
