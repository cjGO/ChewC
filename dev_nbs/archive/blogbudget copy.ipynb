{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eb3311cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stable_baselines3 is already installed.\n",
      "torch is already installed.\n",
      "matplotlib is already installed.\n",
      "gdown is already installed.\n",
      "gymnasium is already installed.\n",
      "tqdm is already installed.\n",
      "rich is already installed.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "def check_and_install(libraries):\n",
    "    for lib in libraries:\n",
    "        try:\n",
    "            importlib.import_module(lib)\n",
    "            print(f\"{lib} is already installed.\")\n",
    "        except ImportError:\n",
    "            print(f\"{lib} is not installed. Installing now...\")\n",
    "            install_package(lib)\n",
    "            print(f\"{lib} has been successfully installed.\")\n",
    "\n",
    "# List of libraries to check and install\n",
    "libraries_to_check = ['stable_baselines3', 'torch', 'matplotlib', 'gdown', 'gymnasium', 'tqdm','rich']\n",
    "\n",
    "check_and_install(libraries_to_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fd72d1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'genome.npy' has been downloaded to the current working directory.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "# URL of the raw file (note the change from blob to raw)\n",
    "url = \"https://github.com/kora-labs/chromax/raw/master/chromax/sample_data/genome.npy\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Get the filename from the URL\n",
    "    filename = os.path.basename(url)\n",
    "    \n",
    "    # Save the content to a file in the current working directory\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    \n",
    "    print(f\"File '{filename}' has been downloaded to the current working directory.\")\n",
    "else:\n",
    "    print(\"Failed to download the file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cf1d17a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "genome = np.load('genome.npy', allow_pickle=True)\n",
    "reshaped_genome = np.transpose(genome, (0, 2, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7e1a4ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from typing import Optional, Dict\n",
    "from dataclasses import dataclass\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3 import PPO\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.logger import Figure\n",
    "tensorboard_log = './ppotb'\n",
    "device= torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d7d8595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9973b2b",
   "metadata": {},
   "source": [
    "# Breeding Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f1474532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1: Max phenotype = nan, Max breeding value = 4.4713, Genetic variance = 1.0000\n",
      "Generation 11: Max phenotype = nan, Max breeding value = 4.3988, Genetic variance = 0.9818\n",
      "Generation 20: Max phenotype = nan, Max breeding value = 4.5520, Genetic variance = 0.7140\n",
      "tensor(1.6925, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_36/3095324757.py:254: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  env_std = torch.sqrt(torch.tensor(env_variance, device=trait.device))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "This breeding simulation will simulate a single additive trait.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "## BREEDING SIMULATOR\n",
    "    \n",
    "class Genome:\n",
    "    def __init__(self, n_markers: int):\n",
    "        self.ploidy: int = 2\n",
    "        self.n_markers: int = n_markers\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Genome(ploidy={self.ploidy}, n_markers={self.n_markers})\"\n",
    "\n",
    "class Population:\n",
    "    def __init__(self, pop_size: int, haplotypes:torch.tensor, genome: Genome, device: torch.device):\n",
    "        self.pop_size: int = pop_size\n",
    "        self.genome: Genome = genome\n",
    "        self.haplotypes: torch.Tensor = haplotypes\n",
    "        self.device: torch.device = device\n",
    "        \n",
    "    def to(self, device: torch.device) -> 'Population':\n",
    "        self.device = device\n",
    "        self.haplotypes = self.haplotypes.to(device)\n",
    "        return self\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Population(pop_size={self.pop_size}, genome={self.genome}, device={self.device})\"\n",
    "\n",
    "class Trait:\n",
    "    def __init__(self, genome: Genome, population: Population, target_mean: float = 0.0, target_variance: float = 1):\n",
    "        self.genome: Genome = genome\n",
    "        self.device: torch.device = population.device\n",
    "        self.target_mean: float = target_mean\n",
    "        self.target_variance: float = target_variance\n",
    "\n",
    "        # Use torch.randn with a generator for reproducibility\n",
    "        generator = torch.Generator(device=self.device)\n",
    "        generator.manual_seed(torch.initial_seed())  # Use the seed set by torch.manual_seed()\n",
    "        raw_effects = torch.randn(genome.n_markers, device=self.device, generator=generator)\n",
    "\n",
    "        centered_effects = raw_effects - raw_effects.mean()\n",
    "        dosages = population.haplotypes.sum(dim=1)\n",
    "        founder_values = torch.einsum('ij,j->i', dosages, centered_effects)\n",
    "        founder_mean = founder_values.mean()\n",
    "        founder_var = founder_values.var()\n",
    "\n",
    "        scaling_factor = torch.sqrt(self.target_variance / founder_var)\n",
    "        self.effects: torch.Tensor = centered_effects * scaling_factor\n",
    "        self.intercept: torch.Tensor = (torch.tensor(self.target_mean, device=self.device) - founder_mean).detach()\n",
    "\n",
    "    def to(self, device: torch.device) -> 'Trait':\n",
    "        self.device = device\n",
    "        self.effects = self.effects.to(device)\n",
    "        self.intercept = self.intercept.to(device)\n",
    "        return self\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Trait(target_mean={self.target_mean}, target_variance={self.target_variance}, device={self.device})\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The logic of the breeding simulation. Meiosis(Recombination) + Crossing\n",
    "\n",
    "All operate on tensors\n",
    "\"\"\"\n",
    "@staticmethod\n",
    "def meiosis(selected_haplotypes: torch.Tensor, num_crossovers: int = 1, num_gametes_per_parent: int = 1) -> torch.Tensor:\n",
    "    \"\"\" takes a tensor of parent genomes, (selected_haplotypes) and generates gametes for each parent\"\"\"\n",
    "    num_parents, ploidy, num_markers = selected_haplotypes.shape\n",
    "\n",
    "    # Repeat each parent's haplotypes num_gametes_per_parent times\n",
    "    expanded_haplotypes = selected_haplotypes.repeat_interleave(num_gametes_per_parent, dim=0)\n",
    "\n",
    "    # The rest of the function remains largely the same, but operates on the expanded haplotypes\n",
    "    total_gametes = num_parents * num_gametes_per_parent\n",
    "\n",
    "    crossover_points = torch.randint(1, num_markers, (total_gametes, num_crossovers), device=selected_haplotypes.device, generator=torch.Generator(device=selected_haplotypes.device).manual_seed(torch.initial_seed()))\n",
    "    crossover_points, _ = torch.sort(crossover_points, dim=1)\n",
    "\n",
    "    crossover_mask = torch.zeros((total_gametes, num_markers), dtype=torch.bool, device=selected_haplotypes.device)\n",
    "    crossover_mask.scatter_(1, crossover_points, 1)\n",
    "    crossover_mask = torch.cumsum(crossover_mask, dim=1) % 2 == 1\n",
    "\n",
    "    crossover_mask = crossover_mask.unsqueeze(1).expand(-1, ploidy, -1)\n",
    "\n",
    "    start_chromosome = torch.randint(0, ploidy, (total_gametes, 1), device=selected_haplotypes.device)\n",
    "    start_mask = start_chromosome.unsqueeze(-1).expand(-1, -1, num_markers)\n",
    "\n",
    "    final_mask = crossover_mask ^ start_mask.bool()\n",
    "\n",
    "    offspring_haplotypes = torch.where(final_mask, expanded_haplotypes, expanded_haplotypes.roll(shifts=1, dims=1))\n",
    "\n",
    "    # Return only the first haplotype for each meiosis event\n",
    "    return offspring_haplotypes[:, 0, :]\n",
    "\n",
    "@staticmethod\n",
    "def random_cross(gamete_tensor: torch.Tensor, total_crosses: int) -> torch.Tensor:\n",
    "    \"\"\" takes output from meiosis (gamete tensor) and outputs offspring \"\"\"\n",
    "    num_gametes, n_markers = gamete_tensor.shape\n",
    "\n",
    "    # Double the gamete tensor until we have enough for the total crosses\n",
    "    while num_gametes < 2 * total_crosses:\n",
    "        gamete_tensor = torch.cat([gamete_tensor, gamete_tensor], dim=0)\n",
    "        num_gametes *= 2\n",
    "\n",
    "    # Randomly select gametes for crossing\n",
    "    gamete_indices = torch.randperm(num_gametes, device=gamete_tensor.device)\n",
    "    parent1_indices = gamete_indices[:total_crosses]\n",
    "    parent2_indices = gamete_indices[total_crosses:2*total_crosses]\n",
    "\n",
    "    # Create the new population haplotype tensor\n",
    "    new_population = torch.stack([\n",
    "        gamete_tensor[parent1_indices],\n",
    "        gamete_tensor[parent2_indices]\n",
    "    ], dim=1)\n",
    "\n",
    "    return new_population\n",
    "    \n",
    "\n",
    "@staticmethod\n",
    "def score_population(haplotypes: torch.Tensor, trait: Trait, h2: float = 1.0, founder_mean: float = 0, founder_std: float = 1):\n",
    "    dosages = haplotypes.sum(dim=1)\n",
    "    breeding_values = torch.einsum('ij,j->i', dosages, trait.effects)\n",
    "    bv_var = breeding_values.var()\n",
    "\n",
    "    if bv_var == 0 or h2 >= 1:\n",
    "        phenotypes = breeding_values\n",
    "    else:\n",
    "        env_variance = (1 - h2) / (h2 * bv_var.item()+.001)\n",
    "        env_std = torch.sqrt(torch.tensor(env_variance, device=trait.device))\n",
    "        env_effects = torch.randn_like(breeding_values) * env_std\n",
    "        phenotypes = breeding_values + env_effects + trait.intercept\n",
    "\n",
    "    # Normalize phenotypes\n",
    "    normalized_phenotypes = (phenotypes - founder_mean) / founder_std\n",
    "\n",
    "    return breeding_values, normalized_phenotypes\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class SimParams:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.genome = Genome(config.n_markers)\n",
    "\n",
    "        # Load and prepare genome\n",
    "        genome = np.load('genome.npy')\n",
    "        reshaped_genome = np.transpose(genome, (0, 2, 1))\n",
    "        reshaped_genome = torch.tensor(reshaped_genome, device=self.device).float()\n",
    "        \n",
    "        # Sample parents\n",
    "        random_indices = torch.randperm(reshaped_genome.shape[0])[:config.starting_parents]\n",
    "        parents = reshaped_genome[random_indices]\n",
    "        \n",
    "        # Sample markers\n",
    "        random_indices = torch.randperm(parents.shape[2])[:config.n_markers]\n",
    "        parents = parents[:,:,random_indices]\n",
    "\n",
    "        f1_gametes = meiosis(parents, num_crossovers=config.num_crossovers, num_gametes_per_parent=config.pop_size)\n",
    "        f1 = random_cross(gamete_tensor=f1_gametes, total_crosses=config.pop_size)\n",
    "\n",
    "        self.founder_pop = Population(config.pop_size, f1, self.genome, self.device)\n",
    "        self.trait = Trait(self.genome, self.founder_pop)\n",
    "        # Calculate founder population statistics\n",
    "        self.founder_bv, self.founder_phenotypes = score_population(self.founder_pop.haplotypes, self.trait, h2=self.config.h2)\n",
    "        \n",
    "\n",
    "        # Perform burn-in\n",
    "        new_pop, new_mean = self.burn_in(num_generations=config.burnin_years, genetic_variance_threshold=config.burnin_gvt)\n",
    "        \n",
    "        # Update founder population\n",
    "        self.founder_pop.haplotypes = new_pop\n",
    "        \n",
    "        # Calculate normalization parameters based on burn-in population\n",
    "        _, burn_in_phenotypes = score_population(new_pop, self.trait, h2=self.config.h2)\n",
    "        self.normalization_mean = burn_in_phenotypes.mean().item()\n",
    "        self.normalization_std = burn_in_phenotypes.std().item()\n",
    "        \n",
    "        # Update trait intercept\n",
    "        self.trait.intercept = torch.tensor(self.trait.target_mean, device=self.trait.device)\n",
    "\n",
    "\n",
    "        \n",
    "    def burn_in(self, num_generations=50, h2=0.1, selection_intensity=0.9, mutation_rate=0.001, genetic_variance_threshold=.4):\n",
    "        current_pop = self.founder_pop.haplotypes\n",
    "        current_size = self.config.pop_size\n",
    "\n",
    "        for generation in range(num_generations):\n",
    "            # Score the current population\n",
    "            breeding_values, phenotypes = score_population(current_pop, self.trait, self.trait.intercept)\n",
    "\n",
    "            # Calculate genetic variance\n",
    "            genetic_variance = breeding_values.var().item()\n",
    "\n",
    "            # Introduce mutations if genetic variance is below the threshold\n",
    "            if genetic_variance < genetic_variance_threshold:\n",
    "                mutation_mask = torch.rand_like(current_pop) < mutation_rate\n",
    "                current_pop = torch.where(mutation_mask, 1 - current_pop, current_pop)\n",
    "            else:\n",
    "                # Select top individuals\n",
    "                num_selected = max(int(current_size * selection_intensity), 2)  # Ensure at least 2 parents\n",
    "                selection = torch.topk(phenotypes, num_selected).indices\n",
    "                selected_parents = current_pop[selection]\n",
    "\n",
    "                # Create next generation\n",
    "                gametes = meiosis(selected_parents, num_gametes_per_parent=self.config.pop_size // num_selected + 1)\n",
    "                current_pop = random_cross(gametes, total_crosses=self.config.pop_size)\n",
    "\n",
    "            if generation % 10 == 0 or generation == num_generations - 1:\n",
    "                print(f\"Generation {generation + 1}: \"\n",
    "                    f\"Max phenotype = {phenotypes.max().item():.4f}, \"\n",
    "                    f\"Max breeding value = {breeding_values.max().item():.4f}, \"\n",
    "                    f\"Genetic variance = {genetic_variance:.4f}\")\n",
    "\n",
    "        # Calculate new mean\n",
    "        final_breeding_values, _ = score_population(current_pop, self.trait, h2=1.0)\n",
    "        new_mean = final_breeding_values.mean().item()\n",
    "\n",
    "        return current_pop, new_mean\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@staticmethod\n",
    "def score_population(haplotypes: torch.Tensor, trait: Trait, h2: float = 1.0, norm_mean: float = 0, norm_std: float = 1):\n",
    "    dosages = haplotypes.sum(dim=1)\n",
    "    breeding_values = torch.einsum('ij,j->i', dosages, trait.effects)\n",
    "    bv_var = breeding_values.var()\n",
    "\n",
    "    if bv_var == 0 or h2 >= 1:\n",
    "        phenotypes = breeding_values\n",
    "    else:\n",
    "        env_variance = (1 - h2) / h2 * bv_var.item()\n",
    "        env_std = torch.sqrt(torch.tensor(env_variance, device=trait.device))\n",
    "        env_effects = torch.randn_like(breeding_values) * env_std\n",
    "        phenotypes = breeding_values + env_effects + trait.intercept\n",
    "\n",
    "    # Normalize phenotypes\n",
    "    normalized_phenotypes = (phenotypes - norm_mean) / norm_std\n",
    "\n",
    "    return breeding_values, normalized_phenotypes\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SimulationConfig:\n",
    "    #sb3 training\n",
    "    total_timesteps: int = 200000\n",
    "    seed: int = 100\n",
    "    #breeding sim parameters\n",
    "    max_generations: int= 10\n",
    "    n_markers: int = 500\n",
    "    starting_parents: int = 200 #inbred parents\n",
    "    h2: float = 1.0 \n",
    "    num_crossovers: int=3\n",
    "    sparse_reward: bool=True\n",
    "    #burnin\n",
    "    burnin_years : int =  20\n",
    "    burnin_gvt : float = .6\n",
    "    num_generations : int = 5\n",
    "    total_budget = num_generations * 500\n",
    "    #starting pop_size\n",
    "    pop_size : int = 100\n",
    "    #min cycle pop_size\n",
    "    min_pop : int = 10\n",
    "    max_budget_per_cycle : int = 1000\n",
    "    #fixed values\n",
    "    selection_intensity: float = 0.3\n",
    "\n",
    "\n",
    "config = SimulationConfig()\n",
    "# config.selection_intensity=0.3\n",
    "\n",
    "#example usage of the breeding simulation. a standard round of selection.\n",
    "\n",
    "#Use default parameters to set up SimParams which holds the key founder_population\n",
    "SP = SimParams(config)\n",
    "#access founder information\n",
    "SP.founder_pop #population class\n",
    "SP.founder_pop.haplotypes #haplotype tensor\n",
    "SP.founder_phenotypes # stored score with config.h2\n",
    "SP.founder_bv # stored breeding_values\n",
    "#NOTE: the founder population is necessarry for doing a reset to compare breeding programs\n",
    "\n",
    "#select parents based on the score\n",
    "parent_haplotypes = SP.founder_pop.haplotypes\n",
    "parent_bv, parent_score = score_population(parent_haplotypes, SP.trait)\n",
    "#filter parents based on score grabbing top 10%\n",
    "selection_intensity = config.selection_intensity\n",
    "top_parents = int(parent_haplotypes.shape[0] * selection_intensity) #get correct number for 10% given pop size\n",
    "top_parents = torch.topk(parent_score, top_parents).indices #Ids for the select parents\n",
    "#filter these parents\n",
    "filtered_parent_haplotypes = parent_haplotypes[top_parents]\n",
    "#create gametes for these parents\n",
    "total_offspring = 5\n",
    "gametes = meiosis(filtered_parent_haplotypes, num_gametes_per_parent=total_offspring)\n",
    "#combine gametes randomly\n",
    "offspring_haplotypes = random_cross(gamete_tensor=gametes, total_crosses=total_offspring)\n",
    "#score the offspring\n",
    "offspring_bv, offspring_score = score_population(offspring_haplotypes, SP.trait)\n",
    "#calculate reward\n",
    "reward = offspring_score.mean() - parent_score.mean()\n",
    "\n",
    "#NOTE this example is core of the rest of the software/analysis\n",
    "print(reward)\n",
    "\n",
    "\n",
    "def selection(parent_haplotypes: torch.Tensor, trait: Trait, selection_intensity: float, total_offspring: int) -> tuple:\n",
    "    \"\"\"\n",
    "    Perform selection, meiosis, crossing, and scoring of offspring.\n",
    "\n",
    "    Args:\n",
    "    parent_haplotypes (torch.Tensor): Haplotypes of the parent population.\n",
    "    trait (Trait): The trait object containing genetic effects.\n",
    "    selection_intensity (float): Proportion of parents to select (0 to 1).\n",
    "    total_offspring (int): Number of offspring to generate.\n",
    "\n",
    "    Returns:\n",
    "    tuple: (offspring_haplotypes, offspring_score, parent_score, reward)\n",
    "    \"\"\"\n",
    "    # Score parents\n",
    "    parent_bv, parent_score = score_population(parent_haplotypes, trait)\n",
    "\n",
    "    # Select top parents\n",
    "    num_parents = parent_haplotypes.shape[0]\n",
    "    top_parents_count = max(int(num_parents * selection_intensity), 2)  # Ensure at least 2 parents\n",
    "    top_parent_indices = torch.topk(parent_score, top_parents_count).indices\n",
    "    \n",
    "    # Filter selected parents\n",
    "    selected_parent_haplotypes = parent_haplotypes[top_parent_indices]\n",
    "\n",
    "    # Create gametes through meiosis\n",
    "    gametes = meiosis(selected_parent_haplotypes, num_gametes_per_parent=total_offspring // top_parents_count + 1)\n",
    "\n",
    "    # Combine gametes randomly to create offspring\n",
    "    offspring_haplotypes = random_cross(gamete_tensor=gametes, total_crosses=total_offspring)\n",
    "\n",
    "    # Score offspring\n",
    "    offspring_bv, offspring_score = score_population(offspring_haplotypes, trait)\n",
    "\n",
    "    # Calculate reward\n",
    "    reward = offspring_score.mean() - parent_score.mean()\n",
    "\n",
    "    return offspring_haplotypes, offspring_score, parent_score, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b2815a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "This breeding simulation will simulate a single additive trait.\n",
    "\n",
    "1) we will init a randomized population of size (config.starting_parents, 2, config.n_markers) with 0/1 tensor\n",
    "2) we will use this starting population to sample the marker effects for our additive trait, which is scaled to be 0/1 mean/var for the population\n",
    "3) we will store the founder_pop and their founder_phentypes\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## BREEDING SIMULATOR\n",
    "    \n",
    "class Genome:\n",
    "    def __init__(self, n_markers: int):\n",
    "        self.ploidy: int = 2\n",
    "        self.n_markers: int = n_markers\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Genome(ploidy={self.ploidy}, n_markers={self.n_markers})\"\n",
    "\n",
    "class Population:\n",
    "    def __init__(self, pop_size: int, haplotypes:torch.tensor, genome: Genome, device: torch.device):\n",
    "        self.pop_size: int = pop_size\n",
    "        self.genome: Genome = genome\n",
    "        self.haplotypes: torch.Tensor = haplotypes\n",
    "        self.device: torch.device = device\n",
    "        \n",
    "    def to(self, device: torch.device) -> 'Population':\n",
    "        self.device = device\n",
    "        self.haplotypes = self.haplotypes.to(device)\n",
    "        return self\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Population(pop_size={self.pop_size}, genome={self.genome}, device={self.device})\"\n",
    "\n",
    "class Trait:\n",
    "    def __init__(self, genome: Genome, population: Population, target_mean: float = 0.0, target_variance: float = 1):\n",
    "        self.genome: Genome = genome\n",
    "        self.device: torch.device = population.device\n",
    "        self.target_mean: float = target_mean\n",
    "        self.target_variance: float = target_variance\n",
    "\n",
    "        # Use torch.randn with a generator for reproducibility\n",
    "        generator = torch.Generator(device=self.device)\n",
    "        generator.manual_seed(torch.initial_seed())  # Use the seed set by torch.manual_seed()\n",
    "        raw_effects = torch.randn(genome.n_markers, device=self.device, generator=generator)\n",
    "\n",
    "        centered_effects = raw_effects - raw_effects.mean()\n",
    "        dosages = population.haplotypes.sum(dim=1)\n",
    "        founder_values = torch.einsum('ij,j->i', dosages, centered_effects)\n",
    "        founder_mean = founder_values.mean()\n",
    "        founder_var = founder_values.var()\n",
    "\n",
    "        scaling_factor = torch.sqrt(self.target_variance / founder_var)\n",
    "        self.effects: torch.Tensor = centered_effects * scaling_factor\n",
    "        self.intercept: torch.Tensor = (torch.tensor(self.target_mean, device=self.device) - founder_mean).detach()\n",
    "\n",
    "    def to(self, device: torch.device) -> 'Trait':\n",
    "        self.device = device\n",
    "        self.effects = self.effects.to(device)\n",
    "        self.intercept = self.intercept.to(device)\n",
    "        return self\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Trait(target_mean={self.target_mean}, target_variance={self.target_variance}, device={self.device})\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The logic of the breeding simulation. Meiosis(Recombination) + Crossing\n",
    "\n",
    "All operate on tensors\n",
    "\"\"\"\n",
    "@staticmethod\n",
    "def meiosis(selected_haplotypes: torch.Tensor, num_crossovers: int = 1, num_gametes_per_parent: int = 1) -> torch.Tensor:\n",
    "    \"\"\" takes a tensor of parent genomes, (selected_haplotypes) and generates gametes for each parent\"\"\"\n",
    "    num_parents, ploidy, num_markers = selected_haplotypes.shape\n",
    "\n",
    "    # Repeat each parent's haplotypes num_gametes_per_parent times\n",
    "    expanded_haplotypes = selected_haplotypes.repeat_interleave(num_gametes_per_parent, dim=0)\n",
    "\n",
    "    # The rest of the function remains largely the same, but operates on the expanded haplotypes\n",
    "    total_gametes = num_parents * num_gametes_per_parent\n",
    "\n",
    "    crossover_points = torch.randint(1, num_markers, (total_gametes, num_crossovers), device=selected_haplotypes.device, generator=torch.Generator(device=selected_haplotypes.device).manual_seed(torch.initial_seed()))\n",
    "    crossover_points, _ = torch.sort(crossover_points, dim=1)\n",
    "\n",
    "    crossover_mask = torch.zeros((total_gametes, num_markers), dtype=torch.bool, device=selected_haplotypes.device)\n",
    "    crossover_mask.scatter_(1, crossover_points, 1)\n",
    "    crossover_mask = torch.cumsum(crossover_mask, dim=1) % 2 == 1\n",
    "\n",
    "    crossover_mask = crossover_mask.unsqueeze(1).expand(-1, ploidy, -1)\n",
    "\n",
    "    start_chromosome = torch.randint(0, ploidy, (total_gametes, 1), device=selected_haplotypes.device)\n",
    "    start_mask = start_chromosome.unsqueeze(-1).expand(-1, -1, num_markers)\n",
    "\n",
    "    final_mask = crossover_mask ^ start_mask.bool()\n",
    "\n",
    "    offspring_haplotypes = torch.where(final_mask, expanded_haplotypes, expanded_haplotypes.roll(shifts=1, dims=1))\n",
    "\n",
    "    # Return only the first haplotype for each meiosis event\n",
    "    return offspring_haplotypes[:, 0, :]\n",
    "\n",
    "@staticmethod\n",
    "def random_cross(gamete_tensor: torch.Tensor, total_crosses: int) -> torch.Tensor:\n",
    "    \"\"\" takes output from meiosis (gamete tensor) and outputs offspring \"\"\"\n",
    "    num_gametes, n_markers = gamete_tensor.shape\n",
    "\n",
    "    # Double the gamete tensor until we have enough for the total crosses\n",
    "    while num_gametes < 2 * total_crosses:\n",
    "        gamete_tensor = torch.cat([gamete_tensor, gamete_tensor], dim=0)\n",
    "        num_gametes *= 2\n",
    "\n",
    "    # Randomly select gametes for crossing\n",
    "    gamete_indices = torch.randperm(num_gametes, device=gamete_tensor.device)\n",
    "    parent1_indices = gamete_indices[:total_crosses]\n",
    "    parent2_indices = gamete_indices[total_crosses:2*total_crosses]\n",
    "\n",
    "    # Create the new population haplotype tensor\n",
    "    new_population = torch.stack([\n",
    "        gamete_tensor[parent1_indices],\n",
    "        gamete_tensor[parent2_indices]\n",
    "    ], dim=1)\n",
    "\n",
    "    return new_population\n",
    "    \n",
    "\n",
    "@staticmethod\n",
    "def score_population(haplotypes: torch.Tensor, trait: Trait, h2: float = 1.0, founder_mean: float = 0, founder_std: float = 1):\n",
    "    dosages = haplotypes.sum(dim=1)\n",
    "    breeding_values = torch.einsum('ij,j->i', dosages, trait.effects)\n",
    "    bv_var = breeding_values.var()\n",
    "\n",
    "    if bv_var == 0 or h2 >= 1:\n",
    "        phenotypes = breeding_values\n",
    "    else:\n",
    "        env_variance = (1 - h2) / (h2 * bv_var.item()+.001)\n",
    "        env_std = torch.sqrt(torch.tensor(env_variance, device=trait.device))\n",
    "        env_effects = torch.randn_like(breeding_values) * env_std\n",
    "        phenotypes = breeding_values + env_effects + trait.intercept\n",
    "\n",
    "    # Normalize phenotypes\n",
    "    normalized_phenotypes = (phenotypes - founder_mean) / founder_std\n",
    "\n",
    "    return breeding_values, normalized_phenotypes\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class SimParams:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.genome = Genome(config.n_markers)\n",
    "\n",
    "        # Load and prepare genome\n",
    "        genome = np.load('genome.npy')\n",
    "        reshaped_genome = np.transpose(genome, (0, 2, 1))\n",
    "        reshaped_genome = torch.tensor(reshaped_genome, device=self.device).float()\n",
    "        \n",
    "        # Sample parents\n",
    "        random_indices = torch.randperm(reshaped_genome.shape[0])[:config.starting_parents]\n",
    "        parents = reshaped_genome[random_indices]\n",
    "        \n",
    "        # Sample markers\n",
    "        random_indices = torch.randperm(parents.shape[2])[:config.n_markers]\n",
    "        parents = parents[:,:,random_indices]\n",
    "\n",
    "        f1_gametes = meiosis(parents, num_crossovers=config.num_crossovers, num_gametes_per_parent=config.pop_size)\n",
    "        f1 = random_cross(gamete_tensor=f1_gametes, total_crosses=config.pop_size)\n",
    "\n",
    "        self.founder_pop = Population(config.pop_size, f1, self.genome, self.device)\n",
    "        self.trait = Trait(self.genome, self.founder_pop)\n",
    "        # Calculate founder population statistics\n",
    "        founder_bv, founder_phenotypes = score_population(self.founder_pop.haplotypes, self.trait, h2=self.config.h2)\n",
    "        self.founder_mean = founder_phenotypes.mean().item()\n",
    "        self.founder_std = founder_phenotypes.std().item()\n",
    "\n",
    "        # Perform burn-in\n",
    "        new_pop, new_mean = self.burn_in(num_generations=config.burnin_years, genetic_variance_threshold=config.burnin_gvt)\n",
    "        \n",
    "        # Update founder population\n",
    "        self.founder_pop.haplotypes = new_pop\n",
    "        \n",
    "        # Calculate normalization parameters based on burn-in population\n",
    "        _, burn_in_phenotypes = score_population(new_pop, self.trait, h2=self.config.h2)\n",
    "        self.normalization_mean = burn_in_phenotypes.mean().item()\n",
    "        self.normalization_std = burn_in_phenotypes.std().item()\n",
    "        \n",
    "        # Update trait intercept\n",
    "        self.trait.intercept = torch.tensor(self.trait.target_mean, device=self.trait.device)\n",
    "\n",
    "        \n",
    "    def burn_in(self, num_generations=50, h2=0.1, selection_intensity=0.9, mutation_rate=0.001, genetic_variance_threshold=.4):\n",
    "        current_pop = self.founder_pop.haplotypes\n",
    "        current_size = self.config.pop_size\n",
    "\n",
    "        for generation in range(num_generations):\n",
    "            # Score the current population\n",
    "            breeding_values, phenotypes = score_population(current_pop, self.trait, self.trait.intercept)\n",
    "\n",
    "            # Calculate genetic variance\n",
    "            genetic_variance = breeding_values.var().item()\n",
    "\n",
    "            # Introduce mutations if genetic variance is below the threshold\n",
    "            if genetic_variance < genetic_variance_threshold:\n",
    "                mutation_mask = torch.rand_like(current_pop) < mutation_rate\n",
    "                current_pop = torch.where(mutation_mask, 1 - current_pop, current_pop)\n",
    "            else:\n",
    "                # Select top individuals\n",
    "                num_selected = max(int(current_size * selection_intensity), 2)  # Ensure at least 2 parents\n",
    "                selection = torch.topk(phenotypes, num_selected).indices\n",
    "                selected_parents = current_pop[selection]\n",
    "\n",
    "                # Create next generation\n",
    "                gametes = meiosis(selected_parents, num_gametes_per_parent=self.config.pop_size // num_selected + 1)\n",
    "                current_pop = random_cross(gametes, total_crosses=self.config.pop_size)\n",
    "\n",
    "            if generation % 10 == 0 or generation == num_generations - 1:\n",
    "                print(f\"Generation {generation + 1}: \"\n",
    "                    f\"Max phenotype = {phenotypes.max().item():.4f}, \"\n",
    "                    f\"Max breeding value = {breeding_values.max().item():.4f}, \"\n",
    "                    f\"Genetic variance = {genetic_variance:.4f}\")\n",
    "\n",
    "        # Calculate new mean\n",
    "        final_breeding_values, _ = score_population(current_pop, self.trait, h2=1.0)\n",
    "        new_mean = final_breeding_values.mean().item()\n",
    "\n",
    "        return current_pop, new_mean\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, display\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "\n",
    "\n",
    "class GeneralizedVisualizationCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0, log_freq=2000, window_size=50, target_phenotype=None, best_action=None):\n",
    "        super().__init__(verbose)\n",
    "        self.data = defaultdict(lambda: defaultdict(list))\n",
    "        self.log_freq = log_freq\n",
    "        self.excluded_metrics = ['TimeLimit.truncated', 'current_generation']\n",
    "        self.target_phenotype = target_phenotype\n",
    "        self.best_action = best_action\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        info = self.locals['infos'][0]\n",
    "        obs = self.locals['new_obs']\n",
    "        \n",
    "        current_generation = info['current_generation']\n",
    "        \n",
    "        # Track all scalar values from the observation space\n",
    "        for key, value in obs.items():\n",
    "            if np.isscalar(value) and key not in self.excluded_metrics:\n",
    "                self.data[key][current_generation].append(value)\n",
    "        \n",
    "        # Also track any scalar values from the info dict\n",
    "        for key, value in info.items():\n",
    "            if np.isscalar(value) and key not in self.excluded_metrics:\n",
    "                self.data[key][current_generation].append(value)\n",
    "\n",
    "        if self.num_timesteps % self.log_freq == 0:\n",
    "            self.visualize()\n",
    "\n",
    "        return True\n",
    "\n",
    "    def visualize(self):\n",
    "        num_metrics = len(self.data)\n",
    "        fig, axes = plt.subplots(num_metrics, 1, figsize=(16, 6*num_metrics), sharex=True)\n",
    "        if num_metrics == 1:\n",
    "            axes = [axes]\n",
    "\n",
    "        for idx, (metric, generations) in enumerate(self.data.items()):\n",
    "            ax = axes[idx]\n",
    "            num_generations = len(generations)\n",
    "            colors = plt.cm.BuPu(np.linspace(0, 1, num_generations))\n",
    "\n",
    "            for i, (generation, values) in enumerate(generations.items()):\n",
    "                if len(values) == 0:\n",
    "                    continue  # Skip empty data\n",
    "\n",
    "                steps = np.arange(len(values))\n",
    "\n",
    "                # Dynamically adjust window size\n",
    "                effective_window = min(self.window_size, len(values))\n",
    "                if effective_window < 2:\n",
    "                    effective_window = 2  # Minimum window size\n",
    "\n",
    "                # Calculate rolling moving average with adjusted window size\n",
    "                rolling_avg = np.convolve(values, np.ones(effective_window), 'valid') / effective_window\n",
    "                rolling_steps = steps[effective_window-1:]\n",
    "\n",
    "                ax.plot(rolling_steps, rolling_avg, label=f'Generation {generation}', color=colors[i])\n",
    "                ax.set_title(f'{metric.capitalize()} per Generation')\n",
    "                ax.set_ylabel(f'Rolling Avg {metric.capitalize()}')\n",
    "                ax.grid(True)\n",
    "\n",
    "            # Add target_phenotype line for max_phenotype chart\n",
    "            if metric == 'max_phenotype' and self.target_phenotype is not None:\n",
    "                ax.axhline(y=self.target_phenotype, color='r', linestyle='--', label='Target Phenotype')\n",
    "            # Add best_action line for selection_intensity chart\n",
    "            if metric == 'selection_intensity' and self.best_action is not None:\n",
    "                best_action_intensity = self.best_action[0] if isinstance(self.best_action, (list, np.ndarray)) else self.best_action\n",
    "                # Remove the conversion here, as best_action should already be a selection intensity\n",
    "                ax.axhline(y=best_action_intensity, color='r', linestyle='--', label='Best Constant Action')\n",
    "                # Set y-axis limits for selection_intensity\n",
    "            if metric == 'selection_intensity':\n",
    "                ax.set_ylim(0, 1)\n",
    "                \n",
    "\n",
    "        axes[-1].set_xlabel('Steps within Generation')\n",
    "        plt.tight_layout()\n",
    "        clear_output(wait=True)\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "import numpy as np\n",
    "import torch\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "class BreedingEnv(gym.Env):\n",
    "    def __init__(self, sim_params: SimParams):\n",
    "        super(BreedingEnv, self).__init__()\n",
    "        \n",
    "        self.SP = sim_params\n",
    "        self.max_generations = sim_params.config.max_generations\n",
    "        self.current_generation = 0\n",
    "        self.current_pop = sim_params.founder_pop.haplotypes\n",
    "        self.selection_intensities = []\n",
    "        self.founder_mean = sim_params.founder_mean\n",
    "        self.founder_std = sim_params.founder_std\n",
    "        \n",
    "        # New attribute to store sum of actions\n",
    "        self.action_sum = 0.0\n",
    "\n",
    "        # Define action and observation spaces\n",
    "        self.action_space = spaces.Box(low=-1, high=1, shape=(1,), dtype=np.float32)\n",
    "        self.observation_space = spaces.Dict({\n",
    "            'remaining_generations': spaces.Box(low=0, high=1, shape=(1,), dtype=np.float32),\n",
    "            'genetic_variance': spaces.Box(low=0, high=np.inf, shape=(1,), dtype=np.float32),\n",
    "            'average_action': spaces.Box(low=0, high=1, shape=(1,), dtype=np.float32),\n",
    "        })\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.current_generation = 0\n",
    "        self.current_pop = self.SP.founder_pop.haplotypes\n",
    "        self.selection_intensities = []\n",
    "        self.action_sum = 0.0  # Reset action sum\n",
    "        return self._get_obs(), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        # Convert action to selection intensity\n",
    "        selection_intensity = (action[0] + 1) / 2 * 0.98 + 0.01  # Maps [-1, 1] to [0.01, 0.99]\n",
    "        self.selection_intensities.append(selection_intensity)\n",
    "        \n",
    "        # Update action sum\n",
    "        self.action_sum += selection_intensity\n",
    "        \n",
    "        # Score the current population\n",
    "        breeding_values, phenotypes = score_population(self.current_pop, self.SP.trait, h2=self.SP.config.h2)\n",
    "        \n",
    "        # Select top individuals\n",
    "        num_selected = max(int(self.SP.config.pop_size * selection_intensity), 2)\n",
    "        selection = torch.topk(phenotypes, num_selected).indices\n",
    "        selected_parents = self.current_pop[selection]\n",
    "        \n",
    "        # Create next generation\n",
    "        gametes = meiosis(selected_parents, num_gametes_per_parent=self.SP.config.pop_size // num_selected + 1)\n",
    "        self.current_pop = random_cross(gametes, total_crosses=self.SP.config.pop_size)\n",
    "        \n",
    "        # Update generation count\n",
    "        self.current_generation += 1\n",
    "        \n",
    "        # Calculate reward\n",
    "        new_breeding_values, new_phenotypes = score_population(self.current_pop, self.SP.trait, h2=self.SP.config.h2)\n",
    "        # Check if done\n",
    "        done = self.current_generation >= self.max_generations\n",
    "\n",
    "        if self.SP.config.sparse_reward:\n",
    "            if done:\n",
    "                reward = new_breeding_values.mean().item() - self.founder_mean\n",
    "            else:\n",
    "                reward = 0\n",
    "        else:\n",
    "            reward = new_breeding_values.mean().item() - breeding_values.mean().item()\n",
    "\n",
    "\n",
    "        # Prepare observation\n",
    "        observation = self._get_obs()\n",
    "\n",
    "        # Prepare info dictionary\n",
    "        info = {\n",
    "            'max_phenotype': new_phenotypes.mean().item(),\n",
    "            'current_generation': self.current_generation,\n",
    "            'genetic_variance': new_phenotypes.var().item(),\n",
    "            'selection_intensity': selection_intensity\n",
    "        }\n",
    "\n",
    "        return observation, reward, done, False, info\n",
    "\n",
    "    def _get_obs(self):\n",
    "        breeding_values, _ = score_population(self.current_pop, self.SP.trait, h2=self.SP.config.h2)\n",
    "        genetic_variance = breeding_values.var().item()\n",
    "        remaining_generations = (self.max_generations - self.current_generation) / self.max_generations\n",
    "        average_action = self.action_sum / (self.current_generation + 1) if self.current_generation > 0 else 0.0\n",
    "        \n",
    "        return {\n",
    "            'remaining_generations': np.array([remaining_generations], dtype=np.float32),\n",
    "            'genetic_variance': np.array([genetic_variance], dtype=np.float32),\n",
    "            'average_action': np.array([average_action], dtype=np.float32)\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa1dbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def run_constant_action_baseline_analysis(env, num_episodes=10, num_actions = 20):\n",
    "    def run_constant_action_baseline(env, action, num_episodes):\n",
    "        results = []\n",
    "        for _ in range(num_episodes):\n",
    "            obs, _ = env.reset()\n",
    "            done = False\n",
    "            episode_reward = 0\n",
    "            max_phenotypes = []\n",
    "            genetic_variances = []\n",
    "            \n",
    "            while not done:\n",
    "                obs, reward, done, _, info = env.step(np.array([action]))\n",
    "                episode_reward += reward\n",
    "                max_phenotypes.append(info['max_phenotype'])\n",
    "                genetic_variances.append(info['genetic_variance'])\n",
    "            \n",
    "            results.append({\n",
    "                'total_reward': episode_reward,\n",
    "                'max_phenotypes': max_phenotypes,\n",
    "                'genetic_variances': genetic_variances\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "\n",
    "    # Define a range of constant actions to test\n",
    "    actions_to_test = np.linspace(-1, 1, num_actions)\n",
    "\n",
    "    # Collect baseline results\n",
    "    baseline_results = {}\n",
    "    best_action = None\n",
    "    best_max_phenotype = float('-inf')\n",
    "    best_avg_reward = float('-inf')\n",
    "\n",
    "    for action in actions_to_test:\n",
    "        baseline_results[action] = run_constant_action_baseline(env, action, num_episodes)\n",
    "        \n",
    "        # Calculate average max phenotype and average total reward for this action\n",
    "        avg_max_phenotype = np.mean([max(r['max_phenotypes']) for r in baseline_results[action]])\n",
    "        avg_total_reward = np.mean([r['total_reward'] for r in baseline_results[action]])\n",
    "        \n",
    "        # Update best action if this action performs better\n",
    "        if avg_max_phenotype > best_max_phenotype:\n",
    "            best_action = action\n",
    "            best_max_phenotype = avg_max_phenotype\n",
    "            best_avg_reward = avg_total_reward\n",
    "\n",
    "    # Plot results\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(12, 18))\n",
    "\n",
    "    n_bins = len(actions_to_test)\n",
    "    cmap = plt.get_cmap('PRGn')\n",
    "\n",
    "    # Determine which actions to label (10 evenly spaced)\n",
    "    label_indices = np.linspace(0, len(actions_to_test) - 1, 10, dtype=int)\n",
    "\n",
    "    for i, (action, results) in enumerate(baseline_results.items()):\n",
    "        selection_intensity = (action + 1) / 2 * 0.98 + 0.01\n",
    "        avg_max_phenotypes = np.mean([r['max_phenotypes'] for r in results], axis=0)\n",
    "        avg_genetic_variances = np.mean([r['genetic_variances'] for r in results], axis=0)\n",
    "        avg_total_reward = np.mean([r['total_reward'] for r in results])\n",
    "        \n",
    "        color = cmap(i / n_bins)\n",
    "        \n",
    "        label = f'Action {action:.2f} (SI: {selection_intensity:.2f})' if i in label_indices else None\n",
    "        ax1.plot(avg_max_phenotypes, label=label, color=color)\n",
    "        ax2.plot(avg_genetic_variances, label=label, color=color)\n",
    "        ax3.bar(i, avg_total_reward, color=color)  # Use index i as x-coordinate\n",
    "\n",
    "    # Add horizontal line for best max phenotype in ax1\n",
    "    ax1.axhline(y=best_max_phenotype, color='r', linestyle='--', label=f'Best Phenotype: {best_max_phenotype:.2f}')\n",
    "\n",
    "    ax1.set_title('Average Max Phenotype over Generations')\n",
    "    ax1.set_xlabel('Generation')\n",
    "    ax1.set_ylabel('Max Phenotype')\n",
    "    ax1.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    ax2.set_title('Average Genetic Variance over Generations')\n",
    "    ax2.set_xlabel('Generation')\n",
    "    ax2.set_ylabel('Genetic Variance')\n",
    "    ax2.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    ax3.set_title('Average Total Reward')\n",
    "    ax3.set_xlabel('Action')\n",
    "    ax3.set_ylabel('Total Reward')\n",
    "\n",
    "    # Find the best action\n",
    "    best_action, best_results = max(baseline_results.items(), key=lambda x: max(r['max_phenotypes'][-1] for r in x[1]))\n",
    "    best_index = list(baseline_results.keys()).index(best_action)\n",
    "\n",
    "    # Calculate the Selection Intensity for the best action\n",
    "    best_selection_intensity = (best_action + 1) / 2 * 0.98 + 0.01\n",
    "\n",
    "    # Add vertical line for best action\n",
    "    ax3.axvline(x=best_index, color='r', linestyle='--', \n",
    "                label=f'Best Action: {best_action:.2f} (SI: {best_selection_intensity:.2f})')\n",
    "\n",
    "    # Clean up x-axis for ax3\n",
    "    x_ticks = np.linspace(0, len(actions_to_test) - 1, 10, dtype=int)\n",
    "    ax3.set_xticks(x_ticks)\n",
    "    ax3.set_xticklabels([f'{actions_to_test[i]:.2f}' for i in x_ticks], rotation=45, ha='right')\n",
    "\n",
    "    # Add legend to ax3\n",
    "    ax3.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print average total rewards and best action information\n",
    "    print(\"Average Total Rewards:\")\n",
    "    for action, results in baseline_results.items():\n",
    "        avg_reward = np.mean([r['total_reward'] for r in results])\n",
    "        selection_intensity = (action + 1) / 2 * 0.98 + 0.01\n",
    "        print(f\"Action {action:.2f} (SI: {selection_intensity:.2f}): {avg_reward:.2f}\")\n",
    "\n",
    "    print(\"\\nBest Action Information:\")\n",
    "    print(f\"Best Action: {best_action:.2f}\")\n",
    "    print(f\"Best Selection Intensity: {best_selection_intensity:.2f}\")\n",
    "    print(f\"Best Max Phenotype: {best_max_phenotype:.2f}\")\n",
    "    print(f\"Best Average Reward: {best_avg_reward:.2f}\")\n",
    "\n",
    "    return best_action, best_selection_intensity, best_max_phenotype, best_avg_reward\n",
    "\n",
    "# Usage:\n",
    "\n",
    "# config = SimulationConfig()\n",
    "# SP = SimParams(config)\n",
    "# breeder_env = BreedingEnv(SP)\n",
    "# best_action, best_si, best_phenotype, best_reward = run_constant_action_baseline_analysis(breeder_env, num_actions=100,num_episodes=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0883e905",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
